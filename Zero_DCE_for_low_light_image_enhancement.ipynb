{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Zero-DCE_for_low-light_image_enhancement.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPhDTuf4lS1c1UWka99jAMv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WoojinJeonkr/DeepLearning/blob/main/Zero_DCE_for_low_light_image_enhancement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 저조도 이미지 향상을 위한 zero-DCE\n",
        "- 내용 출처: https://keras.io/examples/vision/zero_dce/\n",
        "- 목표: 저조도 이미지 향상을 위한 Zero-Reference Deep Curve Estimation 구현\n",
        "- 주어진 이미지의 동적 범위 조정을 위해 픽셀 단위 및 고차 톤 곡선을 추정하기 위해 경량 심층 네트워크 DCE-Net 훈련"
      ],
      "metadata": {
        "id": "HuYf3pp_PzeA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 01. Zero-Reference Deep Curve Estimation(zero-DCE)\n",
        "- 심층 신경망으로 이미지별 색조 곡선 을 추정하는 작업\n",
        "- 저조도 이미지 향상을 공식화\n",
        "- 저조도 이미지를 입력으로 사용하고 출력으로 향상된 이미지를 얻기 위해   \n",
        "입력의 동적 범위에 대한 픽셀 단위 조정에 사용하는 고차 톤 곡선 생성\n",
        "- 곡선 추정 프로세스는 향상된 이미지의 범위를 유지하고 인접 픽셀의 대비를 유지하는 방식으로 수행"
      ],
      "metadata": {
        "id": "CQBA-dzVQFBP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 02. import library"
      ],
      "metadata": {
        "id": "JjYlNmemRwFn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EyHzqc-OPnwh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from PIL import Image, ImageOps\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 03. LOL데이터세트 다운로드\n",
        "- LOL데이터세트   \n",
        "  1) 저조도 이미지 향상을 위해 생성   \n",
        "  2) 훈련용 이미지 485개와 테스트용 이미지 15개 제공   \n",
        "  3) 데이터 세트의 각 이미지 쌍은 저조도 입력 이미지와 해당하는 노출된 참조 이미지로 구성"
      ],
      "metadata": {
        "id": "xYCR-UUOQnnF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1DdGIJ4PZPlF2ikl8mNM9V-PdVxVLbQi6\n",
        "!unzip -q lol_dataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yq2vzjIRRtZ2",
        "outputId": "fa2146a6-6833-452b-f6ca-721537df003a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1DdGIJ4PZPlF2ikl8mNM9V-PdVxVLbQi6\n",
            "To: /content/lol_dataset.zip\n",
            "100% 347M/347M [00:04<00:00, 84.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 04. 훈련용, 평가용 데이터 분할"
      ],
      "metadata": {
        "id": "v1SNqibpSAGK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 256\n",
        "BATCH_SIZE = 16\n",
        "MAX_TRAIN_IMAGES = 400"
      ],
      "metadata": {
        "id": "jBSPzEndR2Tw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(image_path):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_png(image, channels=3)\n",
        "    image = tf.image.resize(images=image, size=[IMAGE_SIZE, IMAGE_SIZE])\n",
        "    image = image / 255.0\n",
        "    return image"
      ],
      "metadata": {
        "id": "Q62ihnVmSFsh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_generator(low_light_images):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((low_light_images))\n",
        "    dataset = dataset.map(load_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "2vOUMe73SHFX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_low_light_images = sorted(glob(\"./lol_dataset/our485/low/*\"))[:MAX_TRAIN_IMAGES]\n",
        "val_low_light_images = sorted(glob(\"./lol_dataset/our485/low/*\"))[MAX_TRAIN_IMAGES:]\n",
        "test_low_light_images = sorted(glob(\"./lol_dataset/eval15/low/*\"))\n",
        "\n",
        "train_dataset = data_generator(train_low_light_images)\n",
        "val_dataset = data_generator(val_low_light_images)"
      ],
      "metadata": {
        "id": "nRgi0o6BSIXj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train Dataset:\", train_dataset)\n",
        "print(\"Validation Dataset:\", val_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCmm9rU-SLIb",
        "outputId": "d347ae97-719c-4fd9-e8d8-0e0a51b971ac"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset: <BatchDataset element_spec=TensorSpec(shape=(16, 256, 256, 3), dtype=tf.float32, name=None)>\n",
            "Validation Dataset: <BatchDataset element_spec=TensorSpec(shape=(16, 256, 256, 3), dtype=tf.float32, name=None)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 05. zero-DCE 프레임워크 구축"
      ],
      "metadata": {
        "id": "GsJxeeJYSS6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DCE-넷\n",
        "def build_dce_net():\n",
        "    input_img = keras.Input(shape=[None, None, 3])\n",
        "    conv1 = layers.Conv2D(\n",
        "        32, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"\n",
        "    )(input_img)\n",
        "    conv2 = layers.Conv2D(\n",
        "        32, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"\n",
        "    )(conv1)\n",
        "    conv3 = layers.Conv2D(\n",
        "        32, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"\n",
        "    )(conv2)\n",
        "    conv4 = layers.Conv2D(\n",
        "        32, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"\n",
        "    )(conv3)\n",
        "    int_con1 = layers.Concatenate(axis=-1)([conv4, conv3])\n",
        "    conv5 = layers.Conv2D(\n",
        "        32, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"\n",
        "    )(int_con1)\n",
        "    int_con2 = layers.Concatenate(axis=-1)([conv5, conv2])\n",
        "    conv6 = layers.Conv2D(\n",
        "        32, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"\n",
        "    )(int_con2)\n",
        "    int_con3 = layers.Concatenate(axis=-1)([conv6, conv1])\n",
        "    x_r = layers.Conv2D(24, (3, 3), strides=(1, 1), activation=\"tanh\", padding=\"same\")(\n",
        "        int_con3\n",
        "    )\n",
        "    return keras.Model(inputs=input_img, outputs=x_r)"
      ],
      "metadata": {
        "id": "9NFFKkNlSMx-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 손실 함수\n",
        "\n",
        "# 색상 불변성 손실\n",
        "\"\"\"zero-DCE를 활성화하기 위해 향상된 이미지의 품질을 평가할 수 있는 미분 가능한 제로 참조 손실 세트 사용\"\"\"\n",
        "def color_constancy_loss(x):\n",
        "    mean_rgb = tf.reduce_mean(x, axis=(1, 2), keepdims=True)\n",
        "    mr, mg, mb = mean_rgb[:, :, :, 0], mean_rgb[:, :, :, 1], mean_rgb[:, :, :, 2]\n",
        "    d_rg = tf.square(mr - mg)\n",
        "    d_rb = tf.square(mr - mb)\n",
        "    d_gb = tf.square(mb - mg)\n",
        "    return tf.sqrt(tf.square(d_rg) + tf.square(d_rb) + tf.square(d_gb))\n",
        "\n",
        "# 노출 손실\n",
        "\"\"\"노출 부족/과다 영역을 억제하기 위해 사용하며 로컬 영역의 평균 강도 값과 미리 설정된 노출도 수준(0.6으로 설정) 사이의 거리 측정\"\"\"\n",
        "def exposure_loss(x, mean_val=0.6):\n",
        "    x = tf.reduce_mean(x, axis=3, keepdims=True)\n",
        "    mean = tf.nn.avg_pool2d(x, ksize=16, strides=16, padding=\"VALID\")\n",
        "    return tf.reduce_mean(tf.square(mean - mean_val))\n",
        "\n",
        "# 조명 평활도 손실\n",
        "\"\"\"인접 픽셀 간의 단조성 관계를 유지하기 위해 각 곡선 매개변수 맵에 조명 평활도 손실 추가\"\"\"\n",
        "def illumination_smoothness_loss(x):\n",
        "    batch_size = tf.shape(x)[0]\n",
        "    h_x = tf.shape(x)[1]\n",
        "    w_x = tf.shape(x)[2]\n",
        "    count_h = (tf.shape(x)[2] - 1) * tf.shape(x)[3]\n",
        "    count_w = tf.shape(x)[2] * (tf.shape(x)[3] - 1)\n",
        "    h_tv = tf.reduce_sum(tf.square((x[:, 1:, :, :] - x[:, : h_x - 1, :, :])))\n",
        "    w_tv = tf.reduce_sum(tf.square((x[:, :, 1:, :] - x[:, :, : w_x - 1, :])))\n",
        "    batch_size = tf.cast(batch_size, dtype=tf.float32)\n",
        "    count_h = tf.cast(count_h, dtype=tf.float32)\n",
        "    count_w = tf.cast(count_w, dtype=tf.float32)\n",
        "    return 2 * (h_tv / count_h + w_tv / count_w) / batch_size"
      ],
      "metadata": {
        "id": "dV51qHAwSehm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 공간 일관성 손실\n",
        "\"\"\"입력 이미지와 향상된 버전에서 인접 영역 간의 대비를 유지하여 향상된 이미지의 공간적 일관성 촉진\"\"\"\n",
        "class SpatialConsistencyLoss(keras.losses.Loss):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(SpatialConsistencyLoss, self).__init__(reduction=\"none\")\n",
        "\n",
        "        self.left_kernel = tf.constant(\n",
        "            [[[[0, 0, 0]], [[-1, 1, 0]], [[0, 0, 0]]]], dtype=tf.float32\n",
        "        )\n",
        "        self.right_kernel = tf.constant(\n",
        "            [[[[0, 0, 0]], [[0, 1, -1]], [[0, 0, 0]]]], dtype=tf.float32\n",
        "        )\n",
        "        self.up_kernel = tf.constant(\n",
        "            [[[[0, -1, 0]], [[0, 1, 0]], [[0, 0, 0]]]], dtype=tf.float32\n",
        "        )\n",
        "        self.down_kernel = tf.constant(\n",
        "            [[[[0, 0, 0]], [[0, 1, 0]], [[0, -1, 0]]]], dtype=tf.float32\n",
        "        )\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "\n",
        "        original_mean = tf.reduce_mean(y_true, 3, keepdims=True)\n",
        "        enhanced_mean = tf.reduce_mean(y_pred, 3, keepdims=True)\n",
        "        original_pool = tf.nn.avg_pool2d(\n",
        "            original_mean, ksize=4, strides=4, padding=\"VALID\"\n",
        "        )\n",
        "        enhanced_pool = tf.nn.avg_pool2d(\n",
        "            enhanced_mean, ksize=4, strides=4, padding=\"VALID\"\n",
        "        )\n",
        "\n",
        "        d_original_left = tf.nn.conv2d(\n",
        "            original_pool, self.left_kernel, strides=[1, 1, 1, 1], padding=\"SAME\"\n",
        "        )\n",
        "        d_original_right = tf.nn.conv2d(\n",
        "            original_pool, self.right_kernel, strides=[1, 1, 1, 1], padding=\"SAME\"\n",
        "        )\n",
        "        d_original_up = tf.nn.conv2d(\n",
        "            original_pool, self.up_kernel, strides=[1, 1, 1, 1], padding=\"SAME\"\n",
        "        )\n",
        "        d_original_down = tf.nn.conv2d(\n",
        "            original_pool, self.down_kernel, strides=[1, 1, 1, 1], padding=\"SAME\"\n",
        "        )\n",
        "\n",
        "        d_enhanced_left = tf.nn.conv2d(\n",
        "            enhanced_pool, self.left_kernel, strides=[1, 1, 1, 1], padding=\"SAME\"\n",
        "        )\n",
        "        d_enhanced_right = tf.nn.conv2d(\n",
        "            enhanced_pool, self.right_kernel, strides=[1, 1, 1, 1], padding=\"SAME\"\n",
        "        )\n",
        "        d_enhanced_up = tf.nn.conv2d(\n",
        "            enhanced_pool, self.up_kernel, strides=[1, 1, 1, 1], padding=\"SAME\"\n",
        "        )\n",
        "        d_enhanced_down = tf.nn.conv2d(\n",
        "            enhanced_pool, self.down_kernel, strides=[1, 1, 1, 1], padding=\"SAME\"\n",
        "        )\n",
        "\n",
        "        d_left = tf.square(d_original_left - d_enhanced_left)\n",
        "        d_right = tf.square(d_original_right - d_enhanced_right)\n",
        "        d_up = tf.square(d_original_up - d_enhanced_up)\n",
        "        d_down = tf.square(d_original_down - d_enhanced_down)\n",
        "        return d_left + d_right + d_up + d_down"
      ],
      "metadata": {
        "id": "voyzOfpRTfy7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 깊은 곡선 추정 모델\n",
        "\"\"\"Zero-DCE 프레임워크 구현\"\"\"\n",
        "class ZeroDCE(keras.Model):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(ZeroDCE, self).__init__(**kwargs)\n",
        "        self.dce_model = build_dce_net()\n",
        "\n",
        "    def compile(self, learning_rate, **kwargs):\n",
        "        super(ZeroDCE, self).compile(**kwargs)\n",
        "        self.optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "        self.spatial_constancy_loss = SpatialConsistencyLoss(reduction=\"none\")\n",
        "\n",
        "    def get_enhanced_image(self, data, output):\n",
        "        r1 = output[:, :, :, :3]\n",
        "        r2 = output[:, :, :, 3:6]\n",
        "        r3 = output[:, :, :, 6:9]\n",
        "        r4 = output[:, :, :, 9:12]\n",
        "        r5 = output[:, :, :, 12:15]\n",
        "        r6 = output[:, :, :, 15:18]\n",
        "        r7 = output[:, :, :, 18:21]\n",
        "        r8 = output[:, :, :, 21:24]\n",
        "        x = data + r1 * (tf.square(data) - data)\n",
        "        x = x + r2 * (tf.square(x) - x)\n",
        "        x = x + r3 * (tf.square(x) - x)\n",
        "        enhanced_image = x + r4 * (tf.square(x) - x)\n",
        "        x = enhanced_image + r5 * (tf.square(enhanced_image) - enhanced_image)\n",
        "        x = x + r6 * (tf.square(x) - x)\n",
        "        x = x + r7 * (tf.square(x) - x)\n",
        "        enhanced_image = x + r8 * (tf.square(x) - x)\n",
        "        return enhanced_image\n",
        "\n",
        "    def call(self, data):\n",
        "        dce_net_output = self.dce_model(data)\n",
        "        return self.get_enhanced_image(data, dce_net_output)\n",
        "\n",
        "    def compute_losses(self, data, output):\n",
        "        enhanced_image = self.get_enhanced_image(data, output)\n",
        "        loss_illumination = 200 * illumination_smoothness_loss(output)\n",
        "        loss_spatial_constancy = tf.reduce_mean(\n",
        "            self.spatial_constancy_loss(enhanced_image, data)\n",
        "        )\n",
        "        loss_color_constancy = 5 * tf.reduce_mean(color_constancy_loss(enhanced_image))\n",
        "        loss_exposure = 10 * tf.reduce_mean(exposure_loss(enhanced_image))\n",
        "        total_loss = (\n",
        "            loss_illumination\n",
        "            + loss_spatial_constancy\n",
        "            + loss_color_constancy\n",
        "            + loss_exposure\n",
        "        )\n",
        "        return {\n",
        "            \"total_loss\": total_loss,\n",
        "            \"illumination_smoothness_loss\": loss_illumination,\n",
        "            \"spatial_constancy_loss\": loss_spatial_constancy,\n",
        "            \"color_constancy_loss\": loss_color_constancy,\n",
        "            \"exposure_loss\": loss_exposure,\n",
        "        }\n",
        "\n",
        "    def train_step(self, data):\n",
        "        with tf.GradientTape() as tape:\n",
        "            output = self.dce_model(data)\n",
        "            losses = self.compute_losses(data, output)\n",
        "        gradients = tape.gradient(\n",
        "            losses[\"total_loss\"], self.dce_model.trainable_weights\n",
        "        )\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.dce_model.trainable_weights))\n",
        "        return losses\n",
        "\n",
        "    def test_step(self, data):\n",
        "        output = self.dce_model(data)\n",
        "        return self.compute_losses(data, output)\n",
        "\n",
        "    def save_weights(self, filepath, overwrite=True, save_format=None, options=None):\n",
        "        self.dce_model.save_weights(\n",
        "            filepath, overwrite=overwrite, save_format=save_format, options=options\n",
        "        )\n",
        "\n",
        "    def load_weights(self, filepath, by_name=False, skip_mismatch=False, options=None):\n",
        "        self.dce_model.load_weights(\n",
        "            filepath=filepath,\n",
        "            by_name=by_name,\n",
        "            skip_mismatch=skip_mismatch,\n",
        "            options=options,\n",
        "        )"
      ],
      "metadata": {
        "id": "uHcHC_tKTsLI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 06. 모델 훈련"
      ],
      "metadata": {
        "id": "n2rWxGnyT85f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zero_dce_model = ZeroDCE()\n",
        "zero_dce_model.compile(learning_rate=1e-4)\n",
        "history = zero_dce_model.fit(train_dataset, validation_data=val_dataset, epochs=100)\n",
        "\n",
        "\n",
        "def plot_result(item):\n",
        "    plt.plot(history.history[item], label=item)\n",
        "    plt.plot(history.history[\"val_\" + item], label=\"val_\" + item)\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(item)\n",
        "    plt.title(\"Train and Validation {} Over Epochs\".format(item), fontsize=14)\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_result(\"total_loss\")\n",
        "plot_result(\"illumination_smoothness_loss\")\n",
        "plot_result(\"spatial_constancy_loss\")\n",
        "plot_result(\"color_constancy_loss\")\n",
        "plot_result(\"exposure_loss\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3F7QDbwkT0Av",
        "outputId": "a7315c79-3ad4-4cbd-a921-c9c7a6444748"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "25/25 [==============================] - 552s 22s/step - total_loss: 4.9114 - illumination_smoothness_loss: 1.9781 - spatial_constancy_loss: 1.1408e-05 - color_constancy_loss: 0.0033 - exposure_loss: 2.9300 - val_total_loss: 4.3892 - val_illumination_smoothness_loss: 1.3859 - val_spatial_constancy_loss: 1.2094e-05 - val_color_constancy_loss: 4.7120e-04 - val_exposure_loss: 3.0028\n",
            "Epoch 2/100\n",
            "25/25 [==============================] - 551s 22s/step - total_loss: 4.1491 - illumination_smoothness_loss: 1.2273 - spatial_constancy_loss: 2.7073e-05 - color_constancy_loss: 0.0032 - exposure_loss: 2.9186 - val_total_loss: 3.9138 - val_illumination_smoothness_loss: 0.9223 - val_spatial_constancy_loss: 3.0823e-05 - val_color_constancy_loss: 4.0957e-04 - val_exposure_loss: 2.9911\n",
            "Epoch 3/100\n",
            "25/25 [==============================] - 554s 22s/step - total_loss: 3.7985 - illumination_smoothness_loss: 0.8889 - spatial_constancy_loss: 5.0826e-05 - color_constancy_loss: 0.0031 - exposure_loss: 2.9065 - val_total_loss: 3.6454 - val_illumination_smoothness_loss: 0.6642 - val_spatial_constancy_loss: 5.2997e-05 - val_color_constancy_loss: 4.0869e-04 - val_exposure_loss: 2.9808\n",
            "Epoch 4/100\n",
            "25/25 [==============================] - 552s 22s/step - total_loss: 3.5789 - illumination_smoothness_loss: 0.6811 - spatial_constancy_loss: 8.1212e-05 - color_constancy_loss: 0.0031 - exposure_loss: 2.8946 - val_total_loss: 3.4712 - val_illumination_smoothness_loss: 0.5009 - val_spatial_constancy_loss: 8.4624e-05 - val_color_constancy_loss: 4.2192e-04 - val_exposure_loss: 2.9698\n",
            "Epoch 5/100\n",
            "25/25 [==============================] - 544s 22s/step - total_loss: 3.4250 - illumination_smoothness_loss: 0.5397 - spatial_constancy_loss: 1.2292e-04 - color_constancy_loss: 0.0032 - exposure_loss: 2.8820 - val_total_loss: 3.3485 - val_illumination_smoothness_loss: 0.3890 - val_spatial_constancy_loss: 1.2393e-04 - val_color_constancy_loss: 4.3513e-04 - val_exposure_loss: 2.9589\n",
            "Epoch 6/100\n",
            "25/25 [==============================] - 548s 22s/step - total_loss: 3.3110 - illumination_smoothness_loss: 0.4378 - spatial_constancy_loss: 1.7148e-04 - color_constancy_loss: 0.0033 - exposure_loss: 2.8698 - val_total_loss: 3.2599 - val_illumination_smoothness_loss: 0.3113 - val_spatial_constancy_loss: 1.7089e-04 - val_color_constancy_loss: 4.5138e-04 - val_exposure_loss: 2.9479\n",
            "Epoch 7/100\n",
            "25/25 [==============================] - 549s 22s/step - total_loss: 3.2230 - illumination_smoothness_loss: 0.3618 - spatial_constancy_loss: 2.2729e-04 - color_constancy_loss: 0.0033 - exposure_loss: 2.8577 - val_total_loss: 3.1932 - val_illumination_smoothness_loss: 0.2553 - val_spatial_constancy_loss: 2.2336e-04 - val_color_constancy_loss: 4.6855e-04 - val_exposure_loss: 2.9372\n",
            "Epoch 8/100\n",
            "25/25 [==============================] - 543s 22s/step - total_loss: 3.1525 - illumination_smoothness_loss: 0.3032 - spatial_constancy_loss: 2.8993e-04 - color_constancy_loss: 0.0034 - exposure_loss: 2.8456 - val_total_loss: 3.1403 - val_illumination_smoothness_loss: 0.2131 - val_spatial_constancy_loss: 2.8096e-04 - val_color_constancy_loss: 4.8751e-04 - val_exposure_loss: 2.9265\n",
            "Epoch 9/100\n",
            "25/25 [==============================] - 542s 22s/step - total_loss: 3.0940 - illumination_smoothness_loss: 0.2569 - spatial_constancy_loss: 3.6052e-04 - color_constancy_loss: 0.0035 - exposure_loss: 2.8332 - val_total_loss: 3.0970 - val_illumination_smoothness_loss: 0.1809 - val_spatial_constancy_loss: 3.4871e-04 - val_color_constancy_loss: 5.0681e-04 - val_exposure_loss: 2.9152\n",
            "Epoch 10/100\n",
            "25/25 [==============================] - 546s 22s/step - total_loss: 3.0434 - illumination_smoothness_loss: 0.2196 - spatial_constancy_loss: 4.4468e-04 - color_constancy_loss: 0.0036 - exposure_loss: 2.8198 - val_total_loss: 3.0600 - val_illumination_smoothness_loss: 0.1562 - val_spatial_constancy_loss: 4.3068e-04 - val_color_constancy_loss: 5.2925e-04 - val_exposure_loss: 2.9029\n",
            "Epoch 11/100\n",
            "25/25 [==============================] - 541s 22s/step - total_loss: 2.9986 - illumination_smoothness_loss: 0.1888 - spatial_constancy_loss: 5.4310e-04 - color_constancy_loss: 0.0038 - exposure_loss: 2.8055 - val_total_loss: 3.0266 - val_illumination_smoothness_loss: 0.1359 - val_spatial_constancy_loss: 5.2808e-04 - val_color_constancy_loss: 5.5334e-04 - val_exposure_loss: 2.8896\n",
            "Epoch 12/100\n",
            "25/25 [==============================] - 546s 22s/step - total_loss: 2.9579 - illumination_smoothness_loss: 0.1636 - spatial_constancy_loss: 6.6214e-04 - color_constancy_loss: 0.0039 - exposure_loss: 2.7898 - val_total_loss: 2.9962 - val_illumination_smoothness_loss: 0.1200 - val_spatial_constancy_loss: 6.4704e-04 - val_color_constancy_loss: 5.7970e-04 - val_exposure_loss: 2.8750\n",
            "Epoch 13/100\n",
            "25/25 [==============================] - 545s 22s/step - total_loss: 2.9207 - illumination_smoothness_loss: 0.1434 - spatial_constancy_loss: 8.0827e-04 - color_constancy_loss: 0.0040 - exposure_loss: 2.7724 - val_total_loss: 2.9676 - val_illumination_smoothness_loss: 0.1077 - val_spatial_constancy_loss: 7.9513e-04 - val_color_constancy_loss: 6.0866e-04 - val_exposure_loss: 2.8586\n",
            "Epoch 14/100\n",
            "25/25 [==============================] - 543s 22s/step - total_loss: 2.8860 - illumination_smoothness_loss: 0.1281 - spatial_constancy_loss: 9.9086e-04 - color_constancy_loss: 0.0042 - exposure_loss: 2.7527 - val_total_loss: 2.9407 - val_illumination_smoothness_loss: 0.0993 - val_spatial_constancy_loss: 9.8327e-04 - val_color_constancy_loss: 6.4233e-04 - val_exposure_loss: 2.8398\n",
            "Epoch 15/100\n",
            "25/25 [==============================] - 542s 22s/step - total_loss: 2.8529 - illumination_smoothness_loss: 0.1171 - spatial_constancy_loss: 0.0012 - color_constancy_loss: 0.0044 - exposure_loss: 2.7301 - val_total_loss: 2.9147 - val_illumination_smoothness_loss: 0.0947 - val_spatial_constancy_loss: 0.0012 - val_color_constancy_loss: 6.8599e-04 - val_exposure_loss: 2.8181\n",
            "Epoch 16/100\n",
            "25/25 [==============================] - 544s 22s/step - total_loss: 2.8197 - illumination_smoothness_loss: 0.1096 - spatial_constancy_loss: 0.0015 - color_constancy_loss: 0.0047 - exposure_loss: 2.7039 - val_total_loss: 2.8875 - val_illumination_smoothness_loss: 0.0929 - val_spatial_constancy_loss: 0.0016 - val_color_constancy_loss: 7.4127e-04 - val_exposure_loss: 2.7923\n",
            "Epoch 17/100\n",
            "25/25 [==============================] - 543s 22s/step - total_loss: 2.7839 - illumination_smoothness_loss: 0.1056 - spatial_constancy_loss: 0.0019 - color_constancy_loss: 0.0050 - exposure_loss: 2.6713 - val_total_loss: 2.8566 - val_illumination_smoothness_loss: 0.0951 - val_spatial_constancy_loss: 0.0020 - val_color_constancy_loss: 8.2261e-04 - val_exposure_loss: 2.7586\n",
            "Epoch 18/100\n",
            "25/25 [==============================] - 546s 22s/step - total_loss: 2.7404 - illumination_smoothness_loss: 0.1068 - spatial_constancy_loss: 0.0026 - color_constancy_loss: 0.0056 - exposure_loss: 2.6254 - val_total_loss: 2.8160 - val_illumination_smoothness_loss: 0.1040 - val_spatial_constancy_loss: 0.0029 - val_color_constancy_loss: 9.4222e-04 - val_exposure_loss: 2.7081\n",
            "Epoch 19/100\n",
            "25/25 [==============================] - 542s 22s/step - total_loss: 2.6763 - illumination_smoothness_loss: 0.1162 - spatial_constancy_loss: 0.0041 - color_constancy_loss: 0.0064 - exposure_loss: 2.5497 - val_total_loss: 2.7472 - val_illumination_smoothness_loss: 0.1246 - val_spatial_constancy_loss: 0.0050 - val_color_constancy_loss: 0.0012 - val_exposure_loss: 2.6165\n",
            "Epoch 20/100\n",
            "25/25 [==============================] - 549s 22s/step - total_loss: 2.5384 - illumination_smoothness_loss: 0.1418 - spatial_constancy_loss: 0.0088 - color_constancy_loss: 0.0084 - exposure_loss: 2.3794 - val_total_loss: 2.5589 - val_illumination_smoothness_loss: 0.1607 - val_spatial_constancy_loss: 0.0130 - val_color_constancy_loss: 0.0019 - val_exposure_loss: 2.3834\n",
            "Epoch 21/100\n",
            "25/25 [==============================] - 550s 22s/step - total_loss: 2.0567 - illumination_smoothness_loss: 0.2068 - spatial_constancy_loss: 0.0481 - color_constancy_loss: 0.0197 - exposure_loss: 1.7822 - val_total_loss: 1.8998 - val_illumination_smoothness_loss: 0.2843 - val_spatial_constancy_loss: 0.1061 - val_color_constancy_loss: 0.0114 - val_exposure_loss: 1.4980\n",
            "Epoch 22/100\n",
            "25/25 [==============================] - 553s 22s/step - total_loss: 1.3995 - illumination_smoothness_loss: 0.2454 - spatial_constancy_loss: 0.2343 - color_constancy_loss: 0.0668 - exposure_loss: 0.8529 - val_total_loss: 1.5751 - val_illumination_smoothness_loss: 0.2012 - val_spatial_constancy_loss: 0.2207 - val_color_constancy_loss: 0.0317 - val_exposure_loss: 1.1216\n",
            "Epoch 23/100\n",
            "25/25 [==============================] - 551s 22s/step - total_loss: 1.2737 - illumination_smoothness_loss: 0.1790 - spatial_constancy_loss: 0.2638 - color_constancy_loss: 0.0721 - exposure_loss: 0.7587 - val_total_loss: 1.5275 - val_illumination_smoothness_loss: 0.1598 - val_spatial_constancy_loss: 0.2287 - val_color_constancy_loss: 0.0345 - val_exposure_loss: 1.1044\n",
            "Epoch 24/100\n",
            "25/25 [==============================] - 546s 22s/step - total_loss: 1.2487 - illumination_smoothness_loss: 0.1555 - spatial_constancy_loss: 0.2657 - color_constancy_loss: 0.0714 - exposure_loss: 0.7560 - val_total_loss: 1.5077 - val_illumination_smoothness_loss: 0.1425 - val_spatial_constancy_loss: 0.2319 - val_color_constancy_loss: 0.0352 - val_exposure_loss: 1.0981\n",
            "Epoch 25/100\n",
            "25/25 [==============================] - 548s 22s/step - total_loss: 1.2342 - illumination_smoothness_loss: 0.1434 - spatial_constancy_loss: 0.2696 - color_constancy_loss: 0.0723 - exposure_loss: 0.7489 - val_total_loss: 1.4953 - val_illumination_smoothness_loss: 0.1306 - val_spatial_constancy_loss: 0.2320 - val_color_constancy_loss: 0.0351 - val_exposure_loss: 1.0976\n",
            "Epoch 26/100\n",
            "25/25 [==============================] - 543s 22s/step - total_loss: 1.2228 - illumination_smoothness_loss: 0.1331 - spatial_constancy_loss: 0.2706 - color_constancy_loss: 0.0726 - exposure_loss: 0.7466 - val_total_loss: 1.4861 - val_illumination_smoothness_loss: 0.1210 - val_spatial_constancy_loss: 0.2322 - val_color_constancy_loss: 0.0361 - val_exposure_loss: 1.0968\n",
            "Epoch 27/100\n",
            "25/25 [==============================] - 537s 22s/step - total_loss: 1.2138 - illumination_smoothness_loss: 0.1252 - spatial_constancy_loss: 0.2725 - color_constancy_loss: 0.0729 - exposure_loss: 0.7432 - val_total_loss: 1.4776 - val_illumination_smoothness_loss: 0.1138 - val_spatial_constancy_loss: 0.2329 - val_color_constancy_loss: 0.0356 - val_exposure_loss: 1.0953\n",
            "Epoch 28/100\n",
            "25/25 [==============================] - 539s 22s/step - total_loss: 1.2083 - illumination_smoothness_loss: 0.1204 - spatial_constancy_loss: 0.2731 - color_constancy_loss: 0.0731 - exposure_loss: 0.7417 - val_total_loss: 1.4713 - val_illumination_smoothness_loss: 0.1070 - val_spatial_constancy_loss: 0.2325 - val_color_constancy_loss: 0.0363 - val_exposure_loss: 1.0956\n",
            "Epoch 29/100\n",
            "25/25 [==============================] - 542s 22s/step - total_loss: 1.2032 - illumination_smoothness_loss: 0.1152 - spatial_constancy_loss: 0.2741 - color_constancy_loss: 0.0732 - exposure_loss: 0.7407 - val_total_loss: 1.4641 - val_illumination_smoothness_loss: 0.1030 - val_spatial_constancy_loss: 0.2361 - val_color_constancy_loss: 0.0366 - val_exposure_loss: 1.0885\n",
            "Epoch 30/100\n",
            "25/25 [==============================] - 542s 22s/step - total_loss: 1.1994 - illumination_smoothness_loss: 0.1107 - spatial_constancy_loss: 0.2752 - color_constancy_loss: 0.0735 - exposure_loss: 0.7400 - val_total_loss: 1.4590 - val_illumination_smoothness_loss: 0.1013 - val_spatial_constancy_loss: 0.2411 - val_color_constancy_loss: 0.0381 - val_exposure_loss: 1.0785\n",
            "Epoch 31/100\n",
            "25/25 [==============================] - 540s 22s/step - total_loss: 1.1944 - illumination_smoothness_loss: 0.1049 - spatial_constancy_loss: 0.2765 - color_constancy_loss: 0.0738 - exposure_loss: 0.7392 - val_total_loss: 1.4587 - val_illumination_smoothness_loss: 0.1024 - val_spatial_constancy_loss: 0.2435 - val_color_constancy_loss: 0.0390 - val_exposure_loss: 1.0737\n",
            "Epoch 32/100\n",
            "25/25 [==============================] - 539s 22s/step - total_loss: 1.1879 - illumination_smoothness_loss: 0.0979 - spatial_constancy_loss: 0.2771 - color_constancy_loss: 0.0736 - exposure_loss: 0.7393 - val_total_loss: 1.4589 - val_illumination_smoothness_loss: 0.1052 - val_spatial_constancy_loss: 0.2471 - val_color_constancy_loss: 0.0398 - val_exposure_loss: 1.0668\n",
            "Epoch 33/100\n",
            "25/25 [==============================] - 545s 22s/step - total_loss: 1.1801 - illumination_smoothness_loss: 0.0911 - spatial_constancy_loss: 0.2784 - color_constancy_loss: 0.0739 - exposure_loss: 0.7368 - val_total_loss: 1.4524 - val_illumination_smoothness_loss: 0.0995 - val_spatial_constancy_loss: 0.2481 - val_color_constancy_loss: 0.0399 - val_exposure_loss: 1.0648\n",
            "Epoch 34/100\n",
            "25/25 [==============================] - 542s 22s/step - total_loss: 1.1741 - illumination_smoothness_loss: 0.0863 - spatial_constancy_loss: 0.2799 - color_constancy_loss: 0.0743 - exposure_loss: 0.7335 - val_total_loss: 1.4453 - val_illumination_smoothness_loss: 0.0929 - val_spatial_constancy_loss: 0.2483 - val_color_constancy_loss: 0.0398 - val_exposure_loss: 1.0642\n",
            "Epoch 35/100\n",
            "25/25 [==============================] - 542s 22s/step - total_loss: 1.1700 - illumination_smoothness_loss: 0.0824 - spatial_constancy_loss: 0.2805 - color_constancy_loss: 0.0743 - exposure_loss: 0.7329 - val_total_loss: 1.4436 - val_illumination_smoothness_loss: 0.0922 - val_spatial_constancy_loss: 0.2498 - val_color_constancy_loss: 0.0402 - val_exposure_loss: 1.0613\n",
            "Epoch 36/100\n",
            "25/25 [==============================] - 539s 22s/step - total_loss: 1.1643 - illumination_smoothness_loss: 0.0769 - spatial_constancy_loss: 0.2814 - color_constancy_loss: 0.0745 - exposure_loss: 0.7316 - val_total_loss: 1.4367 - val_illumination_smoothness_loss: 0.0854 - val_spatial_constancy_loss: 0.2493 - val_color_constancy_loss: 0.0400 - val_exposure_loss: 1.0620\n",
            "Epoch 37/100\n",
            "25/25 [==============================] - 542s 22s/step - total_loss: 1.1604 - illumination_smoothness_loss: 0.0736 - spatial_constancy_loss: 0.2823 - color_constancy_loss: 0.0747 - exposure_loss: 0.7298 - val_total_loss: 1.4324 - val_illumination_smoothness_loss: 0.0825 - val_spatial_constancy_loss: 0.2515 - val_color_constancy_loss: 0.0405 - val_exposure_loss: 1.0579\n",
            "Epoch 38/100\n",
            "25/25 [==============================] - 541s 22s/step - total_loss: 1.1559 - illumination_smoothness_loss: 0.0696 - spatial_constancy_loss: 0.2837 - color_constancy_loss: 0.0749 - exposure_loss: 0.7276 - val_total_loss: 1.4285 - val_illumination_smoothness_loss: 0.0790 - val_spatial_constancy_loss: 0.2517 - val_color_constancy_loss: 0.0404 - val_exposure_loss: 1.0573\n",
            "Epoch 39/100\n",
            "25/25 [==============================] - 539s 22s/step - total_loss: 1.1529 - illumination_smoothness_loss: 0.0669 - spatial_constancy_loss: 0.2843 - color_constancy_loss: 0.0751 - exposure_loss: 0.7266 - val_total_loss: 1.4242 - val_illumination_smoothness_loss: 0.0752 - val_spatial_constancy_loss: 0.2524 - val_color_constancy_loss: 0.0407 - val_exposure_loss: 1.0559\n",
            "Epoch 40/100\n",
            "25/25 [==============================] - 541s 22s/step - total_loss: 1.1493 - illumination_smoothness_loss: 0.0636 - spatial_constancy_loss: 0.2851 - color_constancy_loss: 0.0752 - exposure_loss: 0.7253 - val_total_loss: 1.4209 - val_illumination_smoothness_loss: 0.0719 - val_spatial_constancy_loss: 0.2521 - val_color_constancy_loss: 0.0406 - val_exposure_loss: 1.0562\n",
            "Epoch 41/100\n",
            "25/25 [==============================] - 542s 22s/step - total_loss: 1.1463 - illumination_smoothness_loss: 0.0606 - spatial_constancy_loss: 0.2853 - color_constancy_loss: 0.0753 - exposure_loss: 0.7252 - val_total_loss: 1.4172 - val_illumination_smoothness_loss: 0.0693 - val_spatial_constancy_loss: 0.2536 - val_color_constancy_loss: 0.0409 - val_exposure_loss: 1.0535\n",
            "Epoch 42/100\n",
            "25/25 [==============================] - 541s 22s/step - total_loss: 1.1429 - illumination_smoothness_loss: 0.0574 - spatial_constancy_loss: 0.2865 - color_constancy_loss: 0.0755 - exposure_loss: 0.7234 - val_total_loss: 1.4142 - val_illumination_smoothness_loss: 0.0661 - val_spatial_constancy_loss: 0.2531 - val_color_constancy_loss: 0.0409 - val_exposure_loss: 1.0541\n",
            "Epoch 43/100\n",
            "25/25 [==============================] - 539s 21s/step - total_loss: 1.1403 - illumination_smoothness_loss: 0.0552 - spatial_constancy_loss: 0.2867 - color_constancy_loss: 0.0756 - exposure_loss: 0.7229 - val_total_loss: 1.4103 - val_illumination_smoothness_loss: 0.0633 - val_spatial_constancy_loss: 0.2545 - val_color_constancy_loss: 0.0410 - val_exposure_loss: 1.0515\n",
            "Epoch 44/100\n",
            "25/25 [==============================] - 542s 22s/step - total_loss: 1.1371 - illumination_smoothness_loss: 0.0522 - spatial_constancy_loss: 0.2881 - color_constancy_loss: 0.0758 - exposure_loss: 0.7211 - val_total_loss: 1.4078 - val_illumination_smoothness_loss: 0.0603 - val_spatial_constancy_loss: 0.2534 - val_color_constancy_loss: 0.0408 - val_exposure_loss: 1.0533\n",
            "Epoch 45/100\n",
            "25/25 [==============================] - 540s 22s/step - total_loss: 1.1349 - illumination_smoothness_loss: 0.0504 - spatial_constancy_loss: 0.2872 - color_constancy_loss: 0.0757 - exposure_loss: 0.7217 - val_total_loss: 1.4043 - val_illumination_smoothness_loss: 0.0581 - val_spatial_constancy_loss: 0.2556 - val_color_constancy_loss: 0.0414 - val_exposure_loss: 1.0492\n",
            "Epoch 46/100\n",
            "25/25 [==============================] - 539s 22s/step - total_loss: 1.1320 - illumination_smoothness_loss: 0.0478 - spatial_constancy_loss: 0.2896 - color_constancy_loss: 0.0760 - exposure_loss: 0.7187 - val_total_loss: 1.4010 - val_illumination_smoothness_loss: 0.0539 - val_spatial_constancy_loss: 0.2533 - val_color_constancy_loss: 0.0408 - val_exposure_loss: 1.0531\n",
            "Epoch 47/100\n",
            "25/25 [==============================] - 539s 22s/step - total_loss: 1.1304 - illumination_smoothness_loss: 0.0462 - spatial_constancy_loss: 0.2880 - color_constancy_loss: 0.0759 - exposure_loss: 0.7203 - val_total_loss: 1.3983 - val_illumination_smoothness_loss: 0.0530 - val_spatial_constancy_loss: 0.2568 - val_color_constancy_loss: 0.0416 - val_exposure_loss: 1.0468\n",
            "Epoch 48/100\n",
            "25/25 [==============================] - 540s 22s/step - total_loss: 1.1277 - illumination_smoothness_loss: 0.0439 - spatial_constancy_loss: 0.2908 - color_constancy_loss: 0.0762 - exposure_loss: 0.7168 - val_total_loss: 1.3970 - val_illumination_smoothness_loss: 0.0505 - val_spatial_constancy_loss: 0.2539 - val_color_constancy_loss: 0.0409 - val_exposure_loss: 1.0517\n",
            "Epoch 49/100\n",
            "25/25 [==============================] - 540s 22s/step - total_loss: 1.1260 - illumination_smoothness_loss: 0.0421 - spatial_constancy_loss: 0.2887 - color_constancy_loss: 0.0760 - exposure_loss: 0.7191 - val_total_loss: 1.3944 - val_illumination_smoothness_loss: 0.0496 - val_spatial_constancy_loss: 0.2568 - val_color_constancy_loss: 0.0416 - val_exposure_loss: 1.0464\n",
            "Epoch 50/100\n",
            "25/25 [==============================] - 548s 22s/step - total_loss: 1.1230 - illumination_smoothness_loss: 0.0388 - spatial_constancy_loss: 0.2910 - color_constancy_loss: 0.0762 - exposure_loss: 0.7170 - val_total_loss: 1.3918 - val_illumination_smoothness_loss: 0.0471 - val_spatial_constancy_loss: 0.2564 - val_color_constancy_loss: 0.0413 - val_exposure_loss: 1.0470\n",
            "Epoch 51/100\n",
            "25/25 [==============================] - 540s 22s/step - total_loss: 1.1214 - illumination_smoothness_loss: 0.0379 - spatial_constancy_loss: 0.2911 - color_constancy_loss: 0.0765 - exposure_loss: 0.7159 - val_total_loss: 1.3911 - val_illumination_smoothness_loss: 0.0472 - val_spatial_constancy_loss: 0.2581 - val_color_constancy_loss: 0.0418 - val_exposure_loss: 1.0439\n",
            "Epoch 52/100\n",
            "25/25 [==============================] - 550s 22s/step - total_loss: 1.1192 - illumination_smoothness_loss: 0.0357 - spatial_constancy_loss: 0.2912 - color_constancy_loss: 0.0763 - exposure_loss: 0.7159 - val_total_loss: 1.3884 - val_illumination_smoothness_loss: 0.0446 - val_spatial_constancy_loss: 0.2576 - val_color_constancy_loss: 0.0416 - val_exposure_loss: 1.0447\n",
            "Epoch 53/100\n",
            "25/25 [==============================] - 550s 22s/step - total_loss: 1.1176 - illumination_smoothness_loss: 0.0344 - spatial_constancy_loss: 0.2918 - color_constancy_loss: 0.0764 - exposure_loss: 0.7149 - val_total_loss: 1.3865 - val_illumination_smoothness_loss: 0.0426 - val_spatial_constancy_loss: 0.2571 - val_color_constancy_loss: 0.0414 - val_exposure_loss: 1.0453\n",
            "Epoch 54/100\n",
            "25/25 [==============================] - 555s 22s/step - total_loss: 1.1162 - illumination_smoothness_loss: 0.0331 - spatial_constancy_loss: 0.2919 - color_constancy_loss: 0.0765 - exposure_loss: 0.7147 - val_total_loss: 1.3829 - val_illumination_smoothness_loss: 0.0395 - val_spatial_constancy_loss: 0.2580 - val_color_constancy_loss: 0.0418 - val_exposure_loss: 1.0436\n",
            "Epoch 55/100\n",
            "25/25 [==============================] - 555s 22s/step - total_loss: 1.1151 - illumination_smoothness_loss: 0.0326 - spatial_constancy_loss: 0.2934 - color_constancy_loss: 0.0768 - exposure_loss: 0.7123 - val_total_loss: 1.3836 - val_illumination_smoothness_loss: 0.0407 - val_spatial_constancy_loss: 0.2590 - val_color_constancy_loss: 0.0421 - val_exposure_loss: 1.0418\n",
            "Epoch 56/100\n",
            "25/25 [==============================] - 544s 22s/step - total_loss: 1.1128 - illumination_smoothness_loss: 0.0302 - spatial_constancy_loss: 0.2926 - color_constancy_loss: 0.0765 - exposure_loss: 0.7135 - val_total_loss: 1.3800 - val_illumination_smoothness_loss: 0.0370 - val_spatial_constancy_loss: 0.2582 - val_color_constancy_loss: 0.0419 - val_exposure_loss: 1.0428\n",
            "Epoch 57/100\n",
            "25/25 [==============================] - 553s 22s/step - total_loss: 1.1114 - illumination_smoothness_loss: 0.0289 - spatial_constancy_loss: 0.2935 - color_constancy_loss: 0.0768 - exposure_loss: 0.7123 - val_total_loss: 1.3798 - val_illumination_smoothness_loss: 0.0370 - val_spatial_constancy_loss: 0.2585 - val_color_constancy_loss: 0.0420 - val_exposure_loss: 1.0423\n",
            "Epoch 58/100\n",
            "25/25 [==============================] - 546s 22s/step - total_loss: 1.1098 - illumination_smoothness_loss: 0.0273 - spatial_constancy_loss: 0.2944 - color_constancy_loss: 0.0768 - exposure_loss: 0.7113 - val_total_loss: 1.3756 - val_illumination_smoothness_loss: 0.0329 - val_spatial_constancy_loss: 0.2578 - val_color_constancy_loss: 0.0415 - val_exposure_loss: 1.0435\n",
            "Epoch 59/100\n",
            "25/25 [==============================] - 553s 22s/step - total_loss: 1.1096 - illumination_smoothness_loss: 0.0272 - spatial_constancy_loss: 0.2941 - color_constancy_loss: 0.0769 - exposure_loss: 0.7115 - val_total_loss: 1.3774 - val_illumination_smoothness_loss: 0.0354 - val_spatial_constancy_loss: 0.2594 - val_color_constancy_loss: 0.0420 - val_exposure_loss: 1.0405\n",
            "Epoch 60/100\n",
            "25/25 [==============================] - 550s 22s/step - total_loss: 1.1080 - illumination_smoothness_loss: 0.0261 - spatial_constancy_loss: 0.2943 - color_constancy_loss: 0.0769 - exposure_loss: 0.7107 - val_total_loss: 1.3757 - val_illumination_smoothness_loss: 0.0335 - val_spatial_constancy_loss: 0.2583 - val_color_constancy_loss: 0.0417 - val_exposure_loss: 1.0422\n",
            "Epoch 61/100\n",
            "25/25 [==============================] - 546s 22s/step - total_loss: 1.1066 - illumination_smoothness_loss: 0.0243 - spatial_constancy_loss: 0.2942 - color_constancy_loss: 0.0769 - exposure_loss: 0.7112 - val_total_loss: 1.3743 - val_illumination_smoothness_loss: 0.0334 - val_spatial_constancy_loss: 0.2608 - val_color_constancy_loss: 0.0423 - val_exposure_loss: 1.0378\n",
            "Epoch 62/100\n",
            "25/25 [==============================] - 547s 22s/step - total_loss: 1.1048 - illumination_smoothness_loss: 0.0236 - spatial_constancy_loss: 0.2952 - color_constancy_loss: 0.0772 - exposure_loss: 0.7089 - val_total_loss: 1.3715 - val_illumination_smoothness_loss: 0.0302 - val_spatial_constancy_loss: 0.2600 - val_color_constancy_loss: 0.0423 - val_exposure_loss: 1.0390\n",
            "Epoch 63/100\n",
            "25/25 [==============================] - 546s 22s/step - total_loss: 1.1043 - illumination_smoothness_loss: 0.0224 - spatial_constancy_loss: 0.2951 - color_constancy_loss: 0.0771 - exposure_loss: 0.7097 - val_total_loss: 1.3725 - val_illumination_smoothness_loss: 0.0322 - val_spatial_constancy_loss: 0.2618 - val_color_constancy_loss: 0.0426 - val_exposure_loss: 1.0359\n",
            "Epoch 64/100\n",
            "25/25 [==============================] - 546s 22s/step - total_loss: 1.1030 - illumination_smoothness_loss: 0.0218 - spatial_constancy_loss: 0.2958 - color_constancy_loss: 0.0773 - exposure_loss: 0.7081 - val_total_loss: 1.3697 - val_illumination_smoothness_loss: 0.0293 - val_spatial_constancy_loss: 0.2613 - val_color_constancy_loss: 0.0426 - val_exposure_loss: 1.0366\n",
            "Epoch 65/100\n",
            "25/25 [==============================] - 543s 22s/step - total_loss: 1.1025 - illumination_smoothness_loss: 0.0206 - spatial_constancy_loss: 0.2968 - color_constancy_loss: 0.0773 - exposure_loss: 0.7077 - val_total_loss: 1.3688 - val_illumination_smoothness_loss: 0.0273 - val_spatial_constancy_loss: 0.2589 - val_color_constancy_loss: 0.0421 - val_exposure_loss: 1.0405\n",
            "Epoch 66/100\n",
            "25/25 [==============================] - 545s 22s/step - total_loss: 1.1014 - illumination_smoothness_loss: 0.0200 - spatial_constancy_loss: 0.2951 - color_constancy_loss: 0.0771 - exposure_loss: 0.7093 - val_total_loss: 1.3681 - val_illumination_smoothness_loss: 0.0276 - val_spatial_constancy_loss: 0.2599 - val_color_constancy_loss: 0.0419 - val_exposure_loss: 1.0387\n",
            "Epoch 67/100\n",
            "25/25 [==============================] - 538s 22s/step - total_loss: 1.1007 - illumination_smoothness_loss: 0.0191 - spatial_constancy_loss: 0.2964 - color_constancy_loss: 0.0774 - exposure_loss: 0.7078 - val_total_loss: 1.3672 - val_illumination_smoothness_loss: 0.0275 - val_spatial_constancy_loss: 0.2618 - val_color_constancy_loss: 0.0426 - val_exposure_loss: 1.0354\n",
            "Epoch 68/100\n",
            "25/25 [==============================] - 544s 22s/step - total_loss: 1.0991 - illumination_smoothness_loss: 0.0183 - spatial_constancy_loss: 0.2968 - color_constancy_loss: 0.0775 - exposure_loss: 0.7065 - val_total_loss: 1.3662 - val_illumination_smoothness_loss: 0.0263 - val_spatial_constancy_loss: 0.2614 - val_color_constancy_loss: 0.0427 - val_exposure_loss: 1.0358\n",
            "Epoch 69/100\n",
            "25/25 [==============================] - 544s 22s/step - total_loss: 1.0987 - illumination_smoothness_loss: 0.0177 - spatial_constancy_loss: 0.2967 - color_constancy_loss: 0.0774 - exposure_loss: 0.7068 - val_total_loss: 1.3652 - val_illumination_smoothness_loss: 0.0259 - val_spatial_constancy_loss: 0.2624 - val_color_constancy_loss: 0.0429 - val_exposure_loss: 1.0340\n",
            "Epoch 70/100\n",
            "25/25 [==============================] - 542s 22s/step - total_loss: 1.0978 - illumination_smoothness_loss: 0.0173 - spatial_constancy_loss: 0.2971 - color_constancy_loss: 0.0775 - exposure_loss: 0.7059 - val_total_loss: 1.3647 - val_illumination_smoothness_loss: 0.0255 - val_spatial_constancy_loss: 0.2625 - val_color_constancy_loss: 0.0430 - val_exposure_loss: 1.0337\n",
            "Epoch 71/100\n",
            "25/25 [==============================] - 543s 22s/step - total_loss: 1.0974 - illumination_smoothness_loss: 0.0165 - spatial_constancy_loss: 0.2975 - color_constancy_loss: 0.0776 - exposure_loss: 0.7059 - val_total_loss: 1.3646 - val_illumination_smoothness_loss: 0.0253 - val_spatial_constancy_loss: 0.2620 - val_color_constancy_loss: 0.0429 - val_exposure_loss: 1.0344\n",
            "Epoch 72/100\n",
            "25/25 [==============================] - 541s 22s/step - total_loss: 1.0966 - illumination_smoothness_loss: 0.0160 - spatial_constancy_loss: 0.2973 - color_constancy_loss: 0.0775 - exposure_loss: 0.7057 - val_total_loss: 1.3633 - val_illumination_smoothness_loss: 0.0243 - val_spatial_constancy_loss: 0.2622 - val_color_constancy_loss: 0.0428 - val_exposure_loss: 1.0339\n",
            "Epoch 73/100\n",
            "25/25 [==============================] - 541s 22s/step - total_loss: 1.0962 - illumination_smoothness_loss: 0.0153 - spatial_constancy_loss: 0.2976 - color_constancy_loss: 0.0775 - exposure_loss: 0.7057 - val_total_loss: 1.3624 - val_illumination_smoothness_loss: 0.0235 - val_spatial_constancy_loss: 0.2620 - val_color_constancy_loss: 0.0428 - val_exposure_loss: 1.0341\n",
            "Epoch 74/100\n",
            "25/25 [==============================] - 546s 22s/step - total_loss: 1.0958 - illumination_smoothness_loss: 0.0152 - spatial_constancy_loss: 0.2974 - color_constancy_loss: 0.0776 - exposure_loss: 0.7056 - val_total_loss: 1.3620 - val_illumination_smoothness_loss: 0.0232 - val_spatial_constancy_loss: 0.2620 - val_color_constancy_loss: 0.0427 - val_exposure_loss: 1.0341\n",
            "Epoch 75/100\n",
            "25/25 [==============================] - 532s 21s/step - total_loss: 1.0953 - illumination_smoothness_loss: 0.0149 - spatial_constancy_loss: 0.2979 - color_constancy_loss: 0.0776 - exposure_loss: 0.7049 - val_total_loss: 1.3619 - val_illumination_smoothness_loss: 0.0235 - val_spatial_constancy_loss: 0.2630 - val_color_constancy_loss: 0.0432 - val_exposure_loss: 1.0322\n",
            "Epoch 76/100\n",
            "13/25 [==============>...............] - ETA: 4:04 - total_loss: 1.2275 - illumination_smoothness_loss: 0.0125 - spatial_constancy_loss: 0.2656 - color_constancy_loss: 0.0972 - exposure_loss: 0.8522"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hojajapEUGiR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}