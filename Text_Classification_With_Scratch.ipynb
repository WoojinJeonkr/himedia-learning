{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_Classification_With_Scratch.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMY9CpfMsBwjD5vo846IVBR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WoojinJeonkr/DeepLearning/blob/main/Text_Classification_With_Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scratch를 통한 텍스트 분류\n",
        "- 내용 출처: https://keras.io/examples/nlp/text_classification_from_scratch/"
      ],
      "metadata": {
        "id": "ORGwdQl3j5F_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 01. 라이브러리 설정"
      ],
      "metadata": {
        "id": "Pr2zOxaLkUpc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TeoLXOTvjjYr"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 02. 데이터 다운로드 및 확인\n",
        "- 사용 데이터: [IMDB 영화 리뷰](ttps://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz)"
      ],
      "metadata": {
        "id": "Y98qq62OkaHy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 다운로드\n",
        "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xf aclImdb_v1.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C06oUOfOkYxb",
        "outputId": "80275bb3-93ed-4990-e808-6098f3f8601b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  18.3M      0  0:00:04  0:00:04 --:--:-- 18.3M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 폴더 생성(train 데이터와 test 데이터 나누기)\n",
        "!ls aclImdb\n",
        "!ls aclImdb/test\n",
        "!ls aclImdb/train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_UiygwmlF2P",
        "outputId": "dfd755ae-672c-459a-ca6a-cfc6d4a7bfa6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "imdbEr.txt  imdb.vocab\tREADME\ttest  train\n",
            "labeledBow.feat  neg  pos  urls_neg.txt  urls_pos.txt\n",
            "labeledBow.feat  pos\tunsupBow.feat  urls_pos.txt\n",
            "neg\t\t unsup\turls_neg.txt   urls_unsup.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 임의의 데이터 출력\n",
        "!cat aclImdb/train/pos/6248_7.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0yqOZEElTGr",
        "outputId": "e3e42607-ba00-41c0-a0f5-8b5c7e481bc6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Being an Austrian myself this has been a straight knock in my face. Fortunately I don't live nowhere near the place where this movie takes place but unfortunately it portrays everything that the rest of Austria hates about Viennese people (or people close to that region). And it is very easy to read that this is exactly the directors intention: to let your head sink into your hands and say \"Oh my god, how can THAT be possible!\". No, not with me, the (in my opinion) totally exaggerated uncensored swinger club scene is not necessary, I watch porn, sure, but in this context I was rather disgusted than put in the right context.<br /><br />This movie tells a story about how misled people who suffer from lack of education or bad company try to survive and live in a world of redundancy and boring horizons. A girl who is treated like a whore by her super-jealous boyfriend (and still keeps coming back), a female teacher who discovers her masochism by putting the life of her super-cruel \"lover\" on the line, an old couple who has an almost mathematical daily cycle (she is the \"official replacement\" of his ex wife), a couple that has just divorced and has the ex husband suffer under the acts of his former wife obviously having a relationship with her masseuse and finally a crazy hitchhiker who asks her drivers the most unusual questions and stretches their nerves by just being super-annoying.<br /><br />After having seen it you feel almost nothing. You're not even shocked, sad, depressed or feel like doing anything... Maybe that's why I gave it 7 points, it made me react in a way I never reacted before. If that's good or bad is up to you!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 설정\n",
        "batch_size = 32\n",
        "raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    \"aclImdb/train\",\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=1337,\n",
        ")\n",
        "raw_val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    \"aclImdb/train\",\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=1337,\n",
        ")\n",
        "raw_test_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    \"aclImdb/test\", batch_size=batch_size\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38YaSFNolZOf",
        "outputId": "4c1943d2-332d-46c1-a1e7-6045604247b6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 75000 files belonging to 3 classes.\n",
            "Using 60000 files for training.\n",
            "Found 75000 files belonging to 3 classes.\n",
            "Using 15000 files for validation.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of batches in raw_train_ds: {raw_train_ds.cardinality()}\")\n",
        "print(f\"Number of batches in raw_val_ds: {raw_val_ds.cardinality()}\")\n",
        "print(f\"Number of batches in raw_test_ds: {raw_test_ds.cardinality()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMAHZhqjljUW",
        "outputId": "653bcb99-ce5e-4d6f-f14a-dc698fc4f295"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of batches in raw_train_ds: 1875\n",
            "Number of batches in raw_val_ds: 469\n",
            "Number of batches in raw_test_ds: 782\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 확인하기\n",
        "for text_batch, label_batch in raw_train_ds.take(1):\n",
        "    for i in range(5):\n",
        "        print(text_batch.numpy()[i])\n",
        "        print(label_batch.numpy()[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPNFUBYul-8N",
        "outputId": "f54c6a93-14f5-430e-a7c1-9bf3d52b4d9f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'SPOILERS: We sit through ten minutes of AWFUL clich\\xc3\\xa9d dialog at the beginning from two completely unoriginal characters with bad twangs (ripped off from Kalifornia and Natural Born Killers - there isn\\'t an original thing about these two) and you\\'re going \"either they\\'re about to kill everyone in the diner or already have\" and lo and behold guess what happens.<br /><br />I can\\'t stand all the Tarantino wannabes out there and this guy is one of the worst. I got maybe 25-30 minutes into the thing when I just couldn\\'t take it and stopped watching. Miner\\'s really bad acting was unbearable - I couldn\\'t take it. That, and the terrible script. After reading some of these comments I see there was a big twist - well guess what? No one cares. When you create completely uninteresting, unoriginal and unlikeable character like these two clich\\xc3\\xa9s, no one cares what big \"twist\" may have happened. I hope this is the end of these types of movies.'\n",
            "2\n",
            "b'This movie is horrible- in a \\'so bad it\\'s good\\' kind of way.<br /><br />The storyline is rehashed from so many other films of this kind, that I\\'m not going to even bother describing it. It\\'s a sword/sorcery picture, has a kid hoping to realize how important he is in this world, has a \"nomadic\" adventurer, an evil aide/sorcerer, a princess, a hairy creature....you get the point.<br /><br />The first time I caught this movie was during a very harsh winter. I don\\'t know why I decided to continue watching it for an extra five minutes before turning the channel, but when I caught site of Gulfax, I decided to stay and watch it until the end.<br /><br />Gulfax is a white, furry creature akin to Chewbacca, but not nearly as useful or entertaining to watch. He looks like someone glued a bunch of white shag carpeting together and forced the actor to wear it. There are scenes where it looks like the actor cannot move within, or that he\\'s almost falling over. Although he isn\\'t in the movie that much, the few scenes are worth it! Watch as he attempts to talk smack to Bo Svenson, taking the Solo-Chewbacca comparison\\'s to an even higher level! <br /><br />I actually bought this movie just because of that character, and still have it somewhere! <br /><br />Gulfax may look like sh!t, but he made this movie!!! The only reason I\\'ve never seen the sequel, or even sought it out, was because of his absence! Perhaps should there be a final film, completing the trilogy, Gulfax will make a much-anticipated return!'\n",
            "1\n",
            "b\"Pierce Brosnan has sipped his last Martini and returns, in an outrageous self-parody, as the aging foul-mouthed boozy assassin Julian Noble, who has a particular fondness for teenage girls, bullfights and tacky clothes. During a job in Mexico City he meets Danny (Greg Kinnear), a straight-faced Denver suburban business-man, who's in town to make his deal of-a-life-time, in a hotel bar. Despite their completely different personalities and Julian's crude and insensible remarks, they become friends. <br /><br />Largely carried by the performances of Pierce Brosnan and Greg Kinnear, director Richard Shepard revealed that he didn't write the film with Pierce Brosnan in mind , but I can hardly imagine this without him. He proves to have a real talent for comedy and can be more than just James Bond or cold-war spies. The scene in which the two meet at a glossy hotel bar (stunning sets and beautifully photographed) really is a bravura piece of acting skills. The scene lasts almost fifteen minutes, and although it was probably carefully scripted, the two actors are largely improvising, but they succeed wonderfully! It almost feels like a new standard in screen acting. Think of Robert De Niro and Harvey Keitel in MEAN STEETS improvising and add one of the most subtle underpinnings of many genre clich\\xc3\\xa9s and the actors' own typecasting (Brosnan's James Bond in particular), and you got one of the most delightful pairings in recent Hollywood. <br /><br />Sadly, the story wears thin after a while. After an hour, the film just runs out of steam. Nevertheless, and I can't put my finger on it exactly, I did enjoy this very much. It just feels very fresh and original, with some imaginative use of sets and lighting, and some hints to Seijun Suzuki and Jean-Pierre Melville. The other characters aren't given much to do, but this film does offer something new, in that respect it almost effortlessly succeeds in blending all conventional genres into quite an entertaining spoof. Very amusing.<br /><br />Camera Obscura --- 7/10\"\n",
            "1\n",
            "b\"I hadn't seen this show until it was repeated on Dave. I became aware of it after seeing The Comedy Store Players, a group of comedians which includes Josie Lawrence.<br /><br />I enjoy the unpredictability of Whose Line is it Anyway and the diversity of the performers. The fact that the show had both English and American comedians made it better.<br /><br />The best performance ever had to be when Josie Lawrence and Caroline Quentin sung a duet about a beached whale. Admitedly that description may not sound funny, but if you've seen it you'll know how good it was.<br /><br />Colin Mochrie and Ryan Stiles were a great double act. They were particularly good at the round where they were given two completely random lines to incorporate into a sketch.<br /><br />Other improv shows such as Mock The Week are good, but Whose Line is it Anyway will always be the king of Improvised Comedy shows\"\n",
            "2\n",
            "b'This film, directed by New World Pictures alumnus Jonathan Kaplan and starring cult favorite Aimee Graham, is part of the \"Rebel Highway\" series of remakes of 1950s juvenile-delinquent films.<br /><br />For what was basically a chance for the filmmakers to have fun, _Reform School Girl_ is quite watchable. There are the allusions to McCarthyism characteristic of the \"Rebel Highway\" series (and a well-done general 50s ambiance), and the usual array of interesting types we meet in women-in-prison films. This one is nowhere near as graphic as a typical entry in that genre, but there is one lesbian love scene that is strikingly filmed and acted, suprisingly graphic for such young-looking actresses, and really kind of a tonal shift from the rest of the film. Unfortunately, the film never really resolves the lesbian relationship.<br /><br />The only time I really cringed was the scene where Donna (Aimee Graham) started dancing and singing with the mop, and the camera began moving around and getting in the faces of the onlookers. This was a totally ridiculous scene (but I guess it\\'s hard to pad these things out to 80 minutes).<br /><br />Graham is stellar in the title role, a girl who has had to deal with abuse and, while in reform school, awakens to more positive sexual experiences. I really wish Hollywood would take more notice of her.'\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 03. 데이터 전처리"
      ],
      "metadata": {
        "id": "xSJPjCagmJqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import TextVectorization\n",
        "import string\n",
        "import re"
      ],
      "metadata": {
        "id": "i5IOPvzumDWK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_standardization(input_data):\n",
        "    lowercase = tf.strings.lower(input_data)\n",
        "    stripped_html = tf.strings.regex_replace(lowercase, \"<br />\", \" \")\n",
        "    return tf.strings.regex_replace(\n",
        "        stripped_html, f\"[{re.escape(string.punctuation)}]\", \"\"\n",
        "    )"
      ],
      "metadata": {
        "id": "t5I8FfjomNao"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 설정\n",
        "max_features = 20000\n",
        "embedding_dim = 128\n",
        "sequence_length = 500"
      ],
      "metadata": {
        "id": "7mvXPfrhmPW7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vecorize_layer 정의\n",
        "vectorize_layer = TextVectorization(\n",
        "    standardize=custom_standardization,\n",
        "    max_tokens=max_features,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length,\n",
        ")"
      ],
      "metadata": {
        "id": "kpVnH0ermR86"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 오직 text로만 이루어진 데이터 생성\n",
        "text_ds = raw_train_ds.map(lambda x, y: x)"
      ],
      "metadata": {
        "id": "siXtHU8mmXxl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 적용\n",
        "vectorize_layer.adapt(text_ds)"
      ],
      "metadata": {
        "id": "AXypugRZmeT8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 04. 데이터 벡터화"
      ],
      "metadata": {
        "id": "uU64gCJWmtXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize_text(text, label):\n",
        "    text = tf.expand_dims(text, -1)\n",
        "    return vectorize_layer(text), label\n",
        "\n",
        "train_ds = raw_train_ds.map(vectorize_text)\n",
        "val_ds = raw_val_ds.map(vectorize_text)\n",
        "test_ds = raw_test_ds.map(vectorize_text)\n",
        "\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=10)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=10)\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=10)"
      ],
      "metadata": {
        "id": "xHemA0NjmgRH"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 05. 모델 설계"
      ],
      "metadata": {
        "id": "BfZUqplMm5ea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "NzY6oUVqmwam"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력층 설계\n",
        "inputs = tf.keras.Input(shape=(None,), dtype=\"int64\")\n",
        "\n",
        "# 층 쌓기\n",
        "x = layers.Embedding(max_features, embedding_dim)(inputs)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "\n",
        "x = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
        "x = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "\n",
        "x = layers.Dense(128, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "\n",
        "predictions = layers.Dense(1, activation=\"sigmoid\", name=\"predictions\")(x)\n",
        "\n",
        "# 모델 정의\n",
        "model = tf.keras.Model(inputs, predictions)\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "aUNBLByxm9XL"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 06. 모델 훈련"
      ],
      "metadata": {
        "id": "7HDic-wsnPhp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "\n",
        "model.fit(train_ds, validation_data=val_ds, epochs=epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjFOG9CnnN4W",
        "outputId": "d5188c00-73e7-46cd-ab19-64056d141aa1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 324s 172ms/step - loss: -379463499776.0000 - accuracy: 0.1664 - val_loss: -2016055525376.0000 - val_accuracy: 0.1677\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 305s 163ms/step - loss: -14453680635904.0000 - accuracy: 0.1664 - val_loss: -36312497258496.0000 - val_accuracy: 0.1677\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 302s 161ms/step - loss: -96621681442816.0000 - accuracy: 0.1664 - val_loss: -175864851464192.0000 - val_accuracy: 0.1677\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 303s 161ms/step - loss: -340538930757632.0000 - accuracy: 0.1664 - val_loss: -526845351034880.0000 - val_accuracy: 0.1677\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 303s 161ms/step - loss: -872596023279616.0000 - accuracy: 0.1664 - val_loss: -1232033246347264.0000 - val_accuracy: 0.1677\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f815f0c1f10>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 07. 모델 평가"
      ],
      "metadata": {
        "id": "heqmj_MZt8lw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DeJ9OTEnUtP",
        "outputId": "593868aa-7149-4c8c-ad35-26e100ab026a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 30s 38ms/step - loss: 1246312133558272.0000 - accuracy: 0.5000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1246312133558272.0, 0.5]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 08. end-to-end 모델 생성"
      ],
      "metadata": {
        "id": "mVgSDmsxuH4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.Input(shape=(1,), dtype=\"string\")\n",
        "indices = vectorize_layer(inputs)\n",
        "outputs = model(indices)\n",
        "\n",
        "end_to_end_model = tf.keras.Model(inputs, outputs)\n",
        "end_to_end_model.compile(\n",
        "    loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
        ")\n",
        "end_to_end_model.evaluate(raw_test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VorSIlQJuDVC",
        "outputId": "3c220702-9647-4f86-f3ec-267adce8b887"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 30s 37ms/step - loss: 1246313609953280.0000 - accuracy: 0.5000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1246313609953280.0, 0.5]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ]
}