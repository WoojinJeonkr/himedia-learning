{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorflow_Decision_Forests.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMXjKQXU6qJGnMXa5/9RfTR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WoojinJeonkr/DeepLearning/blob/main/Tensorflow_Decision_Forests.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensorflow Decsion Forests\n",
        "- 출처: https://www.tensorflow.org/decision_forests/tutorials/beginner_colab?hl=ko#installing_tensorflow_decision_forests"
      ],
      "metadata": {
        "id": "FPDpREp1clvN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision Forest\n",
        "- 지도 분류, 회귀 및 순위 지정을 위한 대규모 기계 학습 알고리즘 제품군"
      ],
      "metadata": {
        "id": "ioaiov82gCqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 01. Tensorflow Decision Forests 설치"
      ],
      "metadata": {
        "id": "Xf-VB4rQgKxc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRN2f9kOaz45",
        "outputId": "2f1d8a4a-0b2e-49dd-820c-8b948abf5241"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow_decision_forests\n",
            "  Downloading tensorflow_decision_forests-0.2.7-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 16.0 MB 11.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorflow_decision_forests) (1.15.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from tensorflow_decision_forests) (0.37.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from tensorflow_decision_forests) (1.3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorflow_decision_forests) (1.21.6)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from tensorflow_decision_forests) (1.2.0)\n",
            "Collecting tensorflow~=2.9.1\n",
            "  Downloading tensorflow-2.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 511.7 MB 6.7 kB/s \n",
            "\u001b[?25hCollecting wurlitzer\n",
            "  Downloading wurlitzer-3.0.2-py3-none-any.whl (7.3 kB)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.1->tensorflow_decision_forests) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.1->tensorflow_decision_forests) (0.26.0)\n",
            "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
            "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[K     |████████████████████████████████| 438 kB 70.2 MB/s \n",
            "\u001b[?25hCollecting gast<=0.4.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Collecting flatbuffers<2,>=1.12\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.1->tensorflow_decision_forests) (1.14.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.1->tensorflow_decision_forests) (0.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.1->tensorflow_decision_forests) (21.3)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.1->tensorflow_decision_forests) (14.0.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.1->tensorflow_decision_forests) (1.1.0)\n",
            "Collecting tensorboard<2.10,>=2.9\n",
            "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 52.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.1->tensorflow_decision_forests) (3.17.3)\n",
            "Collecting keras<2.10.0,>=2.9.0rc0\n",
            "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 54.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.1->tensorflow_decision_forests) (1.1.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.1->tensorflow_decision_forests) (1.47.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.1->tensorflow_decision_forests) (1.6.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.1->tensorflow_decision_forests) (57.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.1->tensorflow_decision_forests) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.1->tensorflow_decision_forests) (4.1.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow~=2.9.1->tensorflow_decision_forests) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.1->tensorflow_decision_forests) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.1->tensorflow_decision_forests) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.1->tensorflow_decision_forests) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.1->tensorflow_decision_forests) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.1->tensorflow_decision_forests) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.1->tensorflow_decision_forests) (3.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.1->tensorflow_decision_forests) (2.23.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow~=2.9.1->tensorflow_decision_forests) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow~=2.9.1->tensorflow_decision_forests) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow~=2.9.1->tensorflow_decision_forests) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.1->tensorflow_decision_forests) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow~=2.9.1->tensorflow_decision_forests) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow~=2.9.1->tensorflow_decision_forests) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow~=2.9.1->tensorflow_decision_forests) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow~=2.9.1->tensorflow_decision_forests) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow~=2.9.1->tensorflow_decision_forests) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow~=2.9.1->tensorflow_decision_forests) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow~=2.9.1->tensorflow_decision_forests) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.1->tensorflow_decision_forests) (3.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow~=2.9.1->tensorflow_decision_forests) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tensorflow_decision_forests) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tensorflow_decision_forests) (2022.1)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras, gast, flatbuffers, wurlitzer, tensorflow, tensorflow-decision-forests\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.2+zzzcolab20220719082949\n",
            "    Uninstalling tensorflow-2.8.2+zzzcolab20220719082949:\n",
            "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220719082949\n",
            "Successfully installed flatbuffers-1.12 gast-0.4.0 keras-2.9.0 tensorboard-2.9.1 tensorflow-2.9.1 tensorflow-decision-forests-0.2.7 tensorflow-estimator-2.9.0 wurlitzer-3.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow_decision_forests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wurlitzer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egIlvhpdgxNO",
        "outputId": "cd4ff293-4b26-4b74-a4ae-0da23cdef9dc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wurlitzer in /usr/local/lib/python3.7/dist-packages (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 02. 라이브러리 불러오기"
      ],
      "metadata": {
        "id": "1cEapSnHheoe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_decision_forests as tfdf\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import math\n",
        "\n",
        "try:\n",
        "  from wurlitzer import sys_pipes\n",
        "except:\n",
        "  from colabtools.googlelog import CaptureLog as sys_pipes\n",
        "\n",
        "from IPython.core.magic import register_line_magic\n",
        "from IPython.display import Javascript"
      ],
      "metadata": {
        "id": "LEcwNjm0hcez"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 출력 높이 제한\n",
        "@register_line_magic\n",
        "def set_cell_height(size):\n",
        "  display(\n",
        "      Javascript(\"google.colab.output.setIframeHeight(0, true, {maxHeight: \" +\n",
        "                 str(size) + \"})\"))"
      ],
      "metadata": {
        "id": "Oq4OTsyZhirw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TensorFlow Decision Forests 버전 확인\n",
        "print(\"Found TensorFlow Decision Forests v\" + tfdf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlXHT-c1iLXz",
        "outputId": "f79d9aff-aa52-4175-f85b-5169a1b28bed"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found TensorFlow Decision Forests v0.2.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 03. 랜덤 포레스트 훈련"
      ],
      "metadata": {
        "id": "ZS_7ep00iSCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 다운로드\n",
        "!wget -q https://storage.googleapis.com/download.tensorflow.org/data/palmer_penguins/penguins.csv -O /tmp/penguins.csv\n",
        "\n",
        "# 데이터셋 불러오기\n",
        "dataset_df = pd.read_csv(\"/tmp/penguins.csv\")\n",
        "\n",
        "# 상위 3개의 데이터 출력\n",
        "dataset_df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "z0qdMdyLiQSe",
        "outputId": "8166bfd2-8364-4139-9fa1-fc1d77d6b09b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
              "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
              "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
              "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
              "\n",
              "   body_mass_g     sex  year  \n",
              "0       3750.0    male  2007  \n",
              "1       3800.0  female  2007  \n",
              "2       3250.0  female  2007  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-870b47c2-4e30-40f2-abc0-17af9359c84e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>species</th>\n",
              "      <th>island</th>\n",
              "      <th>bill_length_mm</th>\n",
              "      <th>bill_depth_mm</th>\n",
              "      <th>flipper_length_mm</th>\n",
              "      <th>body_mass_g</th>\n",
              "      <th>sex</th>\n",
              "      <th>year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>39.1</td>\n",
              "      <td>18.7</td>\n",
              "      <td>181.0</td>\n",
              "      <td>3750.0</td>\n",
              "      <td>male</td>\n",
              "      <td>2007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>39.5</td>\n",
              "      <td>17.4</td>\n",
              "      <td>186.0</td>\n",
              "      <td>3800.0</td>\n",
              "      <td>female</td>\n",
              "      <td>2007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>40.3</td>\n",
              "      <td>18.0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>3250.0</td>\n",
              "      <td>female</td>\n",
              "      <td>2007</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-870b47c2-4e30-40f2-abc0-17af9359c84e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-870b47c2-4e30-40f2-abc0-17af9359c84e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-870b47c2-4e30-40f2-abc0-17af9359c84e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label = \"species\"\n",
        "\n",
        "classes = dataset_df[label].unique().tolist()\n",
        "print(f\"Label classes: {classes}\")\n",
        "\n",
        "dataset_df[label] = dataset_df[label].map(classes.index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hdu29U7xmpfS",
        "outputId": "cdd1028a-10bc-485a-addb-25da4a1e7ff3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label classes: ['Adelie', 'Gentoo', 'Chinstrap']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터세트 분할\n",
        "def split_dataset(dataset, test_ratio=0.30):\n",
        "  \"\"\"Splits a panda dataframe in two.\"\"\"\n",
        "  test_indices = np.random.rand(len(dataset)) < test_ratio\n",
        "  return dataset[~test_indices], dataset[test_indices]\n",
        "\n",
        "\n",
        "train_ds_pd, test_ds_pd = split_dataset(dataset_df)\n",
        "print(\"{} examples in training, {} examples for testing.\".format(\n",
        "    len(train_ds_pd), len(test_ds_pd)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVUMpzpImks1",
        "outputId": "a06d4c6d-7675-471c-cc61-08171cb338ca"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "242 examples in training, 102 examples for testing.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=label)\n",
        "test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_ds_pd, label=label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADhUyTp1mva2",
        "outputId": "c5efb573-bd6c-43bb-c5b5-e852e13eb5fc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow_decision_forests/keras/core.py:2574: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  features_dataframe = dataframe.drop(label, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 훈련\n",
        "%set_cell_height 300\n",
        "\n",
        "model_1 = tfdf.keras.RandomForestModel()\n",
        "\n",
        "model_1.compile(\n",
        "    metrics=[\"accuracy\"])\n",
        "\n",
        "with sys_pipes():\n",
        "  model_1.fit(x=train_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "HsuRaI83mxnI",
        "outputId": "07144f34-0186-4de7-cbe6-fe97087172e2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use /tmp/tmpx9xeoyzj as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:05.613122. Found 242 examples.\n",
            "Training model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[INFO kernel.cc:1176] Loading model from path /tmp/tmpx9xeoyzj/model/ with prefix bd189f22c1744cc6\n",
            "[INFO abstract_model.cc:1248] Engine \"RandomForestGeneric\" built\n",
            "[INFO kernel.cc:1022] Use fast generic engine\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained in 0:00:00.082022\n",
            "Compiling model...\n",
            "WARNING:tensorflow:AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x7fd28a8a14d0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x7fd28a8a14d0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x7fd28a8a14d0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Model compiled.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 평가\n",
        "evaluation = model_1.evaluate(test_ds, return_dict=True)\n",
        "print()\n",
        "\n",
        "for name, value in evaluation.items():\n",
        "  print(f\"{name}: {value:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbLA0CdJnku0",
        "outputId": "b0ddf174-c8f7-439d-9d0b-8a0a4a26c454"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 708ms/step - loss: 0.0000e+00 - accuracy: 0.9902\n",
            "\n",
            "loss: 0.0000\n",
            "accuracy: 0.9902\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 내보내기\n",
        "model_1.save(\"/tmp/my_saved_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZWdfBXRoJmQ",
        "outputId": "1681d3b9-fd1b-47f6-a37a-ca2ac9dc7e02"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as call_get_leaves while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/my_saved_model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/my_saved_model/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 플로팅\n",
        "tfdf.model_plotter.plot_model_in_colab(model_1, tree_idx=0, max_depth=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "XeX03X9HoN1A",
        "outputId": "16faca78-5d18-4a6a-c606-da24b9757693"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<script src=\"https://d3js.org/d3.v6.min.js\"></script>\n",
              "<div id=\"tree_plot_b0d5d4459131430fae83815fbe1968a6\"></div>\n",
              "<script>\n",
              "/*\n",
              " * Copyright 2021 Google LLC.\n",
              " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              " * you may not use this file except in compliance with the License.\n",
              " * You may obtain a copy of the License at\n",
              " *\n",
              " *     https://www.apache.org/licenses/LICENSE-2.0\n",
              " *\n",
              " * Unless required by applicable law or agreed to in writing, software\n",
              " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              " * See the License for the specific language governing permissions and\n",
              " * limitations under the License.\n",
              " */\n",
              "\n",
              "/**\n",
              " *  Plotting of decision trees generated by TF-DF.\n",
              " *\n",
              " *  A tree is a recursive structure of node objects.\n",
              " *  A node contains one or more of the following components:\n",
              " *\n",
              " *    - A value: Representing the output of the node. If the node is not a leaf,\n",
              " *      the value is only present for analysis i.e. it is not used for\n",
              " *      predictions.\n",
              " *\n",
              " *    - A condition : For non-leaf nodes, the condition (also known as split)\n",
              " *      defines a binary test to branch to the positive or negative child.\n",
              " *\n",
              " *    - An explanation: Generally a plot showing the relation between the label\n",
              " *      and the condition to give insights about the effect of the condition.\n",
              " *\n",
              " *    - Two children : For non-leaf nodes, the children nodes. The first\n",
              " *      children (i.e. \"node.children[0]\") is the negative children (drawn in\n",
              " *      red). The second children is the positive one (drawn in green).\n",
              " *\n",
              " */\n",
              "\n",
              "/**\n",
              " * Plots a single decision tree into a DOM element.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!tree} raw_tree Recursive tree structure.\n",
              " * @param {string} canvas_id Id of the output dom element.\n",
              " */\n",
              "function display_tree(options, raw_tree, canvas_id) {\n",
              "  console.log(options);\n",
              "\n",
              "  // Determine the node placement.\n",
              "  const tree_struct = d3.tree().nodeSize(\n",
              "      [options.node_y_offset, options.node_x_offset])(d3.hierarchy(raw_tree));\n",
              "\n",
              "  // Boundaries of the node placement.\n",
              "  let x_min = Infinity;\n",
              "  let x_max = -x_min;\n",
              "  let y_min = Infinity;\n",
              "  let y_max = -x_min;\n",
              "\n",
              "  tree_struct.each(d => {\n",
              "    if (d.x > x_max) x_max = d.x;\n",
              "    if (d.x < x_min) x_min = d.x;\n",
              "    if (d.y > y_max) y_max = d.y;\n",
              "    if (d.y < y_min) y_min = d.y;\n",
              "  });\n",
              "\n",
              "  // Size of the plot.\n",
              "  const width = y_max - y_min + options.node_x_size + options.margin * 2;\n",
              "  const height = x_max - x_min + options.node_y_size + options.margin * 2 +\n",
              "      options.node_y_offset - options.node_y_size;\n",
              "\n",
              "  const plot = d3.select(canvas_id);\n",
              "\n",
              "  // Tool tip\n",
              "  options.tooltip = plot.append('div')\n",
              "                        .attr('width', 100)\n",
              "                        .attr('height', 100)\n",
              "                        .style('padding', '4px')\n",
              "                        .style('background', '#fff')\n",
              "                        .style('box-shadow', '4px 4px 0px rgba(0,0,0,0.1)')\n",
              "                        .style('border', '1px solid black')\n",
              "                        .style('font-family', 'sans-serif')\n",
              "                        .style('font-size', options.font_size)\n",
              "                        .style('position', 'absolute')\n",
              "                        .style('z-index', '10')\n",
              "                        .attr('pointer-events', 'none')\n",
              "                        .style('display', 'none');\n",
              "\n",
              "  // Create canvas\n",
              "  const svg = plot.append('svg').attr('width', width).attr('height', height);\n",
              "  const graph =\n",
              "      svg.style('overflow', 'visible')\n",
              "          .append('g')\n",
              "          .attr('font-family', 'sans-serif')\n",
              "          .attr('font-size', options.font_size)\n",
              "          .attr(\n",
              "              'transform',\n",
              "              () => `translate(${options.margin},${\n",
              "                  - x_min + options.node_y_offset / 2 + options.margin})`);\n",
              "\n",
              "  // Plot bounding box.\n",
              "  if (options.show_plot_bounding_box) {\n",
              "    svg.append('rect')\n",
              "        .attr('width', width)\n",
              "        .attr('height', height)\n",
              "        .attr('fill', 'none')\n",
              "        .attr('stroke-width', 1.0)\n",
              "        .attr('stroke', 'black');\n",
              "  }\n",
              "\n",
              "  // Draw the edges.\n",
              "  display_edges(options, graph, tree_struct);\n",
              "\n",
              "  // Draw the nodes.\n",
              "  display_nodes(options, graph, tree_struct);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Draw the nodes of the tree.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!graph} graph D3 search handle containing the graph.\n",
              " * @param {!tree_struct} tree_struct Structure of the tree (node placement,\n",
              " *     data, etc.).\n",
              " */\n",
              "function display_nodes(options, graph, tree_struct) {\n",
              "  const nodes = graph.append('g')\n",
              "                    .selectAll('g')\n",
              "                    .data(tree_struct.descendants())\n",
              "                    .join('g')\n",
              "                    .attr('transform', d => `translate(${d.y},${d.x})`);\n",
              "\n",
              "  nodes.append('rect')\n",
              "      .attr('x', 0.5)\n",
              "      .attr('y', 0.5)\n",
              "      .attr('width', options.node_x_size)\n",
              "      .attr('height', options.node_y_size)\n",
              "      .attr('stroke', 'lightgrey')\n",
              "      .attr('stroke-width', 1)\n",
              "      .attr('fill', 'white')\n",
              "      .attr('y', -options.node_y_size / 2);\n",
              "\n",
              "  // Brackets on the right of condition nodes without children.\n",
              "  non_leaf_node_without_children =\n",
              "      nodes.filter(node => node.data.condition != null && node.children == null)\n",
              "          .append('g')\n",
              "          .attr('transform', `translate(${options.node_x_size},0)`);\n",
              "\n",
              "  non_leaf_node_without_children.append('path')\n",
              "      .attr('d', 'M0,0 C 10,0 0,10 10,10')\n",
              "      .attr('fill', 'none')\n",
              "      .attr('stroke-width', 1.0)\n",
              "      .attr('stroke', '#F00');\n",
              "\n",
              "  non_leaf_node_without_children.append('path')\n",
              "      .attr('d', 'M0,0 C 10,0 0,-10 10,-10')\n",
              "      .attr('fill', 'none')\n",
              "      .attr('stroke-width', 1.0)\n",
              "      .attr('stroke', '#0F0');\n",
              "\n",
              "  const node_content = nodes.append('g').attr(\n",
              "      'transform',\n",
              "      `translate(0,${options.node_padding - options.node_y_size / 2})`);\n",
              "\n",
              "  node_content.append(node => create_node_element(options, node));\n",
              "}\n",
              "\n",
              "/**\n",
              " * Creates the D3 content for a single node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!node} node Node to draw.\n",
              " * @return {!d3} D3 content.\n",
              " */\n",
              "function create_node_element(options, node) {\n",
              "  // Output accumulator.\n",
              "  let output = {\n",
              "    // Content to draw.\n",
              "    content: d3.create('svg:g'),\n",
              "    // Vertical offset to the next element to draw.\n",
              "    vertical_offset: 0\n",
              "  };\n",
              "\n",
              "  // Conditions.\n",
              "  if (node.data.condition != null) {\n",
              "    display_condition(options, node.data.condition, output);\n",
              "  }\n",
              "\n",
              "  // Values.\n",
              "  if (node.data.value != null) {\n",
              "    display_value(options, node.data.value, output);\n",
              "  }\n",
              "\n",
              "  // Explanations.\n",
              "  if (node.data.explanation != null) {\n",
              "    display_explanation(options, node.data.explanation, output);\n",
              "  }\n",
              "\n",
              "  return output.content.node();\n",
              "}\n",
              "\n",
              "\n",
              "/**\n",
              " * Adds a single line of text inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {string} text Text to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_node_text(options, text, output) {\n",
              "  output.content.append('text')\n",
              "      .attr('x', options.node_padding)\n",
              "      .attr('y', output.vertical_offset)\n",
              "      .attr('alignment-baseline', 'hanging')\n",
              "      .text(text);\n",
              "  output.vertical_offset += 10;\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a single line of text inside of a node with a tooltip.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {string} text Text to display.\n",
              " * @param {string} tooltip Text in the Tooltip.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_node_text_with_tooltip(options, text, tooltip, output) {\n",
              "  const item = output.content.append('text')\n",
              "                   .attr('x', options.node_padding)\n",
              "                   .attr('alignment-baseline', 'hanging')\n",
              "                   .text(text);\n",
              "\n",
              "  add_tooltip(options, item, () => tooltip);\n",
              "  output.vertical_offset += 10;\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a tooltip to a dom element.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!dom} target Dom element to equip with a tooltip.\n",
              " * @param {!func} get_content Generates the html content of the tooltip.\n",
              " */\n",
              "function add_tooltip(options, target, get_content) {\n",
              "  function show(d) {\n",
              "    options.tooltip.style('display', 'block');\n",
              "    options.tooltip.html(get_content());\n",
              "  }\n",
              "\n",
              "  function hide(d) {\n",
              "    options.tooltip.style('display', 'none');\n",
              "  }\n",
              "\n",
              "  function move(d) {\n",
              "    options.tooltip.style('display', 'block');\n",
              "    options.tooltip.style('left', (d.pageX + 5) + 'px');\n",
              "    options.tooltip.style('top', d.pageY + 'px');\n",
              "  }\n",
              "\n",
              "  target.on('mouseover', show);\n",
              "  target.on('mouseout', hide);\n",
              "  target.on('mousemove', move);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a condition inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!condition} condition Condition to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_condition(options, condition, output) {\n",
              "  threshold_format = d3.format('r');\n",
              "\n",
              "  if (condition.type === 'IS_MISSING') {\n",
              "    display_node_text(options, `${condition.attribute} is missing`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'IS_TRUE') {\n",
              "    display_node_text(options, `${condition.attribute} is true`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'NUMERICAL_IS_HIGHER_THAN') {\n",
              "    format = d3.format('r');\n",
              "    display_node_text(\n",
              "        options,\n",
              "        `${condition.attribute} >= ${threshold_format(condition.threshold)}`,\n",
              "        output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'CATEGORICAL_IS_IN') {\n",
              "    display_node_text_with_tooltip(\n",
              "        options, `${condition.attribute} in [...]`,\n",
              "        `${condition.attribute} in [${condition.mask}]`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'CATEGORICAL_SET_CONTAINS') {\n",
              "    display_node_text_with_tooltip(\n",
              "        options, `${condition.attribute} intersect [...]`,\n",
              "        `${condition.attribute} intersect [${condition.mask}]`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'NUMERICAL_SPARSE_OBLIQUE') {\n",
              "    display_node_text_with_tooltip(\n",
              "        options, `Sparse oblique split...`,\n",
              "        `[${condition.attributes}]*[${condition.weights}]>=${\n",
              "            threshold_format(condition.threshold)}`,\n",
              "        output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  display_node_text(\n",
              "      options, `Non supported condition ${condition.type}`, output);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a value inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!value} value Value to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_value(options, value, output) {\n",
              "  if (value.type === 'PROBABILITY') {\n",
              "    const left_margin = 0;\n",
              "    const right_margin = 50;\n",
              "    const plot_width = options.node_x_size - options.node_padding * 2 -\n",
              "        left_margin - right_margin;\n",
              "\n",
              "    let cusum = Array.from(d3.cumsum(value.distribution));\n",
              "    cusum.unshift(0);\n",
              "    const distribution_plot = output.content.append('g').attr(\n",
              "        'transform', `translate(0,${output.vertical_offset + 0.5})`);\n",
              "\n",
              "    distribution_plot.selectAll('rect')\n",
              "        .data(value.distribution)\n",
              "        .join('rect')\n",
              "        .attr('height', 10)\n",
              "        .attr(\n",
              "            'x',\n",
              "            (d, i) =>\n",
              "                (cusum[i] * plot_width + left_margin + options.node_padding))\n",
              "        .attr('width', (d, i) => d * plot_width)\n",
              "        .style('fill', (d, i) => d3.schemeSet1[i]);\n",
              "\n",
              "    const num_examples =\n",
              "        output.content.append('g')\n",
              "            .attr('transform', `translate(0,${output.vertical_offset})`)\n",
              "            .append('text')\n",
              "            .attr('x', options.node_x_size - options.node_padding)\n",
              "            .attr('alignment-baseline', 'hanging')\n",
              "            .attr('text-anchor', 'end')\n",
              "            .text(`(${value.num_examples})`);\n",
              "\n",
              "    const distribution_details = d3.create('ul');\n",
              "    distribution_details.selectAll('li')\n",
              "        .data(value.distribution)\n",
              "        .join('li')\n",
              "        .append('span')\n",
              "        .text(\n",
              "            (d, i) =>\n",
              "                'class ' + i + ': ' + d3.format('.3%')(value.distribution[i]));\n",
              "\n",
              "    add_tooltip(options, distribution_plot, () => distribution_details.html());\n",
              "    add_tooltip(options, num_examples, () => 'Number of examples');\n",
              "\n",
              "    output.vertical_offset += 10;\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (value.type === 'REGRESSION') {\n",
              "    display_node_text(\n",
              "        options,\n",
              "        'value: ' + d3.format('r')(value.value) + ` (` +\n",
              "            d3.format('.6')(value.num_examples) + `)`,\n",
              "        output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  display_node_text(options, `Non supported value ${value.type}`, output);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds an explanation inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!explanation} explanation Explanation to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_explanation(options, explanation, output) {\n",
              "  // Margin before the explanation.\n",
              "  output.vertical_offset += 10;\n",
              "\n",
              "  display_node_text(\n",
              "      options, `Non supported explanation ${explanation.type}`, output);\n",
              "}\n",
              "\n",
              "\n",
              "/**\n",
              " * Draw the edges of the tree.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!graph} graph D3 search handle containing the graph.\n",
              " * @param {!tree_struct} tree_struct Structure of the tree (node placement,\n",
              " *     data, etc.).\n",
              " */\n",
              "function display_edges(options, graph, tree_struct) {\n",
              "  // Draw an edge between a parent and a child node with a bezier.\n",
              "  function draw_single_edge(d) {\n",
              "    return 'M' + (d.source.y + options.node_x_size) + ',' + d.source.x + ' C' +\n",
              "        (d.source.y + options.node_x_size + options.edge_rounding) + ',' +\n",
              "        d.source.x + ' ' + (d.target.y - options.edge_rounding) + ',' +\n",
              "        d.target.x + ' ' + d.target.y + ',' + d.target.x;\n",
              "  }\n",
              "\n",
              "  graph.append('g')\n",
              "      .attr('fill', 'none')\n",
              "      .attr('stroke-width', 1.2)\n",
              "      .selectAll('path')\n",
              "      .data(tree_struct.links())\n",
              "      .join('path')\n",
              "      .attr('d', draw_single_edge)\n",
              "      .attr(\n",
              "          'stroke', d => (d.target === d.source.children[0]) ? '#0F0' : '#F00');\n",
              "}\n",
              "\n",
              "display_tree({\"margin\": 10, \"node_x_size\": 160, \"node_y_size\": 28, \"node_x_offset\": 180, \"node_y_offset\": 33, \"font_size\": 10, \"edge_rounding\": 20, \"node_padding\": 2, \"show_plot_bounding_box\": false}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.45867768595041325, 0.3347107438016529, 0.2066115702479339], \"num_examples\": 242.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"flipper_length_mm\", \"threshold\": 207.5}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.022727272727272728, 0.9204545454545454, 0.056818181818181816], \"num_examples\": 88.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"bill_depth_mm\", \"threshold\": 17.649999618530273}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.2857142857142857, 0.0, 0.7142857142857143], \"num_examples\": 7.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.0, 1.0, 0.0], \"num_examples\": 81.0}}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.7077922077922078, 0.0, 0.2922077922077922], \"num_examples\": 154.0}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"island\", \"mask\": [\"Biscoe\", \"Torgersen\"]}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [1.0, 0.0, 0.0], \"num_examples\": 72.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.45121951219512196, 0.0, 0.5487804878048781], \"num_examples\": 82.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"body_mass_g\", \"threshold\": 4375.0}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [1.0, 0.0, 0.0], \"num_examples\": 6.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.40789473684210525, 0.0, 0.5921052631578947], \"num_examples\": 76.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"bill_length_mm\", \"threshold\": 40.75}}]}]}]}, \"#tree_plot_b0d5d4459131430fae83815fbe1968a6\")\n",
              "</script>\n"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 구조 및 기능 중요도\n",
        "%set_cell_height 300\n",
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "dY_J3nV5oVm3",
        "outputId": "c1367354-1971-45da-8387-34b31920c998"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"random_forest_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            "=================================================================\n",
            "Total params: 1\n",
            "Trainable params: 0\n",
            "Non-trainable params: 1\n",
            "_________________________________________________________________\n",
            "Type: \"RANDOM_FOREST\"\n",
            "Task: CLASSIFICATION\n",
            "Label: \"__LABEL\"\n",
            "\n",
            "Input Features (7):\n",
            "\tbill_depth_mm\n",
            "\tbill_length_mm\n",
            "\tbody_mass_g\n",
            "\tflipper_length_mm\n",
            "\tisland\n",
            "\tsex\n",
            "\tyear\n",
            "\n",
            "No weights\n",
            "\n",
            "Variable Importance: MEAN_MIN_DEPTH:\n",
            "    1.           \"__LABEL\"  3.140619 ################\n",
            "    2.               \"sex\"  3.117510 ###############\n",
            "    3.              \"year\"  3.115809 ###############\n",
            "    4.       \"body_mass_g\"  2.646164 ###########\n",
            "    5.            \"island\"  2.157530 #######\n",
            "    6.     \"bill_depth_mm\"  1.952792 #####\n",
            "    7.    \"bill_length_mm\"  1.399079 \n",
            "    8. \"flipper_length_mm\"  1.384412 \n",
            "\n",
            "Variable Importance: NUM_AS_ROOT:\n",
            "    1. \"flipper_length_mm\" 143.000000 ################\n",
            "    2.    \"bill_length_mm\" 75.000000 ########\n",
            "    3.     \"bill_depth_mm\" 68.000000 #######\n",
            "    4.            \"island\"  9.000000 \n",
            "    5.       \"body_mass_g\"  5.000000 \n",
            "\n",
            "Variable Importance: NUM_NODES:\n",
            "    1.    \"bill_length_mm\" 615.000000 ################\n",
            "    2.     \"bill_depth_mm\" 416.000000 ##########\n",
            "    3. \"flipper_length_mm\" 332.000000 ########\n",
            "    4.       \"body_mass_g\" 286.000000 #######\n",
            "    5.            \"island\" 263.000000 ######\n",
            "    6.               \"sex\" 19.000000 \n",
            "    7.              \"year\" 11.000000 \n",
            "\n",
            "Variable Importance: SUM_SCORE:\n",
            "    1.    \"bill_length_mm\" 24993.768285 ################\n",
            "    2. \"flipper_length_mm\" 21750.989929 #############\n",
            "    3.     \"bill_depth_mm\" 13241.040874 ########\n",
            "    4.            \"island\" 9975.020363 ######\n",
            "    5.       \"body_mass_g\" 2750.528042 #\n",
            "    6.               \"sex\" 142.260510 \n",
            "    7.              \"year\" 25.266718 \n",
            "\n",
            "\n",
            "\n",
            "Winner take all: true\n",
            "Out-of-bag evaluation: accuracy:0.979339 logloss:0.078074\n",
            "Number of trees: 300\n",
            "Total number of nodes: 4184\n",
            "\n",
            "Number of nodes by tree:\n",
            "Count: 300 Average: 13.9467 StdDev: 2.79711\n",
            "Min: 9 Max: 29 Ignored: 0\n",
            "----------------------------------------------\n",
            "[  9, 10)  14   4.67%   4.67% #\n",
            "[ 10, 11)   0   0.00%   4.67%\n",
            "[ 11, 12)  51  17.00%  21.67% #####\n",
            "[ 12, 13)   0   0.00%  21.67%\n",
            "[ 13, 14) 109  36.33%  58.00% ##########\n",
            "[ 14, 15)   0   0.00%  58.00%\n",
            "[ 15, 16)  69  23.00%  81.00% ######\n",
            "[ 16, 17)   0   0.00%  81.00%\n",
            "[ 17, 18)  35  11.67%  92.67% ###\n",
            "[ 18, 19)   0   0.00%  92.67%\n",
            "[ 19, 20)  13   4.33%  97.00% #\n",
            "[ 20, 21)   0   0.00%  97.00%\n",
            "[ 21, 22)   6   2.00%  99.00% #\n",
            "[ 22, 23)   0   0.00%  99.00%\n",
            "[ 23, 24)   1   0.33%  99.33%\n",
            "[ 24, 25)   0   0.00%  99.33%\n",
            "[ 25, 26)   1   0.33%  99.67%\n",
            "[ 26, 27)   0   0.00%  99.67%\n",
            "[ 27, 28)   0   0.00%  99.67%\n",
            "[ 28, 29]   1   0.33% 100.00%\n",
            "\n",
            "Depth by leafs:\n",
            "Count: 2242 Average: 3.20919 StdDev: 1.01173\n",
            "Min: 1 Max: 9 Ignored: 0\n",
            "----------------------------------------------\n",
            "[ 1, 2)   8   0.36%   0.36%\n",
            "[ 2, 3) 609  27.16%  27.52% ########\n",
            "[ 3, 4) 790  35.24%  62.76% ##########\n",
            "[ 4, 5) 626  27.92%  90.68% ########\n",
            "[ 5, 6) 172   7.67%  98.35% ##\n",
            "[ 6, 7)  29   1.29%  99.64%\n",
            "[ 7, 8)   5   0.22%  99.87%\n",
            "[ 8, 9)   1   0.04%  99.91%\n",
            "[ 9, 9]   2   0.09% 100.00%\n",
            "\n",
            "Number of training obs by leaf:\n",
            "Count: 2242 Average: 32.3818 StdDev: 32.4971\n",
            "Min: 5 Max: 113 Ignored: 0\n",
            "----------------------------------------------\n",
            "[   5,  10) 1036  46.21%  46.21% ##########\n",
            "[  10,  15)   98   4.37%  50.58% #\n",
            "[  15,  21)   95   4.24%  54.82% #\n",
            "[  21,  26)   49   2.19%  57.00%\n",
            "[  26,  32)   81   3.61%  60.62% #\n",
            "[  32,  37)   91   4.06%  64.67% #\n",
            "[  37,  43)  109   4.86%  69.54% #\n",
            "[  43,  48)   67   2.99%  72.52% #\n",
            "[  48,  54)   45   2.01%  74.53%\n",
            "[  54,  59)   39   1.74%  76.27%\n",
            "[  59,  64)   22   0.98%  77.25%\n",
            "[  64,  70)   27   1.20%  78.46%\n",
            "[  70,  75)   36   1.61%  80.06%\n",
            "[  75,  81)   89   3.97%  84.03% #\n",
            "[  81,  86)   89   3.97%  88.00% #\n",
            "[  86,  92)  116   5.17%  93.18% #\n",
            "[  92,  97)   81   3.61%  96.79% #\n",
            "[  97, 103)   49   2.19%  98.97%\n",
            "[ 103, 108)   16   0.71%  99.69%\n",
            "[ 108, 113]    7   0.31% 100.00%\n",
            "\n",
            "Attribute in nodes:\n",
            "\t615 : bill_length_mm [NUMERICAL]\n",
            "\t416 : bill_depth_mm [NUMERICAL]\n",
            "\t332 : flipper_length_mm [NUMERICAL]\n",
            "\t286 : body_mass_g [NUMERICAL]\n",
            "\t263 : island [CATEGORICAL]\n",
            "\t19 : sex [CATEGORICAL]\n",
            "\t11 : year [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 0:\n",
            "\t143 : flipper_length_mm [NUMERICAL]\n",
            "\t75 : bill_length_mm [NUMERICAL]\n",
            "\t68 : bill_depth_mm [NUMERICAL]\n",
            "\t9 : island [CATEGORICAL]\n",
            "\t5 : body_mass_g [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 1:\n",
            "\t224 : bill_length_mm [NUMERICAL]\n",
            "\t216 : flipper_length_mm [NUMERICAL]\n",
            "\t195 : bill_depth_mm [NUMERICAL]\n",
            "\t185 : island [CATEGORICAL]\n",
            "\t72 : body_mass_g [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 2:\n",
            "\t408 : bill_length_mm [NUMERICAL]\n",
            "\t334 : bill_depth_mm [NUMERICAL]\n",
            "\t289 : flipper_length_mm [NUMERICAL]\n",
            "\t245 : island [CATEGORICAL]\n",
            "\t181 : body_mass_g [NUMERICAL]\n",
            "\t6 : year [NUMERICAL]\n",
            "\t4 : sex [CATEGORICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 3:\n",
            "\t561 : bill_length_mm [NUMERICAL]\n",
            "\t400 : bill_depth_mm [NUMERICAL]\n",
            "\t321 : flipper_length_mm [NUMERICAL]\n",
            "\t261 : island [CATEGORICAL]\n",
            "\t259 : body_mass_g [NUMERICAL]\n",
            "\t18 : sex [CATEGORICAL]\n",
            "\t7 : year [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 5:\n",
            "\t613 : bill_length_mm [NUMERICAL]\n",
            "\t416 : bill_depth_mm [NUMERICAL]\n",
            "\t332 : flipper_length_mm [NUMERICAL]\n",
            "\t283 : body_mass_g [NUMERICAL]\n",
            "\t263 : island [CATEGORICAL]\n",
            "\t19 : sex [CATEGORICAL]\n",
            "\t11 : year [NUMERICAL]\n",
            "\n",
            "Condition type in nodes:\n",
            "\t1660 : HigherCondition\n",
            "\t282 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 0:\n",
            "\t291 : HigherCondition\n",
            "\t9 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 1:\n",
            "\t707 : HigherCondition\n",
            "\t185 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 2:\n",
            "\t1218 : HigherCondition\n",
            "\t249 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 3:\n",
            "\t1548 : HigherCondition\n",
            "\t279 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 5:\n",
            "\t1655 : HigherCondition\n",
            "\t282 : ContainsBitmapCondition\n",
            "Node format: NOT_SET\n",
            "\n",
            "Training OOB:\n",
            "\ttrees: 1, Out-of-bag evaluation: accuracy:0.866667 logloss:4.80582\n",
            "\ttrees: 11, Out-of-bag evaluation: accuracy:0.975104 logloss:0.650937\n",
            "\ttrees: 21, Out-of-bag evaluation: accuracy:0.966942 logloss:0.221163\n",
            "\ttrees: 31, Out-of-bag evaluation: accuracy:0.971074 logloss:0.222984\n",
            "\ttrees: 41, Out-of-bag evaluation: accuracy:0.971074 logloss:0.0889175\n",
            "\ttrees: 51, Out-of-bag evaluation: accuracy:0.971074 logloss:0.0919684\n",
            "\ttrees: 61, Out-of-bag evaluation: accuracy:0.96281 logloss:0.0893265\n",
            "\ttrees: 71, Out-of-bag evaluation: accuracy:0.966942 logloss:0.0880429\n",
            "\ttrees: 81, Out-of-bag evaluation: accuracy:0.971074 logloss:0.0873979\n",
            "\ttrees: 91, Out-of-bag evaluation: accuracy:0.971074 logloss:0.0848382\n",
            "\ttrees: 101, Out-of-bag evaluation: accuracy:0.975207 logloss:0.0834638\n",
            "\ttrees: 111, Out-of-bag evaluation: accuracy:0.971074 logloss:0.0846225\n",
            "\ttrees: 121, Out-of-bag evaluation: accuracy:0.966942 logloss:0.0847823\n",
            "\ttrees: 131, Out-of-bag evaluation: accuracy:0.975207 logloss:0.084942\n",
            "\ttrees: 141, Out-of-bag evaluation: accuracy:0.975207 logloss:0.0849008\n",
            "\ttrees: 151, Out-of-bag evaluation: accuracy:0.966942 logloss:0.0843279\n",
            "\ttrees: 161, Out-of-bag evaluation: accuracy:0.971074 logloss:0.0840889\n",
            "\ttrees: 171, Out-of-bag evaluation: accuracy:0.971074 logloss:0.0836793\n",
            "\ttrees: 181, Out-of-bag evaluation: accuracy:0.971074 logloss:0.0797145\n",
            "\ttrees: 191, Out-of-bag evaluation: accuracy:0.971074 logloss:0.0800722\n",
            "\ttrees: 201, Out-of-bag evaluation: accuracy:0.971074 logloss:0.0789158\n",
            "\ttrees: 211, Out-of-bag evaluation: accuracy:0.971074 logloss:0.0789792\n",
            "\ttrees: 221, Out-of-bag evaluation: accuracy:0.966942 logloss:0.0788001\n",
            "\ttrees: 231, Out-of-bag evaluation: accuracy:0.971074 logloss:0.0794962\n",
            "\ttrees: 241, Out-of-bag evaluation: accuracy:0.975207 logloss:0.0798618\n",
            "\ttrees: 251, Out-of-bag evaluation: accuracy:0.979339 logloss:0.0796383\n",
            "\ttrees: 261, Out-of-bag evaluation: accuracy:0.979339 logloss:0.0773437\n",
            "\ttrees: 271, Out-of-bag evaluation: accuracy:0.979339 logloss:0.077493\n",
            "\ttrees: 281, Out-of-bag evaluation: accuracy:0.979339 logloss:0.07708\n",
            "\ttrees: 291, Out-of-bag evaluation: accuracy:0.979339 logloss:0.077388\n",
            "\ttrees: 300, Out-of-bag evaluation: accuracy:0.979339 logloss:0.078074\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력 특성\n",
        "model_1.make_inspector().features()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyXB9cT9os4Q",
        "outputId": "e21a0f61-cae9-4ad1-a9fe-e019a3dadeff"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"bill_depth_mm\" (1; #0),\n",
              " \"bill_length_mm\" (1; #1),\n",
              " \"body_mass_g\" (1; #2),\n",
              " \"flipper_length_mm\" (1; #3),\n",
              " \"island\" (4; #4),\n",
              " \"sex\" (4; #5),\n",
              " \"year\" (1; #6)]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 기능 중요도\n",
        "model_1.make_inspector().variable_importances()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXK__6c1ovSq",
        "outputId": "167fa61b-3fab-4df5-b3b9-4d6ae0769e17"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'MEAN_MIN_DEPTH': [(\"__LABEL\" (4; #7), 3.1406188256188154),\n",
              "  (\"sex\" (4; #5), 3.1175103600103506),\n",
              "  (\"year\" (1; #6), 3.1158094220594124),\n",
              "  (\"body_mass_g\" (1; #2), 2.646163974913972),\n",
              "  (\"island\" (4; #4), 2.157529775779775),\n",
              "  (\"bill_depth_mm\" (1; #0), 1.9527923280423283),\n",
              "  (\"bill_length_mm\" (1; #1), 1.3990786065786067),\n",
              "  (\"flipper_length_mm\" (1; #3), 1.3844115606615612)],\n",
              " 'NUM_AS_ROOT': [(\"flipper_length_mm\" (1; #3), 143.0),\n",
              "  (\"bill_length_mm\" (1; #1), 75.0),\n",
              "  (\"bill_depth_mm\" (1; #0), 68.0),\n",
              "  (\"island\" (4; #4), 9.0),\n",
              "  (\"body_mass_g\" (1; #2), 5.0)],\n",
              " 'NUM_NODES': [(\"bill_length_mm\" (1; #1), 615.0),\n",
              "  (\"bill_depth_mm\" (1; #0), 416.0),\n",
              "  (\"flipper_length_mm\" (1; #3), 332.0),\n",
              "  (\"body_mass_g\" (1; #2), 286.0),\n",
              "  (\"island\" (4; #4), 263.0),\n",
              "  (\"sex\" (4; #5), 19.0),\n",
              "  (\"year\" (1; #6), 11.0)],\n",
              " 'SUM_SCORE': [(\"bill_length_mm\" (1; #1), 24993.7682845816),\n",
              "  (\"flipper_length_mm\" (1; #3), 21750.989928830415),\n",
              "  (\"bill_depth_mm\" (1; #0), 13241.040874174796),\n",
              "  (\"island\" (4; #4), 9975.020362563431),\n",
              "  (\"body_mass_g\" (1; #2), 2750.5280423536897),\n",
              "  (\"sex\" (4; #5), 142.26051031798124),\n",
              "  (\"year\" (1; #6), 25.266717730090022)]}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 자체 평가\n",
        "model_1.make_inspector().evaluation()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NN0H-NA0o4Z8",
        "outputId": "3388e078-d352-4127-8664-7ef117300da7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Evaluation(num_examples=242, accuracy=0.9793388429752066, loss=0.07807398846850169, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 로그 플로팅\n",
        "%set_cell_height 150\n",
        "model_1.make_inspector().training_logs()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "id": "Cg8WbMqqpe4q",
        "outputId": "95270b92-4b41-4308-bc1c-eb60a248c4ab"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 150})"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[TrainLog(num_trees=1, evaluation=Evaluation(num_examples=90, accuracy=0.8666666666666667, loss=4.80582021077474, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
              " TrainLog(num_trees=11, evaluation=Evaluation(num_examples=241, accuracy=0.975103734439834, loss=0.6509367458800557, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
              " TrainLog(num_trees=21, evaluation=Evaluation(num_examples=242, accuracy=0.9669421487603306, loss=0.22116267157733932, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
              " TrainLog(num_trees=31, evaluation=Evaluation(num_examples=242, accuracy=0.9710743801652892, loss=0.2229844139165376, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
              " TrainLog(num_trees=41, evaluation=Evaluation(num_examples=242, accuracy=0.9710743801652892, loss=0.08891751811154618, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
              " TrainLog(num_trees=51, evaluation=Evaluation(num_examples=242, accuracy=0.9710743801652892, loss=0.09196838698049714, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
              " TrainLog(num_trees=61, evaluation=Evaluation(num_examples=242, accuracy=0.9628099173553719, loss=0.08932649033251873, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
              " TrainLog(num_trees=71, evaluation=Evaluation(num_examples=242, accuracy=0.9669421487603306, loss=0.08804286776249073, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
              " TrainLog(num_trees=81, evaluation=Evaluation(num_examples=242, accuracy=0.9710743801652892, loss=0.08739792272325389, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
              " TrainLog(num_trees=91, evaluation=Evaluation(num_examples=242, accuracy=0.9710743801652892, loss=0.08483817827818561, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
              " TrainLog(num_trees=101, evaluation=Evaluation(num_examples=242, accuracy=0.9752066115702479, loss=0.08346383678457461, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
              " TrainLog(num_trees=111, evaluation=Evaluation(num_examples=242, accuracy=0.9710743801652892, loss=0.08462245973242709, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
              " TrainLog(num_trees=121, evaluation=Evaluation(num_examples=242, accuracy=0.9669421487603306, loss=0.08478228169808949, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
              " TrainLog(num_trees=131, evaluation=Evaluation(num_examples=242, accuracy=0.9752066115702479, loss=0.0849420106700383, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
              " TrainLog(num_trees=141, evaluation=Evaluation(num_examples=242, accuracy=0.9752066115702479, loss=0.08490085153078492, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
              " TrainLog(num_trees=151, evaluation=Evaluation(num_examples=242, accuracy=0.9669421487603306, loss=0.08432789397048802, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
              " TrainLog(num_trees=161, evaluation=Evaluation(num_examples=242, accuracy=0.9710743801652892, loss=0.08408888914691638, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
              " TrainLog(num_trees=171, evaluation=Evaluation(num_examples=242, accuracy=0.9710743801652892, loss=0.08367931040404133, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
              " TrainLog(num_trees=181, evaluation=Evaluation(num_examples=242, accuracy=0.9710743801652892, loss=0.07971453706325948, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
              " TrainLog(num_trees=191, evaluation=Evaluation(num_examples=242, accuracy=0.9710743801652892, loss=0.08007224061149211, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
              " TrainLog(num_trees=201, evaluation=Evaluation(num_examples=242, accuracy=0.9710743801652892, loss=0.07891581326815461, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
              " TrainLog(num_trees=211, evaluation=Evaluation(num_examples=242, accuracy=0.9710743801652892, loss=0.07897916916480735, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
              " TrainLog(num_trees=221, evaluation=Evaluation(num_examples=242, accuracy=0.9669421487603306, loss=0.07880013792829449, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
              " TrainLog(num_trees=231, evaluation=Evaluation(num_examples=242, accuracy=0.9710743801652892, loss=0.07949623402423603, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
              " TrainLog(num_trees=241, evaluation=Evaluation(num_examples=242, accuracy=0.9752066115702479, loss=0.07986183751620783, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
              " TrainLog(num_trees=251, evaluation=Evaluation(num_examples=242, accuracy=0.9793388429752066, loss=0.07963828781758212, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
              " TrainLog(num_trees=261, evaluation=Evaluation(num_examples=242, accuracy=0.9793388429752066, loss=0.07734364686025814, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
              " TrainLog(num_trees=271, evaluation=Evaluation(num_examples=242, accuracy=0.9793388429752066, loss=0.07749299148544053, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
              " TrainLog(num_trees=281, evaluation=Evaluation(num_examples=242, accuracy=0.9793388429752066, loss=0.07707997017794034, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
              " TrainLog(num_trees=291, evaluation=Evaluation(num_examples=242, accuracy=0.9793388429752066, loss=0.07738802858728393, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
              " TrainLog(num_trees=300, evaluation=Evaluation(num_examples=242, accuracy=0.9793388429752066, loss=0.07807398846850169, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None))]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 다른 학습 알고리즘으로 모델 재훈련\n",
        "tfdf.keras.get_all_models()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yCIzlrqpjWS",
        "outputId": "625daf10-ab41-4c75-fbf6-b1c38bd441ba"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensorflow_decision_forests.keras.RandomForestModel,\n",
              " tensorflow_decision_forests.keras.GradientBoostedTreesModel,\n",
              " tensorflow_decision_forests.keras.CartModel,\n",
              " tensorflow_decision_forests.keras.DistributedGradientBoostedTreesModel]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 도움말 출력하기\n",
        "help(tfdf.keras.RandomForestModel)\n",
        "tfdf.keras.RandomForestModel?"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3j7hsp-psGj",
        "outputId": "203b210d-6712-4564-c5b7-6719b5a68ea2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on class RandomForestModel in module tensorflow_decision_forests.keras:\n",
            "\n",
            "class RandomForestModel(tensorflow_decision_forests.keras.wrappers.RandomForestModel)\n",
            " |  RandomForestModel(*args, **kwargs)\n",
            " |  \n",
            " |  Random Forest learning algorithm.\n",
            " |  \n",
            " |  A Random Forest (https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf)\n",
            " |  is a collection of deep CART decision trees trained independently and without\n",
            " |  pruning. Each tree is trained on a random subset of the original training \n",
            " |  dataset (sampled with replacement).\n",
            " |  \n",
            " |  The algorithm is unique in that it is robust to overfitting, even in extreme\n",
            " |  cases e.g. when there is more features than training examples.\n",
            " |  \n",
            " |  It is probably the most well-known of the Decision Forest training\n",
            " |  algorithms.\n",
            " |  \n",
            " |  Usage example:\n",
            " |  \n",
            " |  ```python\n",
            " |  import tensorflow_decision_forests as tfdf\n",
            " |  import pandas as pd\n",
            " |  \n",
            " |  dataset = pd.read_csv(\"project/dataset.csv\")\n",
            " |  tf_dataset = tfdf.keras.pd_dataframe_to_tf_dataset(dataset, label=\"my_label\")\n",
            " |  \n",
            " |  model = tfdf.keras.RandomForestModel()\n",
            " |  model.fit(tf_dataset)\n",
            " |  \n",
            " |  print(model.summary())\n",
            " |  ```\n",
            " |  \n",
            " |  Hyper-parameter tuning:\n",
            " |  \n",
            " |  ```python\n",
            " |  import tensorflow_decision_forests as tfdf\n",
            " |  import pandas as pd\n",
            " |  \n",
            " |  dataset = pd.read_csv(\"project/dataset.csv\")\n",
            " |  tf_dataset = tfdf.keras.pd_dataframe_to_tf_dataset(dataset, label=\"my_label\")\n",
            " |  \n",
            " |  tuner = tfdf.tuner.RandomSearch(num_trials=20)\n",
            " |  \n",
            " |  # Hyper-parameters to optimize.\n",
            " |  tuner.discret(\"max_depth\", [4, 5, 6, 7])\n",
            " |  \n",
            " |  model = tfdf.keras.RandomForestModel(tuner=tuner)\n",
            " |  model.fit(tf_dataset)\n",
            " |  \n",
            " |  print(model.summary())\n",
            " |  ```\n",
            " |  \n",
            " |  \n",
            " |  Attributes:\n",
            " |    task: Task to solve (e.g. Task.CLASSIFICATION, Task.REGRESSION,\n",
            " |      Task.RANKING, Task.CATEGORICAL_UPLIFT, Task.NUMERICAL_UPLIFT).\n",
            " |    features: Specify the list and semantic of the input features of the model.\n",
            " |      If not specified, all the available features will be used. If specified\n",
            " |      and if `exclude_non_specified_features=True`, only the features in\n",
            " |      `features` will be used by the model. If \"preprocessing\" is used,\n",
            " |      `features` corresponds to the output of the preprocessing. In this case,\n",
            " |      it is recommended for the preprocessing to return a dictionary of tensors.\n",
            " |    exclude_non_specified_features: If true, only use the features specified in\n",
            " |      `features`.\n",
            " |    preprocessing: Functional keras model or @tf.function to apply on the input\n",
            " |      feature before the model to train. This preprocessing model can consume\n",
            " |      and return tensors, list of tensors or dictionary of tensors. If\n",
            " |      specified, the model only \"sees\" the output of the preprocessing (and not\n",
            " |      the raw input). Can be used to prepare the features or to stack multiple\n",
            " |      models on top of each other. Unlike preprocessing done in the tf.dataset,\n",
            " |      the operation in \"preprocessing\" are serialized with the model.\n",
            " |    postprocessing: Like \"preprocessing\" but applied on the model output.\n",
            " |    ranking_group: Only for `task=Task.RANKING`. Name of a tf.string feature that\n",
            " |      identifies queries in a query/document ranking task. The ranking group\n",
            " |      is not added automatically for the set of features if\n",
            " |      `exclude_non_specified_features=false`.\n",
            " |    uplift_treatment: Only for task=Task.CATEGORICAL_UPLIFT or\n",
            " |      task=Task.NUMERICAL_UPLIFT. Name of an integer feature that identifies the\n",
            " |      treatment in an uplift problem. The value 0 is reserved for the control\n",
            " |      treatment.\n",
            " |    temp_directory: Temporary directory used to store the model Assets after the\n",
            " |      training, and possibly as a work directory during the training. This\n",
            " |      temporary directory is necessary for the model to be exported after\n",
            " |      training e.g. `model.save(path)`. If not specified, `temp_directory` is\n",
            " |      set to a temporary directory using `tempfile.TemporaryDirectory`. This\n",
            " |      directory is deleted when the model python object is garbage-collected.\n",
            " |    verbose: Verbosity mode. 0 = silent, 1 = small details, 2 = full details.\n",
            " |    hyperparameter_template: Override the default value of the hyper-parameters.\n",
            " |      If None (default) the default parameters of the library are used. If set,\n",
            " |      `default_hyperparameter_template` refers to one of the following\n",
            " |      preconfigured hyper-parameter sets. Those sets outperforms the default\n",
            " |      hyper-parameters (either generally or in specific scenarios).\n",
            " |      You can omit the version (e.g. remove \"@v5\") to use the last version of\n",
            " |      the template. In this case, the hyper-parameter can change in between\n",
            " |      releases (not recommended for training in production).\n",
            " |      - better_default@v1: A configuration that is generally better than the\n",
            " |        default parameters without being more expensive. The parameters are:\n",
            " |        winner_take_all=True.\n",
            " |      - benchmark_rank1@v1: Top ranking hyper-parameters on our benchmark\n",
            " |        slightly modified to run in reasonable time. The parameters are:\n",
            " |        winner_take_all=True, categorical_algorithm=\"RANDOM\",\n",
            " |        split_axis=\"SPARSE_OBLIQUE\", sparse_oblique_normalization=\"MIN_MAX\",\n",
            " |        sparse_oblique_num_projections_exponent=1.0.\n",
            " |  \n",
            " |    advanced_arguments: Advanced control of the model that most users won't need\n",
            " |      to use. See `AdvancedArguments` for details.\n",
            " |    num_threads: Number of threads used to train the model. Different learning\n",
            " |      algorithms use multi-threading differently and with different degree of\n",
            " |      efficiency. If `None`, `num_threads` will be automatically set to the\n",
            " |      number of processors (up to a maximum of 32; or set to 6 if the number of\n",
            " |      processors is not available).\n",
            " |      Making `num_threads` significantly larger than the number of processors\n",
            " |      can slow-down the training speed. The default value logic might change in\n",
            " |      the future.\n",
            " |    name: The name of the model.\n",
            " |    max_vocab_count: Default maximum size of the vocabulary for CATEGORICAL and\n",
            " |      CATEGORICAL_SET features stored as strings. If more unique values exist,\n",
            " |      only the most frequent values are kept, and the remaining values are\n",
            " |      considered as out-of-vocabulary. The value `max_vocab_count` defined in a\n",
            " |      `FeatureUsage` (if any) takes precedence.\n",
            " |    try_resume_training: If true, the model training resumes from the checkpoint\n",
            " |      stored in the `temp_directory` directory. If `temp_directory` does not\n",
            " |      contain any model checkpoint, the training start from the beginning.\n",
            " |      Resuming training is useful in the following situations: (1) The training\n",
            " |        was interrupted by the user (e.g. ctrl+c or \"stop\" button in a\n",
            " |        notebook). (2) the training job was interrupted (e.g. rescheduling), ond\n",
            " |        (3) the hyper-parameter of the model were changed such that an initially\n",
            " |        completed training is now incomplete (e.g. increasing the number of\n",
            " |        trees).\n",
            " |      Note: Training can only be resumed if the training datasets is exactly the\n",
            " |        same (i.e. no reshuffle in the tf.data.Dataset).\n",
            " |    check_dataset: If set to true, test if the dataset is well configured for\n",
            " |      the training: (1) Check if the dataset does contains any `repeat`\n",
            " |        operations, (2) Check if the dataset does contain a `batch` operation,\n",
            " |        (3) Check if the dataset has a large enough batch size (min 100 if the\n",
            " |        dataset contains more than 1k examples or if the number of examples is\n",
            " |        not available) If set to false, do not run any test.\n",
            " |    tuner: If set, automatically optimize the hyperparameters of the model using\n",
            " |      this tuner. If the model is trained with distribution (i.e. the model\n",
            " |      definition is wrapper in a TF Distribution strategy, the tuning is\n",
            " |      distributed.\n",
            " |    discretize_numerical_features: If true, discretize all the numerical\n",
            " |      features before training. Discretized numerical features are faster to\n",
            " |      train with, but they can have a negative impact on the model quality.\n",
            " |      Using discretize_numerical_features=True is equivalent as setting the\n",
            " |      feature semantic DISCRETIZED_NUMERICAL in the `feature` argument. See the\n",
            " |      definition of DISCRETIZED_NUMERICAL for more details.\n",
            " |    num_discretize_numerical_bins: Number of bins used when disretizing\n",
            " |      numerical features. The value `num_discretized_numerical_bins` defined in\n",
            " |      a `FeatureUsage` (if any) takes precedence.\n",
            " |    adapt_bootstrap_size_ratio_for_maximum_training_duration: Control how the\n",
            " |      maximum training duration (if set) is applied. If false, the training\n",
            " |      stop when the time is used. If true, adapts the size of the sampled\n",
            " |      dataset used to train each tree such that `num_trees` will train within\n",
            " |      `maximum_training_duration`. Has no effect if there is no maximum\n",
            " |      training duration specified. Default: False.\n",
            " |    allow_na_conditions: If true, the tree training evaluates conditions of the\n",
            " |      type `X is NA` i.e. `X is missing`. Default: False.\n",
            " |    bootstrap_size_ratio: Number of examples used to train each trees;\n",
            " |      expressed as a ratio of the training dataset size. Default: 1.0.\n",
            " |    bootstrap_training_dataset: If true (default), each tree is trained on a\n",
            " |      separate dataset sampled with replacement from the original dataset. If\n",
            " |      false, all the trees are trained on the entire same dataset. If\n",
            " |      bootstrap_training_dataset:false, OOB metrics are not available.\n",
            " |      bootstrap_training_dataset=false is used in \"Extremely randomized trees\"\n",
            " |      (https://link.springer.com/content/pdf/10.1007%2Fs10994-006-6226-1.pdf).\n",
            " |      Default: True.\n",
            " |    categorical_algorithm: How to learn splits on categorical attributes.\n",
            " |      - `CART`: CART algorithm. Find categorical splits of the form \"value \\\\in\n",
            " |        mask\". The solution is exact for binary classification, regression and\n",
            " |        ranking. It is approximated for multi-class classification. This is a\n",
            " |        good first algorithm to use. In case of overfitting (very small\n",
            " |        dataset, large dictionary), the \"random\" algorithm is a good\n",
            " |        alternative.\n",
            " |      - `ONE_HOT`: One-hot encoding. Find the optimal categorical split of the\n",
            " |        form \"attribute == param\". This method is similar (but more efficient)\n",
            " |        than converting converting each possible categorical value into a\n",
            " |        boolean feature. This method is available for comparison purpose and\n",
            " |        generally performs worse than other alternatives.\n",
            " |      - `RANDOM`: Best splits among a set of random candidate. Find the a\n",
            " |        categorical split of the form \"value \\\\in mask\" using a random search.\n",
            " |        This solution can be seen as an approximation of the CART algorithm.\n",
            " |        This method is a strong alternative to CART. This algorithm is inspired\n",
            " |        from section \"5.1 Categorical Variables\" of \"Random Forest\", 2001.\n",
            " |        Default: \"CART\".\n",
            " |    categorical_set_split_greedy_sampling: For categorical set splits e.g.\n",
            " |      texts. Probability for a categorical value to be a candidate for the\n",
            " |      positive set. The sampling is applied once per node (i.e. not at every\n",
            " |      step of the greedy optimization). Default: 0.1.\n",
            " |    categorical_set_split_max_num_items: For categorical set splits e.g. texts.\n",
            " |      Maximum number of items (prior to the sampling). If more items are\n",
            " |      available, the least frequent items are ignored. Changing this value is\n",
            " |      similar to change the \"max_vocab_count\" before loading the dataset, with\n",
            " |      the following exception: With `max_vocab_count`, all the remaining items\n",
            " |      are grouped in a special Out-of-vocabulary item. With `max_num_items`,\n",
            " |      this is not the case. Default: -1.\n",
            " |    categorical_set_split_min_item_frequency: For categorical set splits e.g.\n",
            " |      texts. Minimum number of occurrences of an item to be considered.\n",
            " |      Default: 1.\n",
            " |    compute_oob_performances: If true, compute the Out-of-bag evaluation (then\n",
            " |      available in the summary and model inspector). This evaluation is a cheap\n",
            " |      alternative to cross-validation evaluation. Default: True.\n",
            " |    compute_oob_variable_importances: If true, compute the Out-of-bag feature\n",
            " |      importance (then available in the summary and model inspector). Note that\n",
            " |      the OOB feature importance can be expensive to compute. Default: False.\n",
            " |    growing_strategy: How to grow the tree.\n",
            " |      - `LOCAL`: Each node is split independently of the other nodes. In other\n",
            " |        words, as long as a node satisfy the splits \"constraints (e.g. maximum\n",
            " |        depth, minimum number of observations), the node will be split. This is\n",
            " |        the \"classical\" way to grow decision trees.\n",
            " |      - `BEST_FIRST_GLOBAL`: The node with the best loss reduction among all\n",
            " |        the nodes of the tree is selected for splitting. This method is also\n",
            " |        called \"best first\" or \"leaf-wise growth\". See \"Best-first decision\n",
            " |        tree learning\", Shi and \"Additive logistic regression : A statistical\n",
            " |        view of boosting\", Friedman for more details. Default: \"LOCAL\".\n",
            " |    honest: In honest trees, different training examples are used to infer the\n",
            " |      structure and the leaf values. This regularization technique trades\n",
            " |      examples for bias estimates. It might increase or reduce the quality of\n",
            " |      the model. See \"Generalized Random Forests\", Athey et al. In this paper,\n",
            " |      Honest trees are trained with the Random Forest algorithm with a sampling\n",
            " |      without replacement. Default: False.\n",
            " |    honest_fixed_separation: For honest trees only i.e. honest=true. If true, a\n",
            " |      new random separation is generated for each tree. If false, the same\n",
            " |      separation is used for all the trees (e.g., in Gradient Boosted Trees\n",
            " |      containing multiple trees). Default: False.\n",
            " |    honest_ratio_leaf_examples: For honest trees only i.e. honest=true. Ratio\n",
            " |      of examples used to set the leaf values. Default: 0.5.\n",
            " |    in_split_min_examples_check: Whether to check the `min_examples` constraint\n",
            " |      in the split search (i.e. splits leading to one child having less than\n",
            " |      `min_examples` examples are considered invalid) or before the split\n",
            " |      search (i.e. a node can be derived only if it contains more than\n",
            " |      `min_examples` examples). If false, there can be nodes with less than\n",
            " |      `min_examples` training examples. Default: True.\n",
            " |    keep_non_leaf_label_distribution: Whether to keep the node value (i.e. the\n",
            " |      distribution of the labels of the training examples) of non-leaf nodes.\n",
            " |      This information is not used during serving, however it can be used for\n",
            " |      model interpretation as well as hyper parameter tuning. This can take\n",
            " |      lots of space, sometimes accounting for half of the model size. Default:\n",
            " |      True.\n",
            " |    max_depth: Maximum depth of the tree. `max_depth=1` means that all trees\n",
            " |      will be roots. Negative values are ignored. Default: 16.\n",
            " |    max_num_nodes: Maximum number of nodes in the tree. Set to -1 to disable\n",
            " |      this limit. Only available for `growing_strategy=BEST_FIRST_GLOBAL`.\n",
            " |      Default: None.\n",
            " |    maximum_model_size_in_memory_in_bytes: Limit the size of the model when\n",
            " |      stored in ram. Different algorithms can enforce this limit differently.\n",
            " |      Note that when models are compiled into an inference, the size of the\n",
            " |      inference engine is generally much smaller than the original model.\n",
            " |      Default: -1.0.\n",
            " |    maximum_training_duration_seconds: Maximum training duration of the model\n",
            " |      expressed in seconds. Each learning algorithm is free to use this\n",
            " |      parameter at it sees fit. Enabling maximum training duration makes the\n",
            " |      model training non-deterministic. Default: -1.0.\n",
            " |    min_examples: Minimum number of examples in a node. Default: 5.\n",
            " |    missing_value_policy: Method used to handle missing attribute values.\n",
            " |      - `GLOBAL_IMPUTATION`: Missing attribute values are imputed, with the\n",
            " |        mean (in case of numerical attribute) or the most-frequent-item (in\n",
            " |        case of categorical attribute) computed on the entire dataset (i.e. the\n",
            " |        information contained in the data spec).\n",
            " |      - `LOCAL_IMPUTATION`: Missing attribute values are imputed with the mean\n",
            " |        (numerical attribute) or most-frequent-item (in the case of categorical\n",
            " |        attribute) evaluated on the training examples in the current node.\n",
            " |      - `RANDOM_LOCAL_IMPUTATION`: Missing attribute values are imputed from\n",
            " |        randomly sampled values from the training examples in the current node.\n",
            " |        This method was proposed by Clinic et al. in \"Random Survival Forests\"\n",
            " |        (https://projecteuclid.org/download/pdfview_1/euclid.aoas/1223908043).\n",
            " |        Default: \"GLOBAL_IMPUTATION\".\n",
            " |    num_candidate_attributes: Number of unique valid attributes tested for each\n",
            " |      node. An attribute is valid if it has at least a valid split. If\n",
            " |      `num_candidate_attributes=0`, the value is set to the classical default\n",
            " |      value for Random Forest: `sqrt(number of input attributes)` in case of\n",
            " |      classification and `number_of_input_attributes / 3` in case of\n",
            " |      regression. If `num_candidate_attributes=-1`, all the attributes are\n",
            " |      tested. Default: 0.\n",
            " |    num_candidate_attributes_ratio: Ratio of attributes tested at each node. If\n",
            " |      set, it is equivalent to `num_candidate_attributes =\n",
            " |      number_of_input_features x num_candidate_attributes_ratio`. The possible\n",
            " |      values are between ]0, and 1] as well as -1. If not set or equal to -1,\n",
            " |      the `num_candidate_attributes` is used. Default: -1.0.\n",
            " |    num_oob_variable_importances_permutations: Number of time the dataset is\n",
            " |      re-shuffled to compute the permutation variable importances. Increasing\n",
            " |      this value increase the training time (if\n",
            " |      \"compute_oob_variable_importances:true\") as well as the stability of the\n",
            " |      oob variable importance metrics. Default: 1.\n",
            " |    num_trees: Number of individual decision trees. Increasing the number of\n",
            " |      trees can increase the quality of the model at the expense of size,\n",
            " |      training speed, and inference latency. Default: 300.\n",
            " |    pure_serving_model: Clear the model from any information that is not\n",
            " |      required for model serving. This includes debugging, model interpretation\n",
            " |      and other meta-data. The size of the serialized model can be reduced\n",
            " |      significatively (50% model size reduction is common). This parameter has\n",
            " |      no impact on the quality, serving speed or RAM usage of model serving.\n",
            " |      Default: False.\n",
            " |    random_seed: Random seed for the training of the model. Learners are\n",
            " |      expected to be deterministic by the random seed. Default: 123456.\n",
            " |    sampling_with_replacement: If true, the training examples are sampled with\n",
            " |      replacement. If false, the training samples are sampled without\n",
            " |      replacement. Only used when \"bootstrap_training_dataset=true\". If false\n",
            " |      (sampling without replacement) and if \"bootstrap_size_ratio=1\" (default),\n",
            " |      all the examples are used to train all the trees (you probably do not\n",
            " |      want that). Default: True.\n",
            " |    sorting_strategy: How are sorted the numerical features in order to find\n",
            " |      the splits\n",
            " |      - PRESORT: The features are pre-sorted at the start of the training. This\n",
            " |        solution is faster but consumes much more memory than IN_NODE.\n",
            " |      - IN_NODE: The features are sorted just before being used in the node.\n",
            " |        This solution is slow but consumes little amount of memory.\n",
            " |      . Default: \"PRESORT\".\n",
            " |    sparse_oblique_normalization: For sparse oblique splits i.e.\n",
            " |      `split_axis=SPARSE_OBLIQUE`. Normalization applied on the features,\n",
            " |      before applying the sparse oblique projections.\n",
            " |      - `NONE`: No normalization.\n",
            " |      - `STANDARD_DEVIATION`: Normalize the feature by the estimated standard\n",
            " |        deviation on the entire train dataset. Also known as Z-Score\n",
            " |        normalization.\n",
            " |      - `MIN_MAX`: Normalize the feature by the range (i.e. max-min) estimated\n",
            " |        on the entire train dataset. Default: None.\n",
            " |    sparse_oblique_num_projections_exponent: For sparse oblique splits i.e.\n",
            " |      `split_axis=SPARSE_OBLIQUE`. Controls of the number of random projections\n",
            " |      to test at each node as `num_features^num_projections_exponent`. Default:\n",
            " |      None.\n",
            " |    sparse_oblique_projection_density_factor: For sparse oblique splits i.e.\n",
            " |      `split_axis=SPARSE_OBLIQUE`. Controls of the number of random projections\n",
            " |      to test at each node as `num_features^num_projections_exponent`. Default:\n",
            " |      None.\n",
            " |    sparse_oblique_weights: For sparse oblique splits i.e.\n",
            " |      `split_axis=SPARSE_OBLIQUE`. Possible values:\n",
            " |      - `BINARY`: The oblique weights are sampled in {-1,1} (default).\n",
            " |      - `CONTINUOUS`: The oblique weights are be sampled in [-1,1]. Default:\n",
            " |        None.\n",
            " |    split_axis: What structure of split to consider for numerical features.\n",
            " |      - `AXIS_ALIGNED`: Axis aligned splits (i.e. one condition at a time).\n",
            " |        This is the \"classical\" way to train a tree. Default value.\n",
            " |      - `SPARSE_OBLIQUE`: Sparse oblique splits (i.e. splits one a small number\n",
            " |        of features) from \"Sparse Projection Oblique Random Forests\", Tomita et\n",
            " |        al., 2020. Default: \"AXIS_ALIGNED\".\n",
            " |    uplift_min_examples_in_treatment: For uplift models only. Minimum number of\n",
            " |      examples per treatment in a node. Default: 5.\n",
            " |    uplift_split_score: For uplift models only. Splitter score i.e. score\n",
            " |      optimized by the splitters. The scores are introduced in \"Decision trees\n",
            " |      for uplift modeling with single and multiple treatments\", Rzepakowski et\n",
            " |      al. Notation: `p` probability / average value of the positive outcome,\n",
            " |      `q` probability / average value in the control group.\n",
            " |      - `KULLBACK_LEIBLER` or `KL`: - p log (p/q)\n",
            " |      - `EUCLIDEAN_DISTANCE` or `ED`: (p-q)^2\n",
            " |      - `CHI_SQUARED` or `CS`: (p-q)^2/q\n",
            " |        Default: \"KULLBACK_LEIBLER\".\n",
            " |    winner_take_all: Control how classification trees vote. If true, each tree\n",
            " |      votes for one class. If false, each tree vote for a distribution of\n",
            " |      classes. winner_take_all_inference=false is often preferable. Default:\n",
            " |      True.\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      RandomForestModel\n",
            " |      tensorflow_decision_forests.keras.wrappers.RandomForestModel\n",
            " |      tensorflow_decision_forests.keras.core.CoreModel\n",
            " |      keras.engine.training.Model\n",
            " |      keras.engine.base_layer.Layer\n",
            " |      tensorflow.python.module.module.Module\n",
            " |      tensorflow.python.training.tracking.autotrackable.AutoTrackable\n",
            " |      tensorflow.python.training.tracking.base.Trackable\n",
            " |      keras.utils.version_utils.LayerVersionSelector\n",
            " |      keras.utils.version_utils.ModelVersionSelector\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods inherited from tensorflow_decision_forests.keras.wrappers.RandomForestModel:\n",
            " |  \n",
            " |  __init__ = wrapper(*args, **kargs)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Static methods inherited from tensorflow_decision_forests.keras.wrappers.RandomForestModel:\n",
            " |  \n",
            " |  capabilities() -> yggdrasil_decision_forests.learner.abstract_learner_pb2.LearnerCapabilities\n",
            " |      Lists the capabilities of the learning algorithm.\n",
            " |  \n",
            " |  predefined_hyperparameters() -> List[tensorflow_decision_forests.keras.core.HyperParameterTemplate]\n",
            " |      Returns a better than default set of hyper-parameters.\n",
            " |      \n",
            " |      They can be used directly with the `hyperparameter_template` argument of the\n",
            " |      model constructor.\n",
            " |      \n",
            " |      These hyper-parameters outperform the default hyper-parameters (either\n",
            " |      generally or in specific scenarios). Like default hyper-parameters, existing\n",
            " |      pre-defined hyper-parameters cannot change.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from tensorflow_decision_forests.keras.core.CoreModel:\n",
            " |  \n",
            " |  call(self, inputs, training=False)\n",
            " |      Inference of the model.\n",
            " |      \n",
            " |      This method is used for prediction and evaluation of a trained model.\n",
            " |      \n",
            " |      Args:\n",
            " |        inputs: Input tensors.\n",
            " |        training: Is the model being trained. Always False.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Model predictions.\n",
            " |  \n",
            " |  call_get_leaves(self, inputs)\n",
            " |      Computes the index of the active leaf in each tree.\n",
            " |      \n",
            " |      The active leaf is the leave that that receive the example during inference.\n",
            " |      \n",
            " |      The returned value \"leaves[i,j]\" is the index of the active leave for the\n",
            " |      i-th example and the j-th tree. Leaves are indexed by depth first\n",
            " |      exploration with the negative child visited before the positive one\n",
            " |      (similarly as \"iterate_on_nodes()\" iteration). Leaf indices are also\n",
            " |      available with LeafNode.leaf_idx.\n",
            " |      \n",
            " |      Args:\n",
            " |        inputs: Input tensors. Same signature as the model's \"call(inputs)\".\n",
            " |      \n",
            " |      Returns:\n",
            " |        Index of the active leaf for each tree in the model.\n",
            " |  \n",
            " |  collect_data_step(self, data, is_training_example)\n",
            " |      Collect examples e.g. training or validation.\n",
            " |  \n",
            " |  compile(self, metrics=None, weighted_metrics=None)\n",
            " |      Configure the model for training.\n",
            " |      \n",
            " |      Unlike for most Keras model, calling \"compile\" is optional before calling\n",
            " |      \"fit\".\n",
            " |      \n",
            " |      Args:\n",
            " |        metrics: List of metrics to be evaluated by the model during training and\n",
            " |          testing.\n",
            " |        weighted_metrics: List of metrics to be evaluated and weighted by\n",
            " |          `sample_weight` or `class_weight` during training and testing.\n",
            " |      \n",
            " |      Raises:\n",
            " |        ValueError: Invalid arguments.\n",
            " |  \n",
            " |  fit(self, x=None, y=None, callbacks=None, verbose: Union[Any, NoneType] = None, validation_steps: Union[int, NoneType] = None, validation_data: Union[Any, NoneType] = None, sample_weight: Union[Any, NoneType] = None, steps_per_epoch: Union[Any, NoneType] = None, class_weight: Union[Any, NoneType] = None, **kwargs) -> keras.callbacks.History\n",
            " |      Trains the model.\n",
            " |      \n",
            " |      Local training\n",
            " |      ==============\n",
            " |      \n",
            " |      It is recommended to use a Pandas Dataframe dataset and to convert it to\n",
            " |      a TensorFlow dataset with \"pd_dataframe_to_tf_dataset()\":\n",
            " |      \n",
            " |        pd_dataset = pandas.Dataframe(...)\n",
            " |        tf_dataset = pd_dataframe_to_tf_dataset(dataset, label=\"my_label\")\n",
            " |        model.fit(pd_dataset)\n",
            " |      \n",
            " |      The following dataset formats are supported:\n",
            " |      \n",
            " |        1. \"x\" is a tf.data.Dataset containing a tuple \"(features, labels)\".\n",
            " |           \"features\" can be a dictionary a tensor, a list of tensors or a\n",
            " |           dictionary of tensors (recommended). \"labels\" is a tensor.\n",
            " |      \n",
            " |        2. \"x\" is a tensor, list of tensors or dictionary of tensors containing\n",
            " |           the input features. \"y\" is a tensor.\n",
            " |      \n",
            " |        3. \"x\" is a numpy-array, list of numpy-arrays or dictionary of\n",
            " |           numpy-arrays containing the input features. \"y\" is a numpy-array.\n",
            " |      \n",
            " |      IMPORTANT: This model trains on the entire dataset at once. This has the\n",
            " |      following consequences:\n",
            " |      \n",
            " |        1. The dataset need to be read exactly once. If you use a TensorFlow\n",
            " |           dataset, make sure NOT to add a \"repeat\" operation.\n",
            " |        2. The algorithm does not benefit from shuffling the dataset. If you use a\n",
            " |           TensorFlow dataset, make sure NOT to add a \"shuffle\" operation.\n",
            " |        3. The dataset needs to be batched (i.e. with a \"batch\" operation).\n",
            " |           However, the number of elements per batch has not impact on the model.\n",
            " |           Generally, it is recommended to use batches as large as possible as its\n",
            " |           speeds-up reading the dataset in TensorFlow.\n",
            " |      \n",
            " |      Input features do not need to be normalized (e.g. dividing numerical values\n",
            " |      by the variance) or indexed (e.g. replacing categorical string values by\n",
            " |      an integer). Additionnaly, missing values can be consumed natigely.\n",
            " |      \n",
            " |      Distributed training\n",
            " |      ====================\n",
            " |      \n",
            " |      Some of the learning algorithms will support distributed training with the\n",
            " |      ParameterServerStrategy.\n",
            " |      \n",
            " |      In this case, the dataset is read asynchronously in between the workers. The\n",
            " |      distribution of the training depends on the learning algorithm.\n",
            " |      \n",
            " |      Like for non-distributed training, the dataset should be read eactly once.\n",
            " |      The simplest solution is to divide the dataset into different files (i.e.\n",
            " |      shards) and have each of the worker read a non overlapping subset of shards.\n",
            " |      \n",
            " |      IMPORTANT: The training dataset should not be infinite i.e. the training\n",
            " |      dataset should not contain any repeat operation.\n",
            " |      \n",
            " |      Currently (to be changed), the validation dataset (if provided) is simply\n",
            " |      feed to the \"model.evaluate()\" method. Therefore, it should satify Keras'\n",
            " |      evaluate API. Notably, for distributed training, the validation dataset\n",
            " |      should be infinite (i.e. have a repeat operation).\n",
            " |      \n",
            " |      See https://www.tensorflow.org/decision_forests/distributed_training for\n",
            " |      more details and examples.\n",
            " |      \n",
            " |      Here is a single example of distributed training using PSS for both dataset\n",
            " |      reading and training distribution.\n",
            " |      \n",
            " |        def dataset_fn(context, paths, training=True):\n",
            " |          ds_path = tf.data.Dataset.from_tensor_slices(paths)\n",
            " |      \n",
            " |      \n",
            " |          if context is not None:\n",
            " |            # Train on at least 2 workers.\n",
            " |            current_worker = tfdf.keras.get_worker_idx_and_num_workers(context)\n",
            " |            assert current_worker.num_workers > 2\n",
            " |      \n",
            " |            # Split the dataset's examples among the workers.\n",
            " |            ds_path = ds_path.shard(\n",
            " |                num_shards=current_worker.num_workers,\n",
            " |                index=current_worker.worker_idx)\n",
            " |      \n",
            " |          def read_csv_file(path):\n",
            " |            numerical = tf.constant([math.nan], dtype=tf.float32)\n",
            " |            categorical_string = tf.constant([\"\"], dtype=tf.string)\n",
            " |            csv_columns = [\n",
            " |                numerical,  # age\n",
            " |                categorical_string,  # workclass\n",
            " |                numerical,  # fnlwgt\n",
            " |                ...\n",
            " |            ]\n",
            " |            column_names = [\n",
            " |              \"age\", \"workclass\", \"fnlwgt\", ...\n",
            " |            ]\n",
            " |            label_name = \"label\"\n",
            " |            return tf.data.experimental.CsvDataset(path, csv_columns, header=True)\n",
            " |      \n",
            " |          ds_columns = ds_path.interleave(read_csv_file)\n",
            " |      \n",
            " |          def map_features(*columns):\n",
            " |            assert len(column_names) == len(columns)\n",
            " |            features = {column_names[i]: col for i, col in enumerate(columns)}\n",
            " |            label = label_table.lookup(features.pop(label_name))\n",
            " |            return features, label\n",
            " |      \n",
            " |          ds_dataset = ds_columns.map(map_features)\n",
            " |          if not training:\n",
            " |            dataset = dataset.repeat(None)\n",
            " |          ds_dataset = ds_dataset.batch(batch_size)\n",
            " |          return ds_dataset\n",
            " |      \n",
            " |        strategy = tf.distribute.experimental.ParameterServerStrategy(...)\n",
            " |        sharded_train_paths = [list of dataset files]\n",
            " |        with strategy.scope():\n",
            " |          model = DistributedGradientBoostedTreesModel()\n",
            " |          train_dataset = strategy.distribute_datasets_from_function(\n",
            " |            lambda context: dataset_fn(context, sharded_train_paths))\n",
            " |      \n",
            " |          test_dataset = strategy.distribute_datasets_from_function(\n",
            " |            lambda context: dataset_fn(context, sharded_test_paths))\n",
            " |      \n",
            " |        model.fit(sharded_train_paths)\n",
            " |        evaluation = model.evaluate(test_dataset, steps=num_test_examples //\n",
            " |          batch_size)\n",
            " |      \n",
            " |      Args:\n",
            " |        x: Training dataset (See details above for the supported formats).\n",
            " |        y: Label of the training dataset. Only used if \"x\" does not contains the\n",
            " |          labels.\n",
            " |        callbacks: Callbacks triggered during the training. The training runs in a\n",
            " |          single epoch, itself run in a single step. Therefore, callback logic can\n",
            " |          be called equivalently before/after the fit function.\n",
            " |        verbose: Verbosity mode. 0 = silent, 1 = small details, 2 = full details.\n",
            " |        validation_steps: Number of steps in the evaluation dataset when\n",
            " |          evaluating the trained model with model.evaluate(). If not specified,\n",
            " |          evaluates the model on the entire dataset (generally recommended; not\n",
            " |          yet supported for distributed datasets).\n",
            " |        validation_data: Validation dataset. If specified, the learner might use\n",
            " |          this dataset to help training e.g. early stopping.\n",
            " |        sample_weight: Training weights. Note: training weights can also be\n",
            " |          provided as the third output in a tf.data.Dataset e.g. (features, label,\n",
            " |          weights).\n",
            " |        steps_per_epoch: [Parameter will be removed] Number of training batch to\n",
            " |          load before training the model. Currently, only supported for\n",
            " |          distributed training.\n",
            " |        class_weight: For binary classification only. Mapping class indices\n",
            " |          (integers) to a weight (float) value. Only available for non-Distributed\n",
            " |          training. For maximum compatibility, feed example weights through the\n",
            " |          tf.data.Dataset or using the `weight` argument of\n",
            " |          pd_dataframe_to_tf_dataset.\n",
            " |        **kwargs: Extra arguments passed to the core keras model's fit. Note that\n",
            " |          not all keras' model fit arguments are supported.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `History` object. Its `History.history` attribute is not yet\n",
            " |        implemented for decision forests algorithms, and will return empty.\n",
            " |        All other fields are filled as usual for `Keras.Mode.fit()`.\n",
            " |  \n",
            " |  fit_on_dataset_path(self, train_path: str, label_key: str, weight_key: Union[str, NoneType] = None, ranking_key: Union[str, NoneType] = None, valid_path: Union[str, NoneType] = None, dataset_format: Union[str, NoneType] = 'csv', max_num_scanned_rows_to_accumulate_statistics: Union[int, NoneType] = 100000, try_resume_training: Union[bool, NoneType] = True, input_model_signature_fn: Union[Callable[[tensorflow_decision_forests.component.inspector.inspector.AbstractInspector], Any], NoneType] = <function build_default_input_model_signature at 0x7fd28a899ef0>)\n",
            " |      Trains the model on a dataset stored on disk.\n",
            " |      \n",
            " |      This solution is generally more efficient and easier that loading the\n",
            " |      dataset with a tf.Dataset both for local and distributed training.\n",
            " |      \n",
            " |      Usage example:\n",
            " |      \n",
            " |        # Local training\n",
            " |        model = model = keras.GradientBoostedTreesModel()\n",
            " |        model.fit_on_dataset_path(\n",
            " |          train_path=\"/path/to/dataset.csv\",\n",
            " |          label_key=\"label\",\n",
            " |          dataset_format=\"csv\")\n",
            " |        model.save(\"/model/path\")\n",
            " |      \n",
            " |        # Distributed training\n",
            " |        with tf.distribute.experimental.ParameterServerStrategy(...).scope():\n",
            " |          model = model = keras.DistributedGradientBoostedTreesModel()\n",
            " |        model.fit_on_dataset_path(\n",
            " |          train_path=\"/path/to/dataset@10\",\n",
            " |          label_key=\"label\",\n",
            " |          dataset_format=\"tfrecord+tfe\")\n",
            " |        model.save(\"/model/path\")\n",
            " |      \n",
            " |      Args:\n",
            " |         train_path: Path to the training dataset. Support comma separated files,\n",
            " |           shard and glob notation.\n",
            " |         label_key: Name of the label column.\n",
            " |         weight_key: Name of the weighing column.\n",
            " |         ranking_key: Name of the ranking column.\n",
            " |         valid_path: Path to the validation dataset. If not provided, or if the\n",
            " |           learning algorithm does not support/need a validation dataset,\n",
            " |           `valid_path` is ignored.\n",
            " |         dataset_format: Format of the dataset. Should be one of the registered\n",
            " |           dataset format (see\n",
            " |           https://github.com/google/yggdrasil-decision-forests/blob/main/documentation/user_manual.md#dataset-path-and-format\n",
            " |             for more details). The format \"csv\" always available but it is\n",
            " |             generally only suited for small datasets.\n",
            " |        max_num_scanned_rows_to_accumulate_statistics: Maximum number of examples\n",
            " |          to scan to determine the statistics of the features (i.e. the dataspec,\n",
            " |          e.g. mean value, dictionaries). (Currently) the \"first\" examples of the\n",
            " |          dataset are scanned (e.g. the first examples of the dataset is a single\n",
            " |          file). Therefore, it is important that the sampled dataset is relatively\n",
            " |          uniformly sampled, notably the scanned examples should contains all the\n",
            " |          possible categorical values (otherwise the not seen value will be\n",
            " |          treated as out-of-vocabulary). If set to None, the entire dataset is\n",
            " |          scanned. This parameter has no effect if the dataset is stored in a\n",
            " |          format that already contains those values.\n",
            " |        try_resume_training: If true, tries to resume training from the model\n",
            " |          checkpoint stored in the `temp_directory` directory. If `temp_directory`\n",
            " |          does not contain any model checkpoint, start the training from the\n",
            " |          start. Works in the following three situations: (1) The training was\n",
            " |          interrupted by the user (e.g. ctrl+c). (2) the training job was\n",
            " |          interrupted (e.g. rescheduling), ond (3) the hyper-parameter of the\n",
            " |          model were changed such that an initially completed training is now\n",
            " |          incomplete (e.g. increasing the number of trees).\n",
            " |        input_model_signature_fn: A lambda that returns the\n",
            " |          (Dense,Sparse,Ragged)TensorSpec (or structure of TensorSpec e.g.\n",
            " |          dictionary, list) corresponding to input signature of the model. If not\n",
            " |          specified, the input model signature is created by\n",
            " |          \"build_default_input_model_signature\". For example, specify\n",
            " |          \"input_model_signature_fn\" if an numerical input feature (which is\n",
            " |          consumed as DenseTensorSpec(float32) by default) will be feed\n",
            " |          differently (e.g. RaggedTensor(int64)).\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `History` object. Its `History.history` attribute is not yet\n",
            " |        implemented for decision forests algorithms, and will return empty.\n",
            " |        All other fields are filled as usual for `Keras.Mode.fit()`.\n",
            " |  \n",
            " |  load_weights(self, *args, **kwargs)\n",
            " |      No-op for TensorFlow Decision Forests models.\n",
            " |      \n",
            " |      `load_weights` is not supported by TensorFlow Decision Forests models.\n",
            " |      To save and restore a model, use the SavedModel API i.e.\n",
            " |      `model.save(...)` and `tf.keras.models.load_model(...)`. To resume the\n",
            " |      training of an existing model, create the model with\n",
            " |      `try_resume_training=True` (default value) and with a similar\n",
            " |      `temp_directory` argument. See documentation of `try_resume_training`\n",
            " |      for more details.\n",
            " |      \n",
            " |      Args:\n",
            " |        *args: Passed through to base `keras.Model` implemenation.\n",
            " |        **kwargs: Passed through to base `keras.Model` implemenation.\n",
            " |  \n",
            " |  make_inspector(self) -> tensorflow_decision_forests.component.inspector.inspector.AbstractInspector\n",
            " |      Creates an inspector to access the internal model structure.\n",
            " |      \n",
            " |      Usage example:\n",
            " |      \n",
            " |      ```python\n",
            " |      inspector = model.make_inspector()\n",
            " |      print(inspector.num_trees())\n",
            " |      print(inspector.variable_importances())\n",
            " |      ```\n",
            " |      \n",
            " |      Returns:\n",
            " |        A model inspector.\n",
            " |  \n",
            " |  make_predict_function(self)\n",
            " |      Prediction of the model (!= evaluation).\n",
            " |  \n",
            " |  make_test_function(self)\n",
            " |      Predictions for evaluation.\n",
            " |  \n",
            " |  predict_get_leaves(self, x)\n",
            " |      Gets the index of the active leaf of each tree.\n",
            " |      \n",
            " |      The active leaf is the leave that that receive the example during inference.\n",
            " |      \n",
            " |      The returned value \"leaves[i,j]\" is the index of the active leave for the\n",
            " |      i-th example and the j-th tree. Leaves are indexed by depth first\n",
            " |      exploration with the negative child visited before the positive one\n",
            " |      (similarly as \"iterate_on_nodes()\" iteration). Leaf indices are also\n",
            " |      available with LeafNode.leaf_idx.\n",
            " |      \n",
            " |      Args:\n",
            " |        x: Input samples as a tf.data.Dataset.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Index of the active leaf for each tree in the model.\n",
            " |  \n",
            " |  save(self, filepath: str, overwrite: Union[bool, NoneType] = True, **kwargs)\n",
            " |      Saves the model as a TensorFlow SavedModel.\n",
            " |      \n",
            " |      The exported SavedModel contains a standalone Yggdrasil Decision Forests\n",
            " |      model in the \"assets\" sub-directory. The Yggdrasil model can be used\n",
            " |      directly using the Yggdrasil API. However, this model does not contain the\n",
            " |      \"preprocessing\" layer (if any).\n",
            " |      \n",
            " |      Args:\n",
            " |        filepath: Path to the output model.\n",
            " |        overwrite: If true, override an already existing model. If false, raise an\n",
            " |          error if a model already exist.\n",
            " |        **kwargs: Arguments passed to the core keras model's save.\n",
            " |  \n",
            " |  summary(self, line_length=None, positions=None, print_fn=None)\n",
            " |      Shows information about the model.\n",
            " |  \n",
            " |  train_step(self, data)\n",
            " |      Collects training examples.\n",
            " |  \n",
            " |  valid_step(self, data)\n",
            " |      Collects validation examples.\n",
            " |  \n",
            " |  yggdrasil_model_path_tensor(self) -> Union[tensorflow.python.framework.ops.Tensor, NoneType]\n",
            " |      Gets the path to yggdrasil model, if available.\n",
            " |      \n",
            " |      The effective path can be obtained with:\n",
            " |      \n",
            " |      ```python\n",
            " |      yggdrasil_model_path_tensor().numpy().decode(\"utf-8\")\n",
            " |      ```\n",
            " |      \n",
            " |      Returns:\n",
            " |        Path to the Yggdrasil model.\n",
            " |  \n",
            " |  yggdrasil_model_prefix(self) -> str\n",
            " |      Gets the prefix of the internal yggdrasil model.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from tensorflow_decision_forests.keras.core.CoreModel:\n",
            " |  \n",
            " |  exclude_non_specified_features\n",
            " |      If true, only use the features specified in \"features\".\n",
            " |  \n",
            " |  learner\n",
            " |      Name of the learning algorithm used to train the model.\n",
            " |  \n",
            " |  learner_params\n",
            " |      Gets the dictionary of hyper-parameters passed in the model constructor.\n",
            " |      \n",
            " |      Changing this dictionary will impact the training.\n",
            " |  \n",
            " |  num_threads\n",
            " |      Number of threads used to train the model.\n",
            " |  \n",
            " |  num_training_examples\n",
            " |      Number of training examples.\n",
            " |  \n",
            " |  num_validation_examples\n",
            " |      Number of validation examples.\n",
            " |  \n",
            " |  task\n",
            " |      Task to solve (e.g. CLASSIFICATION, REGRESSION, RANKING).\n",
            " |  \n",
            " |  training_model_id\n",
            " |      Identifier of the model.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from keras.engine.training.Model:\n",
            " |  \n",
            " |  __call__(self, *args, **kwargs)\n",
            " |  \n",
            " |  __copy__(self)\n",
            " |  \n",
            " |  __deepcopy__(self, memo)\n",
            " |  \n",
            " |  __reduce__(self)\n",
            " |      Helper for pickle.\n",
            " |  \n",
            " |  __setattr__(self, name, value)\n",
            " |      Support self.foo = trackable syntax.\n",
            " |  \n",
            " |  build(self, input_shape)\n",
            " |      Builds the model based on input shapes received.\n",
            " |      \n",
            " |      This is to be used for subclassed models, which do not know at instantiation\n",
            " |      time what their inputs look like.\n",
            " |      \n",
            " |      This method only exists for users who want to call `model.build()` in a\n",
            " |      standalone way (as a substitute for calling the model on real data to\n",
            " |      build it). It will never be called by the framework (and thus it will\n",
            " |      never throw unexpected errors in an unrelated workflow).\n",
            " |      \n",
            " |      Args:\n",
            " |       input_shape: Single tuple, `TensorShape` instance, or list/dict of shapes,\n",
            " |         where shapes are tuples, integers, or `TensorShape` instances.\n",
            " |      \n",
            " |      Raises:\n",
            " |        ValueError:\n",
            " |          1. In case of invalid user-provided data (not of type tuple,\n",
            " |             list, `TensorShape`, or dict).\n",
            " |          2. If the model requires call arguments that are agnostic\n",
            " |             to the input shapes (positional or keyword arg in call signature).\n",
            " |          3. If not all layers were properly built.\n",
            " |          4. If float type inputs are not supported within the layers.\n",
            " |      \n",
            " |        In each of these cases, the user should build their model by calling it\n",
            " |        on real tensor data.\n",
            " |  \n",
            " |  compute_loss(self, x=None, y=None, y_pred=None, sample_weight=None)\n",
            " |      Compute the total loss, validate it, and return it.\n",
            " |      \n",
            " |      Subclasses can optionally override this method to provide custom loss\n",
            " |      computation logic.\n",
            " |      \n",
            " |      Example:\n",
            " |      ```python\n",
            " |      class MyModel(tf.keras.Model):\n",
            " |      \n",
            " |        def __init__(self, *args, **kwargs):\n",
            " |          super(MyModel, self).__init__(*args, **kwargs)\n",
            " |          self.loss_tracker = tf.keras.metrics.Mean(name='loss')\n",
            " |      \n",
            " |        def compute_loss(self, x, y, y_pred, sample_weight):\n",
            " |          loss = tf.reduce_mean(tf.math.squared_difference(y_pred, y))\n",
            " |          loss += tf.add_n(self.losses)\n",
            " |          self.loss_tracker.update_state(loss)\n",
            " |          return loss\n",
            " |      \n",
            " |        def reset_metrics(self):\n",
            " |          self.loss_tracker.reset_states()\n",
            " |      \n",
            " |        @property\n",
            " |        def metrics(self):\n",
            " |          return [self.loss_tracker]\n",
            " |      \n",
            " |      tensors = tf.random.uniform((10, 10)), tf.random.uniform((10,))\n",
            " |      dataset = tf.data.Dataset.from_tensor_slices(tensors).repeat().batch(1)\n",
            " |      \n",
            " |      inputs = tf.keras.layers.Input(shape=(10,), name='my_input')\n",
            " |      outputs = tf.keras.layers.Dense(10)(inputs)\n",
            " |      model = MyModel(inputs, outputs)\n",
            " |      model.add_loss(tf.reduce_sum(outputs))\n",
            " |      \n",
            " |      optimizer = tf.keras.optimizers.SGD()\n",
            " |      model.compile(optimizer, loss='mse', steps_per_execution=10)\n",
            " |      model.fit(dataset, epochs=2, steps_per_epoch=10)\n",
            " |      print('My custom loss: ', model.loss_tracker.result().numpy())\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |        x: Input data.\n",
            " |        y: Target data.\n",
            " |        y_pred: Predictions returned by the model (output of `model(x)`)\n",
            " |        sample_weight: Sample weights for weighting the loss function.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The total loss as a `tf.Tensor`, or `None` if no loss results (which is\n",
            " |        the case when called by `Model.test_step`).\n",
            " |  \n",
            " |  compute_metrics(self, x, y, y_pred, sample_weight)\n",
            " |      Update metric states and collect all metrics to be returned.\n",
            " |      \n",
            " |      Subclasses can optionally override this method to provide custom metric\n",
            " |      updating and collection logic.\n",
            " |      \n",
            " |      Example:\n",
            " |      ```python\n",
            " |      class MyModel(tf.keras.Sequential):\n",
            " |      \n",
            " |        def compute_metrics(self, x, y, y_pred, sample_weight):\n",
            " |      \n",
            " |          # This super call updates `self.compiled_metrics` and returns results\n",
            " |          # for all metrics listed in `self.metrics`.\n",
            " |          metric_results = super(MyModel, self).compute_metrics(\n",
            " |              x, y, y_pred, sample_weight)\n",
            " |      \n",
            " |          # Note that `self.custom_metric` is not listed in `self.metrics`.\n",
            " |          self.custom_metric.update_state(x, y, y_pred, sample_weight)\n",
            " |          metric_results['custom_metric_name'] = self.custom_metric.result()\n",
            " |          return metric_results\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |        x: Input data.\n",
            " |        y: Target data.\n",
            " |        y_pred: Predictions returned by the model (output of `model.call(x)`)\n",
            " |        sample_weight: Sample weights for weighting the loss function.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `dict` containing values that will be passed to\n",
            " |        `tf.keras.callbacks.CallbackList.on_train_batch_end()`. Typically, the\n",
            " |        values of the metrics listed in `self.metrics` are returned. Example:\n",
            " |        `{'loss': 0.2, 'accuracy': 0.7}`.\n",
            " |  \n",
            " |  evaluate(self, x=None, y=None, batch_size=None, verbose='auto', sample_weight=None, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, return_dict=False, **kwargs)\n",
            " |      Returns the loss value & metrics values for the model in test mode.\n",
            " |      \n",
            " |      Computation is done in batches (see the `batch_size` arg.)\n",
            " |      \n",
            " |      Args:\n",
            " |          x: Input data. It could be:\n",
            " |            - A Numpy array (or array-like), or a list of arrays\n",
            " |              (in case the model has multiple inputs).\n",
            " |            - A TensorFlow tensor, or a list of tensors\n",
            " |              (in case the model has multiple inputs).\n",
            " |            - A dict mapping input names to the corresponding array/tensors,\n",
            " |              if the model has named inputs.\n",
            " |            - A `tf.data` dataset. Should return a tuple\n",
            " |              of either `(inputs, targets)` or\n",
            " |              `(inputs, targets, sample_weights)`.\n",
            " |            - A generator or `keras.utils.Sequence` returning `(inputs, targets)`\n",
            " |              or `(inputs, targets, sample_weights)`.\n",
            " |            A more detailed description of unpacking behavior for iterator types\n",
            " |            (Dataset, generator, Sequence) is given in the `Unpacking behavior\n",
            " |            for iterator-like inputs` section of `Model.fit`.\n",
            " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
            " |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
            " |            (you cannot have Numpy inputs and tensor targets, or inversely). If\n",
            " |            `x` is a dataset, generator or `keras.utils.Sequence` instance, `y`\n",
            " |            should not be specified (since targets will be obtained from the\n",
            " |            iterator/dataset).\n",
            " |          batch_size: Integer or `None`. Number of samples per batch of\n",
            " |            computation. If unspecified, `batch_size` will default to 32. Do not\n",
            " |            specify the `batch_size` if your data is in the form of a dataset,\n",
            " |            generators, or `keras.utils.Sequence` instances (since they generate\n",
            " |            batches).\n",
            " |          verbose: `\"auto\"`, 0, 1, or 2. Verbosity mode.\n",
            " |              0 = silent, 1 = progress bar, 2 = single line.\n",
            " |              `\"auto\"` defaults to 1 for most cases, and to 2 when used with\n",
            " |              `ParameterServerStrategy`. Note that the progress bar is not\n",
            " |              particularly useful when logged to a file, so `verbose=2` is\n",
            " |              recommended when not running interactively (e.g. in a production\n",
            " |              environment).\n",
            " |          sample_weight: Optional Numpy array of weights for the test samples,\n",
            " |            used for weighting the loss function. You can either pass a flat (1D)\n",
            " |            Numpy array with the same length as the input samples\n",
            " |              (1:1 mapping between weights and samples), or in the case of\n",
            " |                temporal data, you can pass a 2D array with shape `(samples,\n",
            " |                sequence_length)`, to apply a different weight to every timestep\n",
            " |                of every sample. This argument is not supported when `x` is a\n",
            " |                dataset, instead pass sample weights as the third element of `x`.\n",
            " |          steps: Integer or `None`. Total number of steps (batches of samples)\n",
            " |            before declaring the evaluation round finished. Ignored with the\n",
            " |            default value of `None`. If x is a `tf.data` dataset and `steps` is\n",
            " |            None, 'evaluate' will run until the dataset is exhausted. This\n",
            " |            argument is not supported with array inputs.\n",
            " |          callbacks: List of `keras.callbacks.Callback` instances. List of\n",
            " |            callbacks to apply during evaluation. See\n",
            " |            [callbacks](/api_docs/python/tf/keras/callbacks).\n",
            " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
            " |            input only. Maximum size for the generator queue. If unspecified,\n",
            " |            `max_queue_size` will default to 10.\n",
            " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
            " |            only. Maximum number of processes to spin up when using process-based\n",
            " |            threading. If unspecified, `workers` will default to 1.\n",
            " |          use_multiprocessing: Boolean. Used for generator or\n",
            " |            `keras.utils.Sequence` input only. If `True`, use process-based\n",
            " |            threading. If unspecified, `use_multiprocessing` will default to\n",
            " |            `False`. Note that because this implementation relies on\n",
            " |            multiprocessing, you should not pass non-picklable arguments to the\n",
            " |            generator as they can't be passed easily to children processes.\n",
            " |          return_dict: If `True`, loss and metric results are returned as a dict,\n",
            " |            with each key being the name of the metric. If `False`, they are\n",
            " |            returned as a list.\n",
            " |          **kwargs: Unused at this time.\n",
            " |      \n",
            " |      See the discussion of `Unpacking behavior for iterator-like inputs` for\n",
            " |      `Model.fit`.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Scalar test loss (if the model has a single output and no metrics)\n",
            " |          or list of scalars (if the model has multiple outputs\n",
            " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
            " |          the display labels for the scalar outputs.\n",
            " |      \n",
            " |      Raises:\n",
            " |          RuntimeError: If `model.evaluate` is wrapped in a `tf.function`.\n",
            " |  \n",
            " |  evaluate_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
            " |      Evaluates the model on a data generator.\n",
            " |      \n",
            " |      DEPRECATED:\n",
            " |        `Model.evaluate` now supports generators, so there is no longer any need\n",
            " |        to use this endpoint.\n",
            " |  \n",
            " |  fit_generator(self, generator, steps_per_epoch=None, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, validation_freq=1, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)\n",
            " |      Fits the model on data yielded batch-by-batch by a Python generator.\n",
            " |      \n",
            " |      DEPRECATED:\n",
            " |        `Model.fit` now supports generators, so there is no longer any need to use\n",
            " |        this endpoint.\n",
            " |  \n",
            " |  get_config(self)\n",
            " |      Returns the config of the `Model`.\n",
            " |      \n",
            " |      Config is a Python dictionary (serializable) containing the configuration of\n",
            " |      an object, which in this case is a `Model`. This allows the `Model` to be\n",
            " |      be reinstantiated later (without its trained weights) from this\n",
            " |      configuration.\n",
            " |      \n",
            " |      Note that `get_config()` does not guarantee to return a fresh copy of dict\n",
            " |      every time it is called. The callers should make a copy of the returned dict\n",
            " |      if they want to modify it.\n",
            " |      \n",
            " |      Developers of subclassed `Model` are advised to override this method, and\n",
            " |      continue to update the dict from `super(MyModel, self).get_config()`\n",
            " |      to provide the proper configuration of this `Model`. The default config\n",
            " |      is an empty dict. Optionally, raise `NotImplementedError` to allow Keras to\n",
            " |      attempt a default serialization.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Python dictionary containing the configuration of this `Model`.\n",
            " |  \n",
            " |  get_layer(self, name=None, index=None)\n",
            " |      Retrieves a layer based on either its name (unique) or index.\n",
            " |      \n",
            " |      If `name` and `index` are both provided, `index` will take precedence.\n",
            " |      Indices are based on order of horizontal graph traversal (bottom-up).\n",
            " |      \n",
            " |      Args:\n",
            " |          name: String, name of layer.\n",
            " |          index: Integer, index of layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A layer instance.\n",
            " |  \n",
            " |  get_weights(self)\n",
            " |      Retrieves the weights of the model.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A flat list of Numpy arrays.\n",
            " |  \n",
            " |  make_train_function(self, force=False)\n",
            " |      Creates a function that executes one step of training.\n",
            " |      \n",
            " |      This method can be overridden to support custom training logic.\n",
            " |      This method is called by `Model.fit` and `Model.train_on_batch`.\n",
            " |      \n",
            " |      Typically, this method directly controls `tf.function` and\n",
            " |      `tf.distribute.Strategy` settings, and delegates the actual training\n",
            " |      logic to `Model.train_step`.\n",
            " |      \n",
            " |      This function is cached the first time `Model.fit` or\n",
            " |      `Model.train_on_batch` is called. The cache is cleared whenever\n",
            " |      `Model.compile` is called. You can skip the cache and generate again the\n",
            " |      function with `force=True`.\n",
            " |      \n",
            " |      Args:\n",
            " |        force: Whether to regenerate the train function and skip the cached\n",
            " |          function if available.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Function. The function created by this method should accept a\n",
            " |        `tf.data.Iterator`, and return a `dict` containing values that will\n",
            " |        be passed to `tf.keras.Callbacks.on_train_batch_end`, such as\n",
            " |        `{'loss': 0.2, 'accuracy': 0.7}`.\n",
            " |  \n",
            " |  predict(self, x, batch_size=None, verbose='auto', steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
            " |      Generates output predictions for the input samples.\n",
            " |      \n",
            " |      Computation is done in batches. This method is designed for batch processing\n",
            " |      of large numbers of inputs. It is not intended for use inside of loops\n",
            " |      that iterate over your data and process small numbers of inputs at a time.\n",
            " |      \n",
            " |      For small numbers of inputs that fit in one batch,\n",
            " |      directly use `__call__()` for faster execution, e.g.,\n",
            " |      `model(x)`, or `model(x, training=False)` if you have layers such as\n",
            " |      `tf.keras.layers.BatchNormalization` that behave differently during\n",
            " |      inference. You may pair the individual model call with a `tf.function`\n",
            " |      for additional performance inside your inner loop.\n",
            " |      If you need access to numpy array values instead of tensors after your\n",
            " |      model call, you can use `tensor.numpy()` to get the numpy array value of\n",
            " |      an eager tensor.\n",
            " |      \n",
            " |      Also, note the fact that test loss is not affected by\n",
            " |      regularization layers like noise and dropout.\n",
            " |      \n",
            " |      Note: See [this FAQ entry](\n",
            " |      https://keras.io/getting_started/faq/#whats-the-difference-between-model-methods-predict-and-call)\n",
            " |      for more details about the difference between `Model` methods `predict()`\n",
            " |      and `__call__()`.\n",
            " |      \n",
            " |      Args:\n",
            " |          x: Input samples. It could be:\n",
            " |            - A Numpy array (or array-like), or a list of arrays\n",
            " |              (in case the model has multiple inputs).\n",
            " |            - A TensorFlow tensor, or a list of tensors\n",
            " |              (in case the model has multiple inputs).\n",
            " |            - A `tf.data` dataset.\n",
            " |            - A generator or `keras.utils.Sequence` instance.\n",
            " |            A more detailed description of unpacking behavior for iterator types\n",
            " |            (Dataset, generator, Sequence) is given in the `Unpacking behavior\n",
            " |            for iterator-like inputs` section of `Model.fit`.\n",
            " |          batch_size: Integer or `None`.\n",
            " |              Number of samples per batch.\n",
            " |              If unspecified, `batch_size` will default to 32.\n",
            " |              Do not specify the `batch_size` if your data is in the\n",
            " |              form of dataset, generators, or `keras.utils.Sequence` instances\n",
            " |              (since they generate batches).\n",
            " |          verbose: `\"auto\"`, 0, 1, or 2. Verbosity mode.\n",
            " |              0 = silent, 1 = progress bar, 2 = single line.\n",
            " |              `\"auto\"` defaults to 1 for most cases, and to 2 when used with\n",
            " |              `ParameterServerStrategy`. Note that the progress bar is not\n",
            " |              particularly useful when logged to a file, so `verbose=2` is\n",
            " |              recommended when not running interactively (e.g. in a production\n",
            " |              environment).\n",
            " |          steps: Total number of steps (batches of samples)\n",
            " |              before declaring the prediction round finished.\n",
            " |              Ignored with the default value of `None`. If x is a `tf.data`\n",
            " |              dataset and `steps` is None, `predict()` will\n",
            " |              run until the input dataset is exhausted.\n",
            " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
            " |              List of callbacks to apply during prediction.\n",
            " |              See [callbacks](/api_docs/python/tf/keras/callbacks).\n",
            " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
            " |              input only. Maximum size for the generator queue.\n",
            " |              If unspecified, `max_queue_size` will default to 10.\n",
            " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
            " |              only. Maximum number of processes to spin up when using\n",
            " |              process-based threading. If unspecified, `workers` will default\n",
            " |              to 1.\n",
            " |          use_multiprocessing: Boolean. Used for generator or\n",
            " |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
            " |              threading. If unspecified, `use_multiprocessing` will default to\n",
            " |              `False`. Note that because this implementation relies on\n",
            " |              multiprocessing, you should not pass non-picklable arguments to\n",
            " |              the generator as they can't be passed easily to children processes.\n",
            " |      \n",
            " |      See the discussion of `Unpacking behavior for iterator-like inputs` for\n",
            " |      `Model.fit`. Note that Model.predict uses the same interpretation rules as\n",
            " |      `Model.fit` and `Model.evaluate`, so inputs must be unambiguous for all\n",
            " |      three methods.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Numpy array(s) of predictions.\n",
            " |      \n",
            " |      Raises:\n",
            " |          RuntimeError: If `model.predict` is wrapped in a `tf.function`.\n",
            " |          ValueError: In case of mismatch between the provided\n",
            " |              input data and the model's expectations,\n",
            " |              or in case a stateful model receives a number of samples\n",
            " |              that is not a multiple of the batch size.\n",
            " |  \n",
            " |  predict_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
            " |      Generates predictions for the input samples from a data generator.\n",
            " |      \n",
            " |      DEPRECATED:\n",
            " |        `Model.predict` now supports generators, so there is no longer any need\n",
            " |        to use this endpoint.\n",
            " |  \n",
            " |  predict_on_batch(self, x)\n",
            " |      Returns predictions for a single batch of samples.\n",
            " |      \n",
            " |      Args:\n",
            " |          x: Input data. It could be:\n",
            " |            - A Numpy array (or array-like), or a list of arrays (in case the\n",
            " |                model has multiple inputs).\n",
            " |            - A TensorFlow tensor, or a list of tensors (in case the model has\n",
            " |                multiple inputs).\n",
            " |      \n",
            " |      Returns:\n",
            " |          Numpy array(s) of predictions.\n",
            " |      \n",
            " |      Raises:\n",
            " |          RuntimeError: If `model.predict_on_batch` is wrapped in a `tf.function`.\n",
            " |  \n",
            " |  predict_step(self, data)\n",
            " |      The logic for one inference step.\n",
            " |      \n",
            " |      This method can be overridden to support custom inference logic.\n",
            " |      This method is called by `Model.make_predict_function`.\n",
            " |      \n",
            " |      This method should contain the mathematical logic for one step of inference.\n",
            " |      This typically includes the forward pass.\n",
            " |      \n",
            " |      Configuration details for *how* this logic is run (e.g. `tf.function` and\n",
            " |      `tf.distribute.Strategy` settings), should be left to\n",
            " |      `Model.make_predict_function`, which can also be overridden.\n",
            " |      \n",
            " |      Args:\n",
            " |        data: A nested structure of `Tensor`s.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The result of one inference step, typically the output of calling the\n",
            " |        `Model` on data.\n",
            " |  \n",
            " |  reset_metrics(self)\n",
            " |      Resets the state of all the metrics in the model.\n",
            " |      \n",
            " |      Examples:\n",
            " |      \n",
            " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
            " |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
            " |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
            " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
            " |      \n",
            " |      >>> x = np.random.random((2, 3))\n",
            " |      >>> y = np.random.randint(0, 2, (2, 2))\n",
            " |      >>> _ = model.fit(x, y, verbose=0)\n",
            " |      >>> assert all(float(m.result()) for m in model.metrics)\n",
            " |      \n",
            " |      >>> model.reset_metrics()\n",
            " |      >>> assert all(float(m.result()) == 0 for m in model.metrics)\n",
            " |  \n",
            " |  reset_states(self)\n",
            " |  \n",
            " |  save_spec(self, dynamic_batch=True)\n",
            " |      Returns the `tf.TensorSpec` of call inputs as a tuple `(args, kwargs)`.\n",
            " |      \n",
            " |      This value is automatically defined after calling the model for the first\n",
            " |      time. Afterwards, you can use it when exporting the model for serving:\n",
            " |      \n",
            " |      ```python\n",
            " |      model = tf.keras.Model(...)\n",
            " |      \n",
            " |      @tf.function\n",
            " |      def serve(*args, **kwargs):\n",
            " |        outputs = model(*args, **kwargs)\n",
            " |        # Apply postprocessing steps, or add additional outputs.\n",
            " |        ...\n",
            " |        return outputs\n",
            " |      \n",
            " |      # arg_specs is `[tf.TensorSpec(...), ...]`. kwarg_specs, in this example, is\n",
            " |      # an empty dict since functional models do not use keyword arguments.\n",
            " |      arg_specs, kwarg_specs = model.save_spec()\n",
            " |      \n",
            " |      model.save(path, signatures={\n",
            " |        'serving_default': serve.get_concrete_function(*arg_specs, **kwarg_specs)\n",
            " |      })\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |        dynamic_batch: Whether to set the batch sizes of all the returned\n",
            " |          `tf.TensorSpec` to `None`. (Note that when defining functional or\n",
            " |          Sequential models with `tf.keras.Input([...], batch_size=X)`, the\n",
            " |          batch size will always be preserved). Defaults to `True`.\n",
            " |      Returns:\n",
            " |        If the model inputs are defined, returns a tuple `(args, kwargs)`. All\n",
            " |        elements in `args` and `kwargs` are `tf.TensorSpec`.\n",
            " |        If the model inputs are not defined, returns `None`.\n",
            " |        The model inputs are automatically set when calling the model,\n",
            " |        `model.fit`, `model.evaluate` or `model.predict`.\n",
            " |  \n",
            " |  save_weights(self, filepath, overwrite=True, save_format=None, options=None)\n",
            " |      Saves all layer weights.\n",
            " |      \n",
            " |      Either saves in HDF5 or in TensorFlow format based on the `save_format`\n",
            " |      argument.\n",
            " |      \n",
            " |      When saving in HDF5 format, the weight file has:\n",
            " |        - `layer_names` (attribute), a list of strings\n",
            " |            (ordered names of model layers).\n",
            " |        - For every layer, a `group` named `layer.name`\n",
            " |            - For every such layer group, a group attribute `weight_names`,\n",
            " |                a list of strings\n",
            " |                (ordered names of weights tensor of the layer).\n",
            " |            - For every weight in the layer, a dataset\n",
            " |                storing the weight value, named after the weight tensor.\n",
            " |      \n",
            " |      When saving in TensorFlow format, all objects referenced by the network are\n",
            " |      saved in the same format as `tf.train.Checkpoint`, including any `Layer`\n",
            " |      instances or `Optimizer` instances assigned to object attributes. For\n",
            " |      networks constructed from inputs and outputs using `tf.keras.Model(inputs,\n",
            " |      outputs)`, `Layer` instances used by the network are tracked/saved\n",
            " |      automatically. For user-defined classes which inherit from `tf.keras.Model`,\n",
            " |      `Layer` instances must be assigned to object attributes, typically in the\n",
            " |      constructor. See the documentation of `tf.train.Checkpoint` and\n",
            " |      `tf.keras.Model` for details.\n",
            " |      \n",
            " |      While the formats are the same, do not mix `save_weights` and\n",
            " |      `tf.train.Checkpoint`. Checkpoints saved by `Model.save_weights` should be\n",
            " |      loaded using `Model.load_weights`. Checkpoints saved using\n",
            " |      `tf.train.Checkpoint.save` should be restored using the corresponding\n",
            " |      `tf.train.Checkpoint.restore`. Prefer `tf.train.Checkpoint` over\n",
            " |      `save_weights` for training checkpoints.\n",
            " |      \n",
            " |      The TensorFlow format matches objects and variables by starting at a root\n",
            " |      object, `self` for `save_weights`, and greedily matching attribute\n",
            " |      names. For `Model.save` this is the `Model`, and for `Checkpoint.save` this\n",
            " |      is the `Checkpoint` even if the `Checkpoint` has a model attached. This\n",
            " |      means saving a `tf.keras.Model` using `save_weights` and loading into a\n",
            " |      `tf.train.Checkpoint` with a `Model` attached (or vice versa) will not match\n",
            " |      the `Model`'s variables. See the\n",
            " |      [guide to training checkpoints](https://www.tensorflow.org/guide/checkpoint)\n",
            " |      for details on the TensorFlow format.\n",
            " |      \n",
            " |      Args:\n",
            " |          filepath: String or PathLike, path to the file to save the weights to.\n",
            " |              When saving in TensorFlow format, this is the prefix used for\n",
            " |              checkpoint files (multiple files are generated). Note that the '.h5'\n",
            " |              suffix causes weights to be saved in HDF5 format.\n",
            " |          overwrite: Whether to silently overwrite any existing file at the\n",
            " |              target location, or provide the user with a manual prompt.\n",
            " |          save_format: Either 'tf' or 'h5'. A `filepath` ending in '.h5' or\n",
            " |              '.keras' will default to HDF5 if `save_format` is `None`. Otherwise\n",
            " |              `None` defaults to 'tf'.\n",
            " |          options: Optional `tf.train.CheckpointOptions` object that specifies\n",
            " |              options for saving weights.\n",
            " |      \n",
            " |      Raises:\n",
            " |          ImportError: If `h5py` is not available when attempting to save in HDF5\n",
            " |              format.\n",
            " |  \n",
            " |  test_on_batch(self, x, y=None, sample_weight=None, reset_metrics=True, return_dict=False)\n",
            " |      Test the model on a single batch of samples.\n",
            " |      \n",
            " |      Args:\n",
            " |          x: Input data. It could be:\n",
            " |            - A Numpy array (or array-like), or a list of arrays (in case the\n",
            " |                model has multiple inputs).\n",
            " |            - A TensorFlow tensor, or a list of tensors (in case the model has\n",
            " |                multiple inputs).\n",
            " |            - A dict mapping input names to the corresponding array/tensors, if\n",
            " |                the model has named inputs.\n",
            " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
            " |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
            " |            (you cannot have Numpy inputs and tensor targets, or inversely).\n",
            " |          sample_weight: Optional array of the same length as x, containing\n",
            " |            weights to apply to the model's loss for each sample. In the case of\n",
            " |            temporal data, you can pass a 2D array with shape (samples,\n",
            " |            sequence_length), to apply a different weight to every timestep of\n",
            " |            every sample.\n",
            " |          reset_metrics: If `True`, the metrics returned will be only for this\n",
            " |            batch. If `False`, the metrics will be statefully accumulated across\n",
            " |            batches.\n",
            " |          return_dict: If `True`, loss and metric results are returned as a dict,\n",
            " |            with each key being the name of the metric. If `False`, they are\n",
            " |            returned as a list.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Scalar test loss (if the model has a single output and no metrics)\n",
            " |          or list of scalars (if the model has multiple outputs\n",
            " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
            " |          the display labels for the scalar outputs.\n",
            " |      \n",
            " |      Raises:\n",
            " |          RuntimeError: If `model.test_on_batch` is wrapped in a `tf.function`.\n",
            " |  \n",
            " |  test_step(self, data)\n",
            " |      The logic for one evaluation step.\n",
            " |      \n",
            " |      This method can be overridden to support custom evaluation logic.\n",
            " |      This method is called by `Model.make_test_function`.\n",
            " |      \n",
            " |      This function should contain the mathematical logic for one step of\n",
            " |      evaluation.\n",
            " |      This typically includes the forward pass, loss calculation, and metrics\n",
            " |      updates.\n",
            " |      \n",
            " |      Configuration details for *how* this logic is run (e.g. `tf.function` and\n",
            " |      `tf.distribute.Strategy` settings), should be left to\n",
            " |      `Model.make_test_function`, which can also be overridden.\n",
            " |      \n",
            " |      Args:\n",
            " |        data: A nested structure of `Tensor`s.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `dict` containing values that will be passed to\n",
            " |        `tf.keras.callbacks.CallbackList.on_train_batch_end`. Typically, the\n",
            " |        values of the `Model`'s metrics are returned.\n",
            " |  \n",
            " |  to_json(self, **kwargs)\n",
            " |      Returns a JSON string containing the network configuration.\n",
            " |      \n",
            " |      To load a network from a JSON save file, use\n",
            " |      `keras.models.model_from_json(json_string, custom_objects={})`.\n",
            " |      \n",
            " |      Args:\n",
            " |          **kwargs: Additional keyword arguments\n",
            " |              to be passed to `json.dumps()`.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A JSON string.\n",
            " |  \n",
            " |  to_yaml(self, **kwargs)\n",
            " |      Returns a yaml string containing the network configuration.\n",
            " |      \n",
            " |      Note: Since TF 2.6, this method is no longer supported and will raise a\n",
            " |      RuntimeError.\n",
            " |      \n",
            " |      To load a network from a yaml save file, use\n",
            " |      `keras.models.model_from_yaml(yaml_string, custom_objects={})`.\n",
            " |      \n",
            " |      `custom_objects` should be a dictionary mapping\n",
            " |      the names of custom losses / layers / etc to the corresponding\n",
            " |      functions / classes.\n",
            " |      \n",
            " |      Args:\n",
            " |          **kwargs: Additional keyword arguments\n",
            " |              to be passed to `yaml.dump()`.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A YAML string.\n",
            " |      \n",
            " |      Raises:\n",
            " |          RuntimeError: announces that the method poses a security risk\n",
            " |  \n",
            " |  train_on_batch(self, x, y=None, sample_weight=None, class_weight=None, reset_metrics=True, return_dict=False)\n",
            " |      Runs a single gradient update on a single batch of data.\n",
            " |      \n",
            " |      Args:\n",
            " |          x: Input data. It could be:\n",
            " |            - A Numpy array (or array-like), or a list of arrays\n",
            " |                (in case the model has multiple inputs).\n",
            " |            - A TensorFlow tensor, or a list of tensors\n",
            " |                (in case the model has multiple inputs).\n",
            " |            - A dict mapping input names to the corresponding array/tensors,\n",
            " |                if the model has named inputs.\n",
            " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
            " |            array(s) or TensorFlow tensor(s).\n",
            " |          sample_weight: Optional array of the same length as x, containing\n",
            " |            weights to apply to the model's loss for each sample. In the case of\n",
            " |            temporal data, you can pass a 2D array with shape (samples,\n",
            " |            sequence_length), to apply a different weight to every timestep of\n",
            " |            every sample.\n",
            " |          class_weight: Optional dictionary mapping class indices (integers) to a\n",
            " |            weight (float) to apply to the model's loss for the samples from this\n",
            " |            class during training. This can be useful to tell the model to \"pay\n",
            " |            more attention\" to samples from an under-represented class.\n",
            " |          reset_metrics: If `True`, the metrics returned will be only for this\n",
            " |            batch. If `False`, the metrics will be statefully accumulated across\n",
            " |            batches.\n",
            " |          return_dict: If `True`, loss and metric results are returned as a dict,\n",
            " |            with each key being the name of the metric. If `False`, they are\n",
            " |            returned as a list.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Scalar training loss\n",
            " |          (if the model has a single output and no metrics)\n",
            " |          or list of scalars (if the model has multiple outputs\n",
            " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
            " |          the display labels for the scalar outputs.\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If `model.train_on_batch` is wrapped in a `tf.function`.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods inherited from keras.engine.training.Model:\n",
            " |  \n",
            " |  from_config(config, custom_objects=None) from builtins.type\n",
            " |      Creates a layer from its config.\n",
            " |      \n",
            " |      This method is the reverse of `get_config`,\n",
            " |      capable of instantiating the same layer from the config\n",
            " |      dictionary. It does not handle layer connectivity\n",
            " |      (handled by Network), nor weights (handled by `set_weights`).\n",
            " |      \n",
            " |      Args:\n",
            " |          config: A Python dictionary, typically the\n",
            " |              output of get_config.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A layer instance.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Static methods inherited from keras.engine.training.Model:\n",
            " |  \n",
            " |  __new__(cls, *args, **kwargs)\n",
            " |      Create and return a new object.  See help(type) for accurate signature.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from keras.engine.training.Model:\n",
            " |  \n",
            " |  distribute_strategy\n",
            " |      The `tf.distribute.Strategy` this model was created under.\n",
            " |  \n",
            " |  layers\n",
            " |  \n",
            " |  metrics\n",
            " |      Returns the model's metrics added using `compile()`, `add_metric()` APIs.\n",
            " |      \n",
            " |      Note: Metrics passed to `compile()` are available only after a `keras.Model`\n",
            " |      has been trained/evaluated on actual data.\n",
            " |      \n",
            " |      Examples:\n",
            " |      \n",
            " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
            " |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
            " |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
            " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
            " |      >>> [m.name for m in model.metrics]\n",
            " |      []\n",
            " |      \n",
            " |      >>> x = np.random.random((2, 3))\n",
            " |      >>> y = np.random.randint(0, 2, (2, 2))\n",
            " |      >>> model.fit(x, y)\n",
            " |      >>> [m.name for m in model.metrics]\n",
            " |      ['loss', 'mae']\n",
            " |      \n",
            " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
            " |      >>> d = tf.keras.layers.Dense(2, name='out')\n",
            " |      >>> output_1 = d(inputs)\n",
            " |      >>> output_2 = d(inputs)\n",
            " |      >>> model = tf.keras.models.Model(\n",
            " |      ...    inputs=inputs, outputs=[output_1, output_2])\n",
            " |      >>> model.add_metric(\n",
            " |      ...    tf.reduce_sum(output_2), name='mean', aggregation='mean')\n",
            " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\", \"acc\"])\n",
            " |      >>> model.fit(x, (y, y))\n",
            " |      >>> [m.name for m in model.metrics]\n",
            " |      ['loss', 'out_loss', 'out_1_loss', 'out_mae', 'out_acc', 'out_1_mae',\n",
            " |      'out_1_acc', 'mean']\n",
            " |  \n",
            " |  metrics_names\n",
            " |      Returns the model's display labels for all outputs.\n",
            " |      \n",
            " |      Note: `metrics_names` are available only after a `keras.Model` has been\n",
            " |      trained/evaluated on actual data.\n",
            " |      \n",
            " |      Examples:\n",
            " |      \n",
            " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
            " |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
            " |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
            " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
            " |      >>> model.metrics_names\n",
            " |      []\n",
            " |      \n",
            " |      >>> x = np.random.random((2, 3))\n",
            " |      >>> y = np.random.randint(0, 2, (2, 2))\n",
            " |      >>> model.fit(x, y)\n",
            " |      >>> model.metrics_names\n",
            " |      ['loss', 'mae']\n",
            " |      \n",
            " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
            " |      >>> d = tf.keras.layers.Dense(2, name='out')\n",
            " |      >>> output_1 = d(inputs)\n",
            " |      >>> output_2 = d(inputs)\n",
            " |      >>> model = tf.keras.models.Model(\n",
            " |      ...    inputs=inputs, outputs=[output_1, output_2])\n",
            " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\", \"acc\"])\n",
            " |      >>> model.fit(x, (y, y))\n",
            " |      >>> model.metrics_names\n",
            " |      ['loss', 'out_loss', 'out_1_loss', 'out_mae', 'out_acc', 'out_1_mae',\n",
            " |      'out_1_acc']\n",
            " |  \n",
            " |  non_trainable_weights\n",
            " |      List of all non-trainable weights tracked by this layer.\n",
            " |      \n",
            " |      Non-trainable weights are *not* updated during training. They are expected\n",
            " |      to be updated manually in `call()`.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of non-trainable variables.\n",
            " |  \n",
            " |  run_eagerly\n",
            " |      Settable attribute indicating whether the model should run eagerly.\n",
            " |      \n",
            " |      Running eagerly means that your model will be run step by step,\n",
            " |      like Python code. Your model might run slower, but it should become easier\n",
            " |      for you to debug it by stepping into individual layer calls.\n",
            " |      \n",
            " |      By default, we will attempt to compile your model to a static graph to\n",
            " |      deliver the best execution performance.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Boolean, whether the model should run eagerly.\n",
            " |  \n",
            " |  state_updates\n",
            " |      Deprecated, do NOT use!\n",
            " |      \n",
            " |      Returns the `updates` from all layers that are stateful.\n",
            " |      \n",
            " |      This is useful for separating training updates and\n",
            " |      state updates, e.g. when we need to update a layer's internal state\n",
            " |      during prediction.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A list of update ops.\n",
            " |  \n",
            " |  trainable_weights\n",
            " |      List of all trainable weights tracked by this layer.\n",
            " |      \n",
            " |      Trainable weights are updated via gradient descent during training.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of trainable variables.\n",
            " |  \n",
            " |  weights\n",
            " |      Returns the list of all layer variables/weights.\n",
            " |      \n",
            " |      Note: This will not track the weights of nested `tf.Modules` that are not\n",
            " |      themselves Keras layers.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of variables.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from keras.engine.base_layer.Layer:\n",
            " |  \n",
            " |  __delattr__(self, name)\n",
            " |      Implement delattr(self, name).\n",
            " |  \n",
            " |  __getstate__(self)\n",
            " |  \n",
            " |  __setstate__(self, state)\n",
            " |  \n",
            " |  add_loss(self, losses, **kwargs)\n",
            " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
            " |      \n",
            " |      Some losses (for instance, activity regularization losses) may be dependent\n",
            " |      on the inputs passed when calling a layer. Hence, when reusing the same\n",
            " |      layer on different inputs `a` and `b`, some entries in `layer.losses` may\n",
            " |      be dependent on `a` and some on `b`. This method automatically keeps track\n",
            " |      of dependencies.\n",
            " |      \n",
            " |      This method can be used inside a subclassed layer or model's `call`\n",
            " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      class MyLayer(tf.keras.layers.Layer):\n",
            " |        def call(self, inputs):\n",
            " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
            " |          return inputs\n",
            " |      ```\n",
            " |      \n",
            " |      This method can also be called directly on a Functional Model during\n",
            " |      construction. In this case, any loss Tensors passed to this Model must\n",
            " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
            " |      losses become part of the model's topology and are tracked in `get_config`.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      inputs = tf.keras.Input(shape=(10,))\n",
            " |      x = tf.keras.layers.Dense(10)(inputs)\n",
            " |      outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      model = tf.keras.Model(inputs, outputs)\n",
            " |      # Activity regularization.\n",
            " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
            " |      ```\n",
            " |      \n",
            " |      If this is not the case for your loss (if, for example, your loss references\n",
            " |      a `Variable` of one of the model's layers), you can wrap your loss in a\n",
            " |      zero-argument lambda. These losses are not tracked as part of the model's\n",
            " |      topology since they can't be serialized.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      inputs = tf.keras.Input(shape=(10,))\n",
            " |      d = tf.keras.layers.Dense(10)\n",
            " |      x = d(inputs)\n",
            " |      outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      model = tf.keras.Model(inputs, outputs)\n",
            " |      # Weight regularization.\n",
            " |      model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses\n",
            " |          may also be zero-argument callables which create a loss tensor.\n",
            " |        **kwargs: Used for backwards compatibility only.\n",
            " |  \n",
            " |  add_metric(self, value, name=None, **kwargs)\n",
            " |      Adds metric tensor to the layer.\n",
            " |      \n",
            " |      This method can be used inside the `call()` method of a subclassed layer\n",
            " |      or model.\n",
            " |      \n",
            " |      ```python\n",
            " |      class MyMetricLayer(tf.keras.layers.Layer):\n",
            " |        def __init__(self):\n",
            " |          super(MyMetricLayer, self).__init__(name='my_metric_layer')\n",
            " |          self.mean = tf.keras.metrics.Mean(name='metric_1')\n",
            " |      \n",
            " |        def call(self, inputs):\n",
            " |          self.add_metric(self.mean(inputs))\n",
            " |          self.add_metric(tf.reduce_sum(inputs), name='metric_2')\n",
            " |          return inputs\n",
            " |      ```\n",
            " |      \n",
            " |      This method can also be called directly on a Functional Model during\n",
            " |      construction. In this case, any tensor passed to this Model must\n",
            " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
            " |      metrics become part of the model's topology and are tracked when you\n",
            " |      save the model via `save()`.\n",
            " |      \n",
            " |      ```python\n",
            " |      inputs = tf.keras.Input(shape=(10,))\n",
            " |      x = tf.keras.layers.Dense(10)(inputs)\n",
            " |      outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      model = tf.keras.Model(inputs, outputs)\n",
            " |      model.add_metric(math_ops.reduce_sum(x), name='metric_1')\n",
            " |      ```\n",
            " |      \n",
            " |      Note: Calling `add_metric()` with the result of a metric object on a\n",
            " |      Functional Model, as shown in the example below, is not supported. This is\n",
            " |      because we cannot trace the metric result tensor back to the model's inputs.\n",
            " |      \n",
            " |      ```python\n",
            " |      inputs = tf.keras.Input(shape=(10,))\n",
            " |      x = tf.keras.layers.Dense(10)(inputs)\n",
            " |      outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      model = tf.keras.Model(inputs, outputs)\n",
            " |      model.add_metric(tf.keras.metrics.Mean()(x), name='metric_1')\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |        value: Metric tensor.\n",
            " |        name: String metric name.\n",
            " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
            " |          Accepted values:\n",
            " |          `aggregation` - When the `value` tensor provided is not the result of\n",
            " |          calling a `keras.Metric` instance, it will be aggregated by default\n",
            " |          using a `keras.Metric.Mean`.\n",
            " |  \n",
            " |  add_update(self, updates)\n",
            " |      Add update op(s), potentially dependent on layer inputs.\n",
            " |      \n",
            " |      Weight updates (for instance, the updates of the moving mean and variance\n",
            " |      in a BatchNormalization layer) may be dependent on the inputs passed\n",
            " |      when calling a layer. Hence, when reusing the same layer on\n",
            " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
            " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
            " |      of dependencies.\n",
            " |      \n",
            " |      This call is ignored when eager execution is enabled (in that case, variable\n",
            " |      updates are run on the fly and thus do not need to be tracked for later\n",
            " |      execution).\n",
            " |      \n",
            " |      Args:\n",
            " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
            " |          that returns an update op. A zero-arg callable should be passed in\n",
            " |          order to disable running the updates by setting `trainable=False`\n",
            " |          on this Layer, when executing in Eager mode.\n",
            " |  \n",
            " |  add_variable(self, *args, **kwargs)\n",
            " |      Deprecated, do NOT use! Alias for `add_weight`.\n",
            " |  \n",
            " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregationV2.NONE: 0>, **kwargs)\n",
            " |      Adds a new variable to the layer.\n",
            " |      \n",
            " |      Args:\n",
            " |        name: Variable name.\n",
            " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
            " |        dtype: The type of the variable. Defaults to `self.dtype`.\n",
            " |        initializer: Initializer instance (callable).\n",
            " |        regularizer: Regularizer instance (callable).\n",
            " |        trainable: Boolean, whether the variable should be part of the layer's\n",
            " |          \"trainable_variables\" (e.g. variables, biases)\n",
            " |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
            " |          Note that `trainable` cannot be `True` if `synchronization`\n",
            " |          is set to `ON_READ`.\n",
            " |        constraint: Constraint instance (callable).\n",
            " |        use_resource: Whether to use `ResourceVariable`.\n",
            " |        synchronization: Indicates when a distributed a variable will be\n",
            " |          aggregated. Accepted values are constants defined in the class\n",
            " |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
            " |          `AUTO` and the current `DistributionStrategy` chooses\n",
            " |          when to synchronize. If `synchronization` is set to `ON_READ`,\n",
            " |          `trainable` must not be set to `True`.\n",
            " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
            " |          Accepted values are constants defined in the class\n",
            " |          `tf.VariableAggregation`.\n",
            " |        **kwargs: Additional keyword arguments. Accepted values are `getter`,\n",
            " |          `collections`, `experimental_autocast` and `caching_device`.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The variable created.\n",
            " |      \n",
            " |      Raises:\n",
            " |        ValueError: When giving unsupported dtype and no initializer or when\n",
            " |          trainable has been set to True with synchronization set as `ON_READ`.\n",
            " |  \n",
            " |  compute_mask(self, inputs, mask=None)\n",
            " |      Computes an output mask tensor.\n",
            " |      \n",
            " |      Args:\n",
            " |          inputs: Tensor or list of tensors.\n",
            " |          mask: Tensor or list of tensors.\n",
            " |      \n",
            " |      Returns:\n",
            " |          None or a tensor (or list of tensors,\n",
            " |              one per output tensor of the layer).\n",
            " |  \n",
            " |  compute_output_shape(self, input_shape)\n",
            " |      Computes the output shape of the layer.\n",
            " |      \n",
            " |      This method will cause the layer's state to be built, if that has not\n",
            " |      happened before. This requires that the layer will later be used with\n",
            " |      inputs that match the input shape provided here.\n",
            " |      \n",
            " |      Args:\n",
            " |          input_shape: Shape tuple (tuple of integers)\n",
            " |              or list of shape tuples (one per output tensor of the layer).\n",
            " |              Shape tuples can include None for free dimensions,\n",
            " |              instead of an integer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          An input shape tuple.\n",
            " |  \n",
            " |  compute_output_signature(self, input_signature)\n",
            " |      Compute the output tensor signature of the layer based on the inputs.\n",
            " |      \n",
            " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
            " |      and dtype information for a tensor. This method allows layers to provide\n",
            " |      output dtype information if it is different from the input dtype.\n",
            " |      For any layer that doesn't implement this function,\n",
            " |      the framework will fall back to use `compute_output_shape`, and will\n",
            " |      assume that the output dtype matches the input dtype.\n",
            " |      \n",
            " |      Args:\n",
            " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
            " |          objects, describing a candidate input for the layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Single TensorSpec or nested structure of TensorSpec objects, describing\n",
            " |          how the layer would transform the provided input.\n",
            " |      \n",
            " |      Raises:\n",
            " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
            " |  \n",
            " |  count_params(self)\n",
            " |      Count the total number of scalars composing the weights.\n",
            " |      \n",
            " |      Returns:\n",
            " |          An integer count.\n",
            " |      \n",
            " |      Raises:\n",
            " |          ValueError: if the layer isn't yet built\n",
            " |            (in which case its weights aren't yet defined).\n",
            " |  \n",
            " |  finalize_state(self)\n",
            " |      Finalizes the layers state after updating layer weights.\n",
            " |      \n",
            " |      This function can be subclassed in a layer and will be called after updating\n",
            " |      a layer weights. It can be overridden to finalize any additional layer state\n",
            " |      after a weight update.\n",
            " |      \n",
            " |      This function will be called after weights of a layer have been restored\n",
            " |      from a loaded model.\n",
            " |  \n",
            " |  get_input_at(self, node_index)\n",
            " |      Retrieves the input tensor(s) of a layer at a given node.\n",
            " |      \n",
            " |      Args:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first input node of the layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |  \n",
            " |  get_input_mask_at(self, node_index)\n",
            " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
            " |      \n",
            " |      Args:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first time the layer was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A mask tensor\n",
            " |          (or list of tensors if the layer has multiple inputs).\n",
            " |  \n",
            " |  get_input_shape_at(self, node_index)\n",
            " |      Retrieves the input shape(s) of a layer at a given node.\n",
            " |      \n",
            " |      Args:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first time the layer was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A shape tuple\n",
            " |          (or list of shape tuples if the layer has multiple inputs).\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |  \n",
            " |  get_output_at(self, node_index)\n",
            " |      Retrieves the output tensor(s) of a layer at a given node.\n",
            " |      \n",
            " |      Args:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first output node of the layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |  \n",
            " |  get_output_mask_at(self, node_index)\n",
            " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
            " |      \n",
            " |      Args:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first time the layer was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A mask tensor\n",
            " |          (or list of tensors if the layer has multiple outputs).\n",
            " |  \n",
            " |  get_output_shape_at(self, node_index)\n",
            " |      Retrieves the output shape(s) of a layer at a given node.\n",
            " |      \n",
            " |      Args:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first time the layer was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A shape tuple\n",
            " |          (or list of shape tuples if the layer has multiple outputs).\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |  \n",
            " |  set_weights(self, weights)\n",
            " |      Sets the weights of the layer, from NumPy arrays.\n",
            " |      \n",
            " |      The weights of a layer represent the state of the layer. This function\n",
            " |      sets the weight values from numpy arrays. The weight values should be\n",
            " |      passed in the order they are created by the layer. Note that the layer's\n",
            " |      weights must be instantiated before calling this function, by calling\n",
            " |      the layer.\n",
            " |      \n",
            " |      For example, a `Dense` layer returns a list of two values: the kernel matrix\n",
            " |      and the bias vector. These can be used to set the weights of another\n",
            " |      `Dense` layer:\n",
            " |      \n",
            " |      >>> layer_a = tf.keras.layers.Dense(1,\n",
            " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
            " |      >>> a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
            " |      >>> layer_a.get_weights()\n",
            " |      [array([[1.],\n",
            " |             [1.],\n",
            " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
            " |      >>> layer_b = tf.keras.layers.Dense(1,\n",
            " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
            " |      >>> b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
            " |      >>> layer_b.get_weights()\n",
            " |      [array([[2.],\n",
            " |             [2.],\n",
            " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
            " |      >>> layer_b.set_weights(layer_a.get_weights())\n",
            " |      >>> layer_b.get_weights()\n",
            " |      [array([[1.],\n",
            " |             [1.],\n",
            " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
            " |      \n",
            " |      Args:\n",
            " |        weights: a list of NumPy arrays. The number\n",
            " |          of arrays and their shape must match\n",
            " |          number of the dimensions of the weights\n",
            " |          of the layer (i.e. it should match the\n",
            " |          output of `get_weights`).\n",
            " |      \n",
            " |      Raises:\n",
            " |        ValueError: If the provided weights list does not match the\n",
            " |          layer's specifications.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from keras.engine.base_layer.Layer:\n",
            " |  \n",
            " |  activity_regularizer\n",
            " |      Optional regularizer function for the output of this layer.\n",
            " |  \n",
            " |  compute_dtype\n",
            " |      The dtype of the layer's computations.\n",
            " |      \n",
            " |      This is equivalent to `Layer.dtype_policy.compute_dtype`. Unless\n",
            " |      mixed precision is used, this is the same as `Layer.dtype`, the dtype of\n",
            " |      the weights.\n",
            " |      \n",
            " |      Layers automatically cast their inputs to the compute dtype, which causes\n",
            " |      computations and the output to be in the compute dtype as well. This is done\n",
            " |      by the base Layer class in `Layer.__call__`, so you do not have to insert\n",
            " |      these casts if implementing your own layer.\n",
            " |      \n",
            " |      Layers often perform certain internal computations in higher precision when\n",
            " |      `compute_dtype` is float16 or bfloat16 for numeric stability. The output\n",
            " |      will still typically be float16 or bfloat16 in such cases.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The layer's compute dtype.\n",
            " |  \n",
            " |  dtype\n",
            " |      The dtype of the layer weights.\n",
            " |      \n",
            " |      This is equivalent to `Layer.dtype_policy.variable_dtype`. Unless\n",
            " |      mixed precision is used, this is the same as `Layer.compute_dtype`, the\n",
            " |      dtype of the layer's computations.\n",
            " |  \n",
            " |  dtype_policy\n",
            " |      The dtype policy associated with this layer.\n",
            " |      \n",
            " |      This is an instance of a `tf.keras.mixed_precision.Policy`.\n",
            " |  \n",
            " |  dynamic\n",
            " |      Whether the layer is dynamic (eager-only); set in the constructor.\n",
            " |  \n",
            " |  inbound_nodes\n",
            " |      Return Functional API nodes upstream of this layer.\n",
            " |  \n",
            " |  input\n",
            " |      Retrieves the input tensor(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one input,\n",
            " |      i.e. if it is connected to one incoming layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Input tensor or list of input tensors.\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |        AttributeError: If no inbound nodes are found.\n",
            " |  \n",
            " |  input_mask\n",
            " |      Retrieves the input mask tensor(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one inbound node,\n",
            " |      i.e. if it is connected to one incoming layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Input mask tensor (potentially None) or list of input\n",
            " |          mask tensors.\n",
            " |      \n",
            " |      Raises:\n",
            " |          AttributeError: if the layer is connected to\n",
            " |          more than one incoming layers.\n",
            " |  \n",
            " |  input_shape\n",
            " |      Retrieves the input shape(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one input,\n",
            " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
            " |      have the same shape.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Input shape, as an integer shape tuple\n",
            " |          (or list of shape tuples, one tuple per input tensor).\n",
            " |      \n",
            " |      Raises:\n",
            " |          AttributeError: if the layer has no defined input_shape.\n",
            " |          RuntimeError: if called in Eager mode.\n",
            " |  \n",
            " |  input_spec\n",
            " |      `InputSpec` instance(s) describing the input format for this layer.\n",
            " |      \n",
            " |      When you create a layer subclass, you can set `self.input_spec` to enable\n",
            " |      the layer to run input compatibility checks when it is called.\n",
            " |      Consider a `Conv2D` layer: it can only be called on a single input tensor\n",
            " |      of rank 4. As such, you can set, in `__init__()`:\n",
            " |      \n",
            " |      ```python\n",
            " |      self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n",
            " |      ```\n",
            " |      \n",
            " |      Now, if you try to call the layer on an input that isn't rank 4\n",
            " |      (for instance, an input of shape `(2,)`, it will raise a nicely-formatted\n",
            " |      error:\n",
            " |      \n",
            " |      ```\n",
            " |      ValueError: Input 0 of layer conv2d is incompatible with the layer:\n",
            " |      expected ndim=4, found ndim=1. Full shape received: [2]\n",
            " |      ```\n",
            " |      \n",
            " |      Input checks that can be specified via `input_spec` include:\n",
            " |      - Structure (e.g. a single input, a list of 2 inputs, etc)\n",
            " |      - Shape\n",
            " |      - Rank (ndim)\n",
            " |      - Dtype\n",
            " |      \n",
            " |      For more information, see `tf.keras.layers.InputSpec`.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `tf.keras.layers.InputSpec` instance, or nested structure thereof.\n",
            " |  \n",
            " |  losses\n",
            " |      List of losses added using the `add_loss()` API.\n",
            " |      \n",
            " |      Variable regularization tensors are created when this property is accessed,\n",
            " |      so it is eager safe: accessing `losses` under a `tf.GradientTape` will\n",
            " |      propagate gradients back to the corresponding variables.\n",
            " |      \n",
            " |      Examples:\n",
            " |      \n",
            " |      >>> class MyLayer(tf.keras.layers.Layer):\n",
            " |      ...   def call(self, inputs):\n",
            " |      ...     self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
            " |      ...     return inputs\n",
            " |      >>> l = MyLayer()\n",
            " |      >>> l(np.ones((10, 1)))\n",
            " |      >>> l.losses\n",
            " |      [1.0]\n",
            " |      \n",
            " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
            " |      >>> x = tf.keras.layers.Dense(10)(inputs)\n",
            " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      >>> model = tf.keras.Model(inputs, outputs)\n",
            " |      >>> # Activity regularization.\n",
            " |      >>> len(model.losses)\n",
            " |      0\n",
            " |      >>> model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
            " |      >>> len(model.losses)\n",
            " |      1\n",
            " |      \n",
            " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
            " |      >>> d = tf.keras.layers.Dense(10, kernel_initializer='ones')\n",
            " |      >>> x = d(inputs)\n",
            " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      >>> model = tf.keras.Model(inputs, outputs)\n",
            " |      >>> # Weight regularization.\n",
            " |      >>> model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
            " |      >>> model.losses\n",
            " |      [<tf.Tensor: shape=(), dtype=float32, numpy=1.0>]\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of tensors.\n",
            " |  \n",
            " |  name\n",
            " |      Name of the layer (string), set in the constructor.\n",
            " |  \n",
            " |  non_trainable_variables\n",
            " |      Sequence of non-trainable variables owned by this module and its submodules.\n",
            " |      \n",
            " |      Note: this method uses reflection to find variables on the current instance\n",
            " |      and submodules. For performance reasons you may wish to cache the result\n",
            " |      of calling this method if you don't expect the return value to change.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A sequence of variables for the current module (sorted by attribute\n",
            " |        name) followed by variables from all submodules recursively (breadth\n",
            " |        first).\n",
            " |  \n",
            " |  outbound_nodes\n",
            " |      Return Functional API nodes downstream of this layer.\n",
            " |  \n",
            " |  output\n",
            " |      Retrieves the output tensor(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one output,\n",
            " |      i.e. if it is connected to one incoming layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Output tensor or list of output tensors.\n",
            " |      \n",
            " |      Raises:\n",
            " |        AttributeError: if the layer is connected to more than one incoming\n",
            " |          layers.\n",
            " |        RuntimeError: if called in Eager mode.\n",
            " |  \n",
            " |  output_mask\n",
            " |      Retrieves the output mask tensor(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one inbound node,\n",
            " |      i.e. if it is connected to one incoming layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Output mask tensor (potentially None) or list of output\n",
            " |          mask tensors.\n",
            " |      \n",
            " |      Raises:\n",
            " |          AttributeError: if the layer is connected to\n",
            " |          more than one incoming layers.\n",
            " |  \n",
            " |  output_shape\n",
            " |      Retrieves the output shape(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has one output,\n",
            " |      or if all outputs have the same shape.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Output shape, as an integer shape tuple\n",
            " |          (or list of shape tuples, one tuple per output tensor).\n",
            " |      \n",
            " |      Raises:\n",
            " |          AttributeError: if the layer has no defined output shape.\n",
            " |          RuntimeError: if called in Eager mode.\n",
            " |  \n",
            " |  stateful\n",
            " |  \n",
            " |  supports_masking\n",
            " |      Whether this layer supports computing a mask using `compute_mask`.\n",
            " |  \n",
            " |  trainable\n",
            " |  \n",
            " |  trainable_variables\n",
            " |      Sequence of trainable variables owned by this module and its submodules.\n",
            " |      \n",
            " |      Note: this method uses reflection to find variables on the current instance\n",
            " |      and submodules. For performance reasons you may wish to cache the result\n",
            " |      of calling this method if you don't expect the return value to change.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A sequence of variables for the current module (sorted by attribute\n",
            " |        name) followed by variables from all submodules recursively (breadth\n",
            " |        first).\n",
            " |  \n",
            " |  updates\n",
            " |  \n",
            " |  variable_dtype\n",
            " |      Alias of `Layer.dtype`, the dtype of the weights.\n",
            " |  \n",
            " |  variables\n",
            " |      Returns the list of all layer variables/weights.\n",
            " |      \n",
            " |      Alias of `self.weights`.\n",
            " |      \n",
            " |      Note: This will not track the weights of nested `tf.Modules` that are not\n",
            " |      themselves Keras layers.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of variables.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
            " |  \n",
            " |  with_name_scope(method) from builtins.type\n",
            " |      Decorator to automatically enter the module name scope.\n",
            " |      \n",
            " |      >>> class MyModule(tf.Module):\n",
            " |      ...   @tf.Module.with_name_scope\n",
            " |      ...   def __call__(self, x):\n",
            " |      ...     if not hasattr(self, 'w'):\n",
            " |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
            " |      ...     return tf.matmul(x, self.w)\n",
            " |      \n",
            " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
            " |      names included the module name:\n",
            " |      \n",
            " |      >>> mod = MyModule()\n",
            " |      >>> mod(tf.ones([1, 2]))\n",
            " |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
            " |      >>> mod.w\n",
            " |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
            " |      numpy=..., dtype=float32)>\n",
            " |      \n",
            " |      Args:\n",
            " |        method: The method to wrap.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The original method wrapped such that it enters the module's name scope.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from tensorflow.python.module.module.Module:\n",
            " |  \n",
            " |  name_scope\n",
            " |      Returns a `tf.name_scope` instance for this class.\n",
            " |  \n",
            " |  submodules\n",
            " |      Sequence of all sub-modules.\n",
            " |      \n",
            " |      Submodules are modules which are properties of this module, or found as\n",
            " |      properties of modules which are properties of this module (and so on).\n",
            " |      \n",
            " |      >>> a = tf.Module()\n",
            " |      >>> b = tf.Module()\n",
            " |      >>> c = tf.Module()\n",
            " |      >>> a.b = b\n",
            " |      >>> b.c = c\n",
            " |      >>> list(a.submodules) == [b, c]\n",
            " |      True\n",
            " |      >>> list(b.submodules) == [c]\n",
            " |      True\n",
            " |      >>> list(c.submodules) == []\n",
            " |      True\n",
            " |      \n",
            " |      Returns:\n",
            " |        A sequence of all submodules.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%set_cell_height 300\n",
        "\n",
        "feature_1 = tfdf.keras.FeatureUsage(name=\"year\", semantic=tfdf.keras.FeatureSemantic.CATEGORICAL)\n",
        "feature_2 = tfdf.keras.FeatureUsage(name=\"bill_length_mm\")\n",
        "feature_3 = tfdf.keras.FeatureUsage(name=\"sex\")\n",
        "all_features = [feature_1, feature_2, feature_3]\n",
        "\n",
        "model_3 = tfdf.keras.GradientBoostedTreesModel(features=all_features, exclude_non_specified_features=True)\n",
        "model_3.compile( metrics=[\"accuracy\"])\n",
        "\n",
        "with sys_pipes():\n",
        "  model_3.fit(x=train_ds, validation_data=test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "rxCodv-ipwI5",
        "outputId": "923c8bd7-980e-47ae-cfee-9b0d09a66196"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use /tmp/tmpm9bfon0e as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.375253. Found 242 examples.\n",
            "Reading validation dataset...\n",
            "Num validation examples: tf.Tensor(102, shape=(), dtype=int32)\n",
            "Validation dataset read in 0:00:00.735919. Found 102 examples.\n",
            "Training model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[INFO kernel.cc:1176] Loading model from path /tmp/tmpm9bfon0e/model/ with prefix b773e6e228e647e4\n",
            "[INFO abstract_model.cc:1248] Engine \"GradientBoostedTreesGeneric\" built\n",
            "[INFO kernel.cc:1022] Use fast generic engine\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained in 0:00:00.251537\n",
            "Compiling model...\n",
            "Model compiled.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼 매개변수\n",
        "model_6 = tfdf.keras.GradientBoostedTreesModel(\n",
        "    num_trees=500, growing_strategy=\"BEST_FIRST_GLOBAL\", max_depth=8)\n",
        "model_6.fit(x=train_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqljfJ_crx7R",
        "outputId": "c25d5cde-cb8e-4487-83fd-832078e85593"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use /tmp/tmp3vosfo7j as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.170569. Found 242 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.559350\n",
            "Compiling model...\n",
            "Model compiled.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd2840fd310>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 정확한 모델 설계하기\n",
        "model_7 = tfdf.keras.GradientBoostedTreesModel(\n",
        "    num_trees=500,\n",
        "    growing_strategy=\"BEST_FIRST_GLOBAL\",\n",
        "    max_depth=8,\n",
        "    split_axis=\"SPARSE_OBLIQUE\",\n",
        "    categorical_algorithm=\"RANDOM\",\n",
        "    )\n",
        "model_7.fit(x=train_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gazJ78l1sDmS",
        "outputId": "ea37ae56-0956-4646-f991-bd1ecbc388f9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use /tmp/tmpqpzlrly9 as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.384827. Found 242 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:01.026632\n",
            "Compiling model...\n",
            "Model compiled.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd283f79750>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_8 = tfdf.keras.GradientBoostedTreesModel(hyperparameter_template=\"benchmark_rank1\")\n",
        "model_8.fit(x=train_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CILKFnosOfe",
        "outputId": "f7feb21a-cc85-4bfc-c088-c39de242c9cd"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resolve hyper-parameter template \"benchmark_rank1\" to \"benchmark_rank1@v1\" -> {'growing_strategy': 'BEST_FIRST_GLOBAL', 'categorical_algorithm': 'RANDOM', 'split_axis': 'SPARSE_OBLIQUE', 'sparse_oblique_normalization': 'MIN_MAX', 'sparse_oblique_num_projections_exponent': 1.0}.\n",
            "Use /tmp/tmp2b81xb28 as temporary training directory\n",
            "Reading training dataset...\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function CoreModel._consumes_training_examples_until_eof at 0x7fd28a8b2c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function CoreModel._consumes_training_examples_until_eof at 0x7fd28a8b2c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training dataset read in 0:00:00.159498. Found 242 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.769458\n",
            "Compiling model...\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function CoreModel.make_predict_function.<locals>.predict_function_trained at 0x7fd283958c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function CoreModel.make_predict_function.<locals>.predict_function_trained at 0x7fd283958c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model compiled.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd28433ed50>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tfdf.keras.GradientBoostedTreesModel.predefined_hyperparameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYMAX4BMsSqg",
        "outputId": "6a13b63a-152d-4692-d363-daf1b4c56a78"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[HyperParameterTemplate(name='better_default', version=1, parameters={'growing_strategy': 'BEST_FIRST_GLOBAL'}, description='A configuration that is generally better than the default parameters without being more expensive.'), HyperParameterTemplate(name='benchmark_rank1', version=1, parameters={'growing_strategy': 'BEST_FIRST_GLOBAL', 'categorical_algorithm': 'RANDOM', 'split_axis': 'SPARSE_OBLIQUE', 'sparse_oblique_normalization': 'MIN_MAX', 'sparse_oblique_num_projections_exponent': 1.0}, description='Top ranking hyper-parameters on our benchmark slightly modified to run in reasonable time.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 기능 전처리\n",
        "%set_cell_height 300\n",
        "\n",
        "body_mass_g = tf.keras.layers.Input(shape=(1,), name=\"body_mass_g\")\n",
        "body_mass_kg = body_mass_g / 1000.0\n",
        "\n",
        "bill_length_mm = tf.keras.layers.Input(shape=(1,), name=\"bill_length_mm\")\n",
        "\n",
        "raw_inputs = {\"body_mass_g\": body_mass_g, \"bill_length_mm\": bill_length_mm}\n",
        "processed_inputs = {\"body_mass_kg\": body_mass_kg, \"bill_length_mm\": bill_length_mm}\n",
        "\n",
        "preprocessor = tf.keras.Model(inputs=raw_inputs, outputs=processed_inputs)\n",
        "\n",
        "model_4 = tfdf.keras.RandomForestModel(preprocessing=preprocessor)\n",
        "model_4.fit(x=train_ds)\n",
        "\n",
        "model_4.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "YE55XAl5sWCU",
        "outputId": "22563e33-5224-41b8-e839-da6f52434ee5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use /tmp/tmplz3i_9u7 as temporary training directory\n",
            "Reading training dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:566: UserWarning: Input dict contained keys ['island', 'bill_depth_mm', 'flipper_length_mm', 'sex', 'year'] which did not match any model input. They will be ignored by the model.\n",
            "  inputs = self._flatten_to_reference_inputs(inputs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function CoreModel._consumes_training_examples_until_eof at 0x7fd28a8b2c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function CoreModel._consumes_training_examples_until_eof at 0x7fd28a8b2c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training dataset read in 0:00:00.467635. Found 242 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.135764\n",
            "Compiling model...\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function CoreModel.make_predict_function.<locals>.predict_function_trained at 0x7fd283ef75f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function CoreModel.make_predict_function.<locals>.predict_function_trained at 0x7fd283ef75f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model compiled.\n",
            "WARNING:tensorflow:5 out of the last 10 calls to <function CoreModel.yggdrasil_model_path_tensor at 0x7fd283fb00e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 10 calls to <function CoreModel.yggdrasil_model_path_tensor at 0x7fd283fb00e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"random_forest_model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " model (Functional)          {'body_mass_kg': (None,   0         \n",
            "                             1),                                 \n",
            "                              'bill_length_mm': (None            \n",
            "                             , 1)}                               \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1\n",
            "Trainable params: 0\n",
            "Non-trainable params: 1\n",
            "_________________________________________________________________\n",
            "Type: \"RANDOM_FOREST\"\n",
            "Task: CLASSIFICATION\n",
            "Label: \"__LABEL\"\n",
            "\n",
            "Input Features (2):\n",
            "\tbill_length_mm\n",
            "\tbody_mass_kg\n",
            "\n",
            "No weights\n",
            "\n",
            "Variable Importance: MEAN_MIN_DEPTH:\n",
            "    1.        \"__LABEL\"  3.769471 ################\n",
            "    2.   \"body_mass_kg\"  1.196381 ####\n",
            "    3. \"bill_length_mm\"  0.055515 \n",
            "\n",
            "Variable Importance: NUM_AS_ROOT:\n",
            "    1. \"bill_length_mm\" 284.000000 ################\n",
            "    2.   \"body_mass_kg\" 16.000000 \n",
            "\n",
            "Variable Importance: NUM_NODES:\n",
            "    1. \"bill_length_mm\" 1568.000000 ################\n",
            "    2.   \"body_mass_kg\" 1270.000000 \n",
            "\n",
            "Variable Importance: SUM_SCORE:\n",
            "    1. \"bill_length_mm\" 44569.799430 ################\n",
            "    2.   \"body_mass_kg\" 25151.453656 \n",
            "\n",
            "\n",
            "\n",
            "Winner take all: true\n",
            "Out-of-bag evaluation: accuracy:0.92562 logloss:0.229484\n",
            "Number of trees: 300\n",
            "Total number of nodes: 5976\n",
            "\n",
            "Number of nodes by tree:\n",
            "Count: 300 Average: 19.92 StdDev: 2.87175\n",
            "Min: 11 Max: 29 Ignored: 0\n",
            "----------------------------------------------\n",
            "[ 11, 12)  2   0.67%   0.67%\n",
            "[ 12, 13)  0   0.00%   0.67%\n",
            "[ 13, 14)  1   0.33%   1.00%\n",
            "[ 14, 15)  0   0.00%   1.00%\n",
            "[ 15, 16) 21   7.00%   8.00% ##\n",
            "[ 16, 17)  0   0.00%   8.00%\n",
            "[ 17, 18) 55  18.33%  26.33% ######\n",
            "[ 18, 19)  0   0.00%  26.33%\n",
            "[ 19, 20) 69  23.00%  49.33% ########\n",
            "[ 20, 21)  0   0.00%  49.33%\n",
            "[ 21, 22) 86  28.67%  78.00% ##########\n",
            "[ 22, 23)  0   0.00%  78.00%\n",
            "[ 23, 24) 43  14.33%  92.33% #####\n",
            "[ 24, 25)  0   0.00%  92.33%\n",
            "[ 25, 26) 19   6.33%  98.67% ##\n",
            "[ 26, 27)  0   0.00%  98.67%\n",
            "[ 27, 28)  3   1.00%  99.67%\n",
            "[ 28, 29)  0   0.00%  99.67%\n",
            "[ 29, 29]  1   0.33% 100.00%\n",
            "\n",
            "Depth by leafs:\n",
            "Count: 3138 Average: 3.79477 StdDev: 1.12079\n",
            "Min: 1 Max: 7 Ignored: 0\n",
            "----------------------------------------------\n",
            "[ 1, 2)   21   0.67%   0.67%\n",
            "[ 2, 3)  360  11.47%  12.14% ###\n",
            "[ 3, 4)  880  28.04%  40.18% ########\n",
            "[ 4, 5) 1101  35.09%  75.27% ##########\n",
            "[ 5, 6)  563  17.94%  93.21% #####\n",
            "[ 6, 7)  183   5.83%  99.04% ##\n",
            "[ 7, 7]   30   0.96% 100.00%\n",
            "\n",
            "Number of training obs by leaf:\n",
            "Count: 3138 Average: 23.1358 StdDev: 28.0151\n",
            "Min: 5 Max: 114 Ignored: 0\n",
            "----------------------------------------------\n",
            "[   5,  10) 1981  63.13%  63.13% ##########\n",
            "[  10,  16)  202   6.44%  69.57% #\n",
            "[  16,  21)   31   0.99%  70.55%\n",
            "[  21,  27)   39   1.24%  71.80%\n",
            "[  27,  32)   67   2.14%  73.93%\n",
            "[  32,  38)  113   3.60%  77.53% #\n",
            "[  38,  43)   76   2.42%  79.96%\n",
            "[  43,  49)   31   0.99%  80.94%\n",
            "[  49,  54)    9   0.29%  81.23%\n",
            "[  54,  60)   30   0.96%  82.19%\n",
            "[  60,  65)   51   1.63%  83.81%\n",
            "[  65,  71)   96   3.06%  86.87%\n",
            "[  71,  76)   97   3.09%  89.96%\n",
            "[  76,  82)   95   3.03%  92.99%\n",
            "[  82,  87)   93   2.96%  95.95%\n",
            "[  87,  93)   65   2.07%  98.02%\n",
            "[  93,  98)   37   1.18%  99.20%\n",
            "[  98, 104)   19   0.61%  99.81%\n",
            "[ 104, 109)    3   0.10%  99.90%\n",
            "[ 109, 114]    3   0.10% 100.00%\n",
            "\n",
            "Attribute in nodes:\n",
            "\t1568 : bill_length_mm [NUMERICAL]\n",
            "\t1270 : body_mass_kg [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 0:\n",
            "\t284 : bill_length_mm [NUMERICAL]\n",
            "\t16 : body_mass_kg [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 1:\n",
            "\t476 : bill_length_mm [NUMERICAL]\n",
            "\t403 : body_mass_kg [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 2:\n",
            "\t914 : bill_length_mm [NUMERICAL]\n",
            "\t763 : body_mass_kg [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 3:\n",
            "\t1301 : bill_length_mm [NUMERICAL]\n",
            "\t1092 : body_mass_kg [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 5:\n",
            "\t1558 : bill_length_mm [NUMERICAL]\n",
            "\t1265 : body_mass_kg [NUMERICAL]\n",
            "\n",
            "Condition type in nodes:\n",
            "\t2838 : HigherCondition\n",
            "Condition type in nodes with depth <= 0:\n",
            "\t300 : HigherCondition\n",
            "Condition type in nodes with depth <= 1:\n",
            "\t879 : HigherCondition\n",
            "Condition type in nodes with depth <= 2:\n",
            "\t1677 : HigherCondition\n",
            "Condition type in nodes with depth <= 3:\n",
            "\t2393 : HigherCondition\n",
            "Condition type in nodes with depth <= 5:\n",
            "\t2823 : HigherCondition\n",
            "Node format: NOT_SET\n",
            "\n",
            "Training OOB:\n",
            "\ttrees: 1, Out-of-bag evaluation: accuracy:0.888889 logloss:4.00485\n",
            "\ttrees: 11, Out-of-bag evaluation: accuracy:0.908714 logloss:1.73396\n",
            "\ttrees: 21, Out-of-bag evaluation: accuracy:0.904959 logloss:1.30596\n",
            "\ttrees: 31, Out-of-bag evaluation: accuracy:0.904959 logloss:1.17739\n",
            "\ttrees: 41, Out-of-bag evaluation: accuracy:0.909091 logloss:1.02511\n",
            "\ttrees: 51, Out-of-bag evaluation: accuracy:0.909091 logloss:1.02207\n",
            "\ttrees: 61, Out-of-bag evaluation: accuracy:0.913223 logloss:1.01873\n",
            "\ttrees: 71, Out-of-bag evaluation: accuracy:0.921488 logloss:0.748619\n",
            "\ttrees: 81, Out-of-bag evaluation: accuracy:0.917355 logloss:0.747148\n",
            "\ttrees: 91, Out-of-bag evaluation: accuracy:0.921488 logloss:0.747514\n",
            "\ttrees: 101, Out-of-bag evaluation: accuracy:0.917355 logloss:0.612756\n",
            "\ttrees: 111, Out-of-bag evaluation: accuracy:0.921488 logloss:0.614751\n",
            "\ttrees: 121, Out-of-bag evaluation: accuracy:0.921488 logloss:0.61643\n",
            "\ttrees: 131, Out-of-bag evaluation: accuracy:0.921488 logloss:0.620551\n",
            "\ttrees: 141, Out-of-bag evaluation: accuracy:0.921488 logloss:0.62111\n",
            "\ttrees: 151, Out-of-bag evaluation: accuracy:0.921488 logloss:0.623543\n",
            "\ttrees: 161, Out-of-bag evaluation: accuracy:0.913223 logloss:0.624635\n",
            "\ttrees: 171, Out-of-bag evaluation: accuracy:0.917355 logloss:0.624869\n",
            "\ttrees: 181, Out-of-bag evaluation: accuracy:0.92562 logloss:0.625248\n",
            "\ttrees: 191, Out-of-bag evaluation: accuracy:0.92562 logloss:0.623239\n",
            "\ttrees: 201, Out-of-bag evaluation: accuracy:0.92562 logloss:0.62107\n",
            "\ttrees: 211, Out-of-bag evaluation: accuracy:0.92562 logloss:0.491459\n",
            "\ttrees: 221, Out-of-bag evaluation: accuracy:0.917355 logloss:0.358958\n",
            "\ttrees: 231, Out-of-bag evaluation: accuracy:0.917355 logloss:0.358368\n",
            "\ttrees: 241, Out-of-bag evaluation: accuracy:0.917355 logloss:0.35741\n",
            "\ttrees: 251, Out-of-bag evaluation: accuracy:0.921488 logloss:0.357995\n",
            "\ttrees: 261, Out-of-bag evaluation: accuracy:0.921488 logloss:0.228567\n",
            "\ttrees: 271, Out-of-bag evaluation: accuracy:0.92562 logloss:0.228345\n",
            "\ttrees: 281, Out-of-bag evaluation: accuracy:0.917355 logloss:0.227626\n",
            "\ttrees: 291, Out-of-bag evaluation: accuracy:0.921488 logloss:0.229172\n",
            "\ttrees: 300, Out-of-bag evaluation: accuracy:0.92562 logloss:0.229484\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def g_to_kg(x):\n",
        "  return x / 1000\n",
        "\n",
        "feature_columns = [\n",
        "    tf.feature_column.numeric_column(\"body_mass_g\", normalizer_fn=g_to_kg),\n",
        "    tf.feature_column.numeric_column(\"bill_length_mm\"),\n",
        "]\n",
        "\n",
        "preprocessing = tf.keras.layers.DenseFeatures(feature_columns)\n",
        "\n",
        "model_5 = tfdf.keras.RandomForestModel(preprocessing=preprocessing)\n",
        "model_5.compile(metrics=[\"accuracy\"])\n",
        "model_5.fit(x=train_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fx6AZhchsbvi",
        "outputId": "8f47a368-f2d0-42fb-d625-b1a1740d6260"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use /tmp/tmp_s19_e48 as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.300989. Found 242 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:00.102814\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function CoreModel.yggdrasil_model_path_tensor at 0x7fd283a97e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 11 calls to <function CoreModel.yggdrasil_model_path_tensor at 0x7fd283a97e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd283bf5510>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 04. 회귀 모델 학습"
      ],
      "metadata": {
        "id": "0lbUGaB2sj0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://storage.googleapis.com/download.tensorflow.org/data/abalone_raw.csv -O /tmp/abalone.csv\n",
        "\n",
        "dataset_df = pd.read_csv(\"/tmp/abalone.csv\")\n",
        "print(dataset_df.head(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NksUQEhsew-",
        "outputId": "8d4d4efe-fcc9-434f-c002-0f40e7c43afb"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Type  LongestShell  Diameter  Height  WholeWeight  ShuckedWeight  \\\n",
            "0    M         0.455     0.365   0.095       0.5140         0.2245   \n",
            "1    M         0.350     0.265   0.090       0.2255         0.0995   \n",
            "2    F         0.530     0.420   0.135       0.6770         0.2565   \n",
            "\n",
            "   VisceraWeight  ShellWeight  Rings  \n",
            "0         0.1010         0.15     15  \n",
            "1         0.0485         0.07      7  \n",
            "2         0.1415         0.21      9  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds_pd, test_ds_pd = split_dataset(dataset_df)\n",
        "print(\"{} examples in training, {} examples for testing.\".format(\n",
        "    len(train_ds_pd), len(test_ds_pd)))\n",
        "\n",
        "label = \"Rings\"\n",
        "\n",
        "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=label, task=tfdf.keras.Task.REGRESSION)\n",
        "test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=label, task=tfdf.keras.Task.REGRESSION)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tcn-WRxCsuLU",
        "outputId": "ba605f57-8d5a-4273-d102-8d57deb4ef6b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2925 examples in training, 1252 examples for testing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow_decision_forests/keras/core.py:2574: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  features_dataframe = dataframe.drop(label, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%set_cell_height 300\n",
        "\n",
        "model_7 = tfdf.keras.RandomForestModel(task = tfdf.keras.Task.REGRESSION)\n",
        "\n",
        "model_7.compile(metrics=[\"mse\"])\n",
        "\n",
        "# 모델 훈련\n",
        "with sys_pipes():\n",
        "  model_7.fit(x=train_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "XiOgkatrtAeT",
        "outputId": "3c16701c-8704-4c58-f9d9-2a452f4ec59d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use /tmp/tmpu_pz_tk5 as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.176100. Found 2925 examples.\n",
            "Training model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[INFO kernel.cc:1176] Loading model from path /tmp/tmpu_pz_tk5/model/ with prefix bfce140687b94922\n",
            "[INFO abstract_model.cc:1248] Engine \"RandomForestOptPred\" built\n",
            "[INFO kernel.cc:1022] Use fast generic engine\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained in 0:00:02.678855\n",
            "Compiling model...\n",
            "Model compiled.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation = model_7.evaluate(test_ds, return_dict=True)\n",
        "\n",
        "print(evaluation)\n",
        "print()\n",
        "print(f\"MSE: {evaluation['mse']}\")\n",
        "print(f\"RMSE: {math.sqrt(evaluation['mse'])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iru6vHmNtMfi",
        "outputId": "44b85942-d63d-4031-901b-ed608cbe60b3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 80ms/step - loss: 0.0000e+00 - mse: 1.8886\n",
            "{'loss': 0.0, 'mse': 1.888583779335022}\n",
            "\n",
            "MSE: 1.888583779335022\n",
            "RMSE: 1.3742575374852495\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 05. 순위 모델 학습"
      ],
      "metadata": {
        "id": "y4N7hvCmtqmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%set_cell_height 200\n",
        "\n",
        "archive_path = tf.keras.utils.get_file(\"letor.zip\",\n",
        "  \"https://download.microsoft.com/download/E/7/E/E7EABEF1-4C7B-4E31-ACE5-73927950ED5E/Letor.zip\",\n",
        "  extract=True)\n",
        "\n",
        "raw_dataset_path = os.path.join(os.path.dirname(archive_path),\"OHSUMED/Data/All/OHSUMED.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "spnrHAVWtoDT",
        "outputId": "35b267af-be35-43cc-bce4-4156627cff82"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 200})"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://download.microsoft.com/download/E/7/E/E7EABEF1-4C7B-4E31-ACE5-73927950ED5E/Letor.zip\n",
            "61824018/61824018 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_libsvm_to_csv(src_path, dst_path):\n",
        "  dst_handle = open(dst_path, \"w\")\n",
        "  first_line = True\n",
        "  for src_line in open(src_path,\"r\"):\n",
        "    items = src_line.split(\" \")[:-3]\n",
        "    relevance = items[0]\n",
        "    group = items[1].split(\":\")[1]\n",
        "    features = [ item.split(\":\") for item in items[2:]]\n",
        "\n",
        "    if first_line:\n",
        "      dst_handle.write(\"relevance,group,\" + \",\".join([\"f_\" + feature[0] for feature in features]) + \"\\n\")\n",
        "      first_line = False\n",
        "    dst_handle.write(relevance + \",g_\" + group + \",\" + (\",\".join([feature[1] for feature in features])) + \"\\n\")\n",
        "  dst_handle.close()\n",
        "\n",
        "# 데이터세트 변환\n",
        "csv_dataset_path=\"/tmp/ohsumed.csv\"\n",
        "convert_libsvm_to_csv(raw_dataset_path, csv_dataset_path)\n",
        "\n",
        "# 데이터세트 불러오기\n",
        "dataset_df = pd.read_csv(csv_dataset_path)\n",
        "\n",
        "# 상위 3개 출력.\n",
        "dataset_df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "Sijycx65t9mq",
        "outputId": "dbd6c15c-dd31-4349-a6c0-3b60db3d3c39"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   relevance group  f_1       f_2       f_3       f_4        f_5        f_6  \\\n",
              "0          2   g_1  3.0  2.079442  0.272727  0.261034  37.330565  11.431241   \n",
              "1          0   g_1  3.0  2.079442  0.428571  0.400594  37.330565  11.431241   \n",
              "2          2   g_1  0.0  0.000000  0.000000  0.000000  37.330565  11.431241   \n",
              "\n",
              "        f_7       f_8  ...      f_16       f_17      f_18       f_19  \\\n",
              "0  37.29975  1.138657  ...  9.340024  24.808785  0.393091  57.416517   \n",
              "1  37.29975  1.814480  ...  9.340024  24.808785  0.349205  43.240626   \n",
              "2  37.29975  0.000000  ...  9.340024  24.808785  0.240319  25.816989   \n",
              "\n",
              "       f_20     f_21      f_22     f_23     f_24     f_25  \n",
              "0  3.294893  25.0231  3.219799 -3.87098 -3.90273 -3.87512  \n",
              "1  2.654724  23.4903  3.156588 -3.96838 -4.00865 -3.98670  \n",
              "2  1.551342  15.8650  2.764115 -4.28166 -4.33313 -4.44161  \n",
              "\n",
              "[3 rows x 27 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d5ac6e58-4fd9-4e41-9eb7-1480c7c24c8c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>relevance</th>\n",
              "      <th>group</th>\n",
              "      <th>f_1</th>\n",
              "      <th>f_2</th>\n",
              "      <th>f_3</th>\n",
              "      <th>f_4</th>\n",
              "      <th>f_5</th>\n",
              "      <th>f_6</th>\n",
              "      <th>f_7</th>\n",
              "      <th>f_8</th>\n",
              "      <th>...</th>\n",
              "      <th>f_16</th>\n",
              "      <th>f_17</th>\n",
              "      <th>f_18</th>\n",
              "      <th>f_19</th>\n",
              "      <th>f_20</th>\n",
              "      <th>f_21</th>\n",
              "      <th>f_22</th>\n",
              "      <th>f_23</th>\n",
              "      <th>f_24</th>\n",
              "      <th>f_25</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>g_1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.079442</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.261034</td>\n",
              "      <td>37.330565</td>\n",
              "      <td>11.431241</td>\n",
              "      <td>37.29975</td>\n",
              "      <td>1.138657</td>\n",
              "      <td>...</td>\n",
              "      <td>9.340024</td>\n",
              "      <td>24.808785</td>\n",
              "      <td>0.393091</td>\n",
              "      <td>57.416517</td>\n",
              "      <td>3.294893</td>\n",
              "      <td>25.0231</td>\n",
              "      <td>3.219799</td>\n",
              "      <td>-3.87098</td>\n",
              "      <td>-3.90273</td>\n",
              "      <td>-3.87512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>g_1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.079442</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.400594</td>\n",
              "      <td>37.330565</td>\n",
              "      <td>11.431241</td>\n",
              "      <td>37.29975</td>\n",
              "      <td>1.814480</td>\n",
              "      <td>...</td>\n",
              "      <td>9.340024</td>\n",
              "      <td>24.808785</td>\n",
              "      <td>0.349205</td>\n",
              "      <td>43.240626</td>\n",
              "      <td>2.654724</td>\n",
              "      <td>23.4903</td>\n",
              "      <td>3.156588</td>\n",
              "      <td>-3.96838</td>\n",
              "      <td>-4.00865</td>\n",
              "      <td>-3.98670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>g_1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>37.330565</td>\n",
              "      <td>11.431241</td>\n",
              "      <td>37.29975</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>9.340024</td>\n",
              "      <td>24.808785</td>\n",
              "      <td>0.240319</td>\n",
              "      <td>25.816989</td>\n",
              "      <td>1.551342</td>\n",
              "      <td>15.8650</td>\n",
              "      <td>2.764115</td>\n",
              "      <td>-4.28166</td>\n",
              "      <td>-4.33313</td>\n",
              "      <td>-4.44161</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 27 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d5ac6e58-4fd9-4e41-9eb7-1480c7c24c8c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d5ac6e58-4fd9-4e41-9eb7-1480c7c24c8c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d5ac6e58-4fd9-4e41-9eb7-1480c7c24c8c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds_pd, test_ds_pd = split_dataset(dataset_df)\n",
        "print(\"{} examples in training, {} examples for testing.\".format(\n",
        "    len(train_ds_pd), len(test_ds_pd)))\n",
        "\n",
        "train_ds_pd.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "e7twpfczuLOY",
        "outputId": "bda6a781-627d-4de3-82aa-6f888b913e21"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11381 examples in training, 4759 examples for testing.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   relevance group  f_1       f_2       f_3       f_4        f_5        f_6  \\\n",
              "0          2   g_1  3.0  2.079442  0.272727  0.261034  37.330565  11.431241   \n",
              "1          0   g_1  3.0  2.079442  0.428571  0.400594  37.330565  11.431241   \n",
              "2          2   g_1  0.0  0.000000  0.000000  0.000000  37.330565  11.431241   \n",
              "\n",
              "        f_7       f_8  ...      f_16       f_17      f_18       f_19  \\\n",
              "0  37.29975  1.138657  ...  9.340024  24.808785  0.393091  57.416517   \n",
              "1  37.29975  1.814480  ...  9.340024  24.808785  0.349205  43.240626   \n",
              "2  37.29975  0.000000  ...  9.340024  24.808785  0.240319  25.816989   \n",
              "\n",
              "       f_20     f_21      f_22     f_23     f_24     f_25  \n",
              "0  3.294893  25.0231  3.219799 -3.87098 -3.90273 -3.87512  \n",
              "1  2.654724  23.4903  3.156588 -3.96838 -4.00865 -3.98670  \n",
              "2  1.551342  15.8650  2.764115 -4.28166 -4.33313 -4.44161  \n",
              "\n",
              "[3 rows x 27 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7c3edb45-ed8d-4180-82cb-1450bb06157c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>relevance</th>\n",
              "      <th>group</th>\n",
              "      <th>f_1</th>\n",
              "      <th>f_2</th>\n",
              "      <th>f_3</th>\n",
              "      <th>f_4</th>\n",
              "      <th>f_5</th>\n",
              "      <th>f_6</th>\n",
              "      <th>f_7</th>\n",
              "      <th>f_8</th>\n",
              "      <th>...</th>\n",
              "      <th>f_16</th>\n",
              "      <th>f_17</th>\n",
              "      <th>f_18</th>\n",
              "      <th>f_19</th>\n",
              "      <th>f_20</th>\n",
              "      <th>f_21</th>\n",
              "      <th>f_22</th>\n",
              "      <th>f_23</th>\n",
              "      <th>f_24</th>\n",
              "      <th>f_25</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>g_1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.079442</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.261034</td>\n",
              "      <td>37.330565</td>\n",
              "      <td>11.431241</td>\n",
              "      <td>37.29975</td>\n",
              "      <td>1.138657</td>\n",
              "      <td>...</td>\n",
              "      <td>9.340024</td>\n",
              "      <td>24.808785</td>\n",
              "      <td>0.393091</td>\n",
              "      <td>57.416517</td>\n",
              "      <td>3.294893</td>\n",
              "      <td>25.0231</td>\n",
              "      <td>3.219799</td>\n",
              "      <td>-3.87098</td>\n",
              "      <td>-3.90273</td>\n",
              "      <td>-3.87512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>g_1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.079442</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.400594</td>\n",
              "      <td>37.330565</td>\n",
              "      <td>11.431241</td>\n",
              "      <td>37.29975</td>\n",
              "      <td>1.814480</td>\n",
              "      <td>...</td>\n",
              "      <td>9.340024</td>\n",
              "      <td>24.808785</td>\n",
              "      <td>0.349205</td>\n",
              "      <td>43.240626</td>\n",
              "      <td>2.654724</td>\n",
              "      <td>23.4903</td>\n",
              "      <td>3.156588</td>\n",
              "      <td>-3.96838</td>\n",
              "      <td>-4.00865</td>\n",
              "      <td>-3.98670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>g_1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>37.330565</td>\n",
              "      <td>11.431241</td>\n",
              "      <td>37.29975</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>9.340024</td>\n",
              "      <td>24.808785</td>\n",
              "      <td>0.240319</td>\n",
              "      <td>25.816989</td>\n",
              "      <td>1.551342</td>\n",
              "      <td>15.8650</td>\n",
              "      <td>2.764115</td>\n",
              "      <td>-4.28166</td>\n",
              "      <td>-4.33313</td>\n",
              "      <td>-4.44161</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 27 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c3edb45-ed8d-4180-82cb-1450bb06157c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7c3edb45-ed8d-4180-82cb-1450bb06157c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7c3edb45-ed8d-4180-82cb-1450bb06157c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "relevance = \"relevance\"\n",
        "\n",
        "ranking_train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=relevance, task=tfdf.keras.Task.RANKING)\n",
        "ranking_test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=relevance, task=tfdf.keras.Task.RANKING)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KE1RFlk_uOK0",
        "outputId": "6085501e-c786-4bf3-8324-dc32a13b2e15"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow_decision_forests/keras/core.py:2574: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  features_dataframe = dataframe.drop(label, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%set_cell_height 400\n",
        "\n",
        "model_8 = tfdf.keras.GradientBoostedTreesModel(\n",
        "    task=tfdf.keras.Task.RANKING,\n",
        "    ranking_group=\"group\",\n",
        "    num_trees=50)\n",
        "\n",
        "with sys_pipes():\n",
        "  model_8.fit(x=ranking_train_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "GASEE1APuRi4",
        "outputId": "2ee52e74-61d5-473b-c848-1a9e773ada2f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 400})"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use /tmp/tmpjcdh061f as temporary training directory\n",
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.748533. Found 11381 examples.\n",
            "Training model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[INFO kernel.cc:1176] Loading model from path /tmp/tmpjcdh061f/model/ with prefix 4390be32d1714b83\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained in 0:00:02.588259\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[INFO abstract_model.cc:1248] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n",
            "[INFO kernel.cc:1022] Use fast generic engine\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Compiling model...\n",
            "Model compiled.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%set_cell_height 400\n",
        "\n",
        "model_8.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "UEMTOicfuUVM",
        "outputId": "b400e9bf-7d8d-4cbc-cace-3844ed0d1a53"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 400})"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"gradient_boosted_trees_model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            "=================================================================\n",
            "Total params: 1\n",
            "Trainable params: 0\n",
            "Non-trainable params: 1\n",
            "_________________________________________________________________\n",
            "Type: \"GRADIENT_BOOSTED_TREES\"\n",
            "Task: RANKING\n",
            "Label: \"__LABEL\"\n",
            "Rank group: \"__RANK_GROUP\"\n",
            "\n",
            "Input Features (25):\n",
            "\tf_1\n",
            "\tf_10\n",
            "\tf_11\n",
            "\tf_12\n",
            "\tf_13\n",
            "\tf_14\n",
            "\tf_15\n",
            "\tf_16\n",
            "\tf_17\n",
            "\tf_18\n",
            "\tf_19\n",
            "\tf_2\n",
            "\tf_20\n",
            "\tf_21\n",
            "\tf_22\n",
            "\tf_23\n",
            "\tf_24\n",
            "\tf_25\n",
            "\tf_3\n",
            "\tf_4\n",
            "\tf_5\n",
            "\tf_6\n",
            "\tf_7\n",
            "\tf_8\n",
            "\tf_9\n",
            "\n",
            "No weights\n",
            "\n",
            "Variable Importance: MEAN_MIN_DEPTH:\n",
            "    1. \"__RANK_GROUP\"  4.354192 ################\n",
            "    2.          \"f_1\"  4.354192 ################\n",
            "    3.      \"__LABEL\"  4.354192 ################\n",
            "    4.          \"f_5\"  4.349919 ###############\n",
            "    5.          \"f_6\"  4.327043 ###############\n",
            "    6.         \"f_17\"  4.322493 ###############\n",
            "    7.         \"f_12\"  4.316293 ###############\n",
            "    8.         \"f_24\"  4.311271 ###############\n",
            "    9.          \"f_2\"  4.310959 ###############\n",
            "   10.         \"f_16\"  4.305284 ###############\n",
            "   11.         \"f_13\"  4.292924 ###############\n",
            "   12.         \"f_11\"  4.280434 ###############\n",
            "   13.          \"f_7\"  4.257607 ###############\n",
            "   14.          \"f_9\"  4.246559 ###############\n",
            "   15.         \"f_14\"  4.244356 ###############\n",
            "   16.         \"f_15\"  4.191564 ###############\n",
            "   17.         \"f_19\"  4.179724 ###############\n",
            "   18.         \"f_18\"  4.174627 ###############\n",
            "   19.         \"f_10\"  4.153793 ###############\n",
            "   20.          \"f_3\"  4.099324 ##############\n",
            "   21.         \"f_21\"  3.906196 ##############\n",
            "   22.         \"f_20\"  3.818748 #############\n",
            "   23.          \"f_4\"  3.743127 #############\n",
            "   24.         \"f_25\"  3.696486 #############\n",
            "   25.         \"f_22\"  3.300780 ###########\n",
            "   26.         \"f_23\"  2.517355 ########\n",
            "   27.          \"f_8\"  0.434562 \n",
            "\n",
            "Variable Importance: NUM_AS_ROOT:\n",
            "    1.  \"f_8\" 16.000000 ################\n",
            "    2. \"f_22\"  1.000000 \n",
            "    3.  \"f_4\"  1.000000 \n",
            "\n",
            "Variable Importance: NUM_NODES:\n",
            "    1.  \"f_8\" 49.000000 ################\n",
            "    2. \"f_23\" 32.000000 ##########\n",
            "    3. \"f_25\" 21.000000 ######\n",
            "    4. \"f_22\" 20.000000 ######\n",
            "    5. \"f_19\" 17.000000 #####\n",
            "    6. \"f_20\" 15.000000 ####\n",
            "    7. \"f_10\" 13.000000 ####\n",
            "    8. \"f_18\" 13.000000 ####\n",
            "    9. \"f_21\" 13.000000 ####\n",
            "   10. \"f_14\" 10.000000 ###\n",
            "   11.  \"f_4\" 10.000000 ###\n",
            "   12. \"f_15\"  8.000000 ##\n",
            "   13.  \"f_3\"  7.000000 ##\n",
            "   14.  \"f_9\"  7.000000 ##\n",
            "   15. \"f_24\"  6.000000 #\n",
            "   16.  \"f_7\"  6.000000 #\n",
            "   17. \"f_13\"  5.000000 #\n",
            "   18. \"f_11\"  4.000000 #\n",
            "   19. \"f_12\"  4.000000 #\n",
            "   20.  \"f_6\"  3.000000 \n",
            "   21. \"f_16\"  2.000000 \n",
            "   22. \"f_17\"  2.000000 \n",
            "   23.  \"f_2\"  2.000000 \n",
            "   24.  \"f_5\"  1.000000 \n",
            "\n",
            "Variable Importance: SUM_SCORE:\n",
            "    1.  \"f_8\" 9259.489006 ################\n",
            "    2. \"f_22\" 3255.825436 #####\n",
            "    3. \"f_23\" 2528.303808 ####\n",
            "    4. \"f_21\" 2046.367077 ###\n",
            "    5. \"f_19\" 1871.553668 ###\n",
            "    6. \"f_25\" 1746.745899 ##\n",
            "    7. \"f_20\" 1587.769484 ##\n",
            "    8. \"f_18\" 1029.081813 #\n",
            "    9. \"f_15\" 700.152264 #\n",
            "   10.  \"f_4\" 581.724916 \n",
            "   11.  \"f_3\" 533.295354 \n",
            "   12. \"f_11\" 530.497156 \n",
            "   13. \"f_10\" 512.982495 \n",
            "   14.  \"f_7\" 459.783887 \n",
            "   15. \"f_24\" 358.729147 \n",
            "   16.  \"f_9\" 321.632923 \n",
            "   17. \"f_16\" 245.072323 \n",
            "   18.  \"f_2\" 190.171052 \n",
            "   19. \"f_14\" 159.822482 \n",
            "   20. \"f_17\" 139.014247 \n",
            "   21.  \"f_6\" 89.609285 \n",
            "   22. \"f_13\" 82.316103 \n",
            "   23. \"f_12\" 19.838836 \n",
            "   24.  \"f_5\" 16.324057 \n",
            "\n",
            "\n",
            "\n",
            "Loss: LAMBDA_MART_NDCG5\n",
            "Validation loss value: -0.594399\n",
            "Number of trees per iteration: 1\n",
            "Node format: NOT_SET\n",
            "Number of trees: 18\n",
            "Total number of nodes: 558\n",
            "\n",
            "Number of nodes by tree:\n",
            "Count: 18 Average: 31 StdDev: 7.80313\n",
            "Min: 21 Max: 51 Ignored: 0\n",
            "----------------------------------------------\n",
            "[ 21, 22) 4  22.22%  22.22% ##########\n",
            "[ 22, 24) 0   0.00%  22.22%\n",
            "[ 24, 25) 0   0.00%  22.22%\n",
            "[ 25, 27) 1   5.56%  27.78% ###\n",
            "[ 27, 28) 2  11.11%  38.89% #####\n",
            "[ 28, 30) 1   5.56%  44.44% ###\n",
            "[ 30, 31) 0   0.00%  44.44%\n",
            "[ 31, 33) 2  11.11%  55.56% #####\n",
            "[ 33, 34) 2  11.11%  66.67% #####\n",
            "[ 34, 36) 1   5.56%  72.22% ###\n",
            "[ 36, 38) 2  11.11%  83.33% #####\n",
            "[ 38, 39) 0   0.00%  83.33%\n",
            "[ 39, 41) 2  11.11%  94.44% #####\n",
            "[ 41, 42) 0   0.00%  94.44%\n",
            "[ 42, 44) 0   0.00%  94.44%\n",
            "[ 44, 45) 0   0.00%  94.44%\n",
            "[ 45, 47) 0   0.00%  94.44%\n",
            "[ 47, 48) 0   0.00%  94.44%\n",
            "[ 48, 50) 0   0.00%  94.44%\n",
            "[ 50, 51] 1   5.56% 100.00% ###\n",
            "\n",
            "Depth by leafs:\n",
            "Count: 288 Average: 4.41319 StdDev: 0.957119\n",
            "Min: 2 Max: 5 Ignored: 0\n",
            "----------------------------------------------\n",
            "[ 2, 3)  22   7.64%   7.64% #\n",
            "[ 3, 4)  31  10.76%  18.40% ##\n",
            "[ 4, 5)  41  14.24%  32.64% ##\n",
            "[ 5, 5] 194  67.36% 100.00% ##########\n",
            "\n",
            "Number of training obs by leaf:\n",
            "Count: 288 Average: 645.875 StdDev: 2054.24\n",
            "Min: 5 Max: 10236 Ignored: 0\n",
            "----------------------------------------------\n",
            "[     5,   516) 247  85.76%  85.76% ##########\n",
            "[   516,  1028)   8   2.78%  88.54%\n",
            "[  1028,  1539)   5   1.74%  90.28%\n",
            "[  1539,  2051)   2   0.69%  90.97%\n",
            "[  2051,  2563)   2   0.69%  91.67%\n",
            "[  2563,  3074)   5   1.74%  93.40%\n",
            "[  3074,  3586)   3   1.04%  94.44%\n",
            "[  3586,  4097)   1   0.35%  94.79%\n",
            "[  4097,  4609)   1   0.35%  95.14%\n",
            "[  4609,  5121)   0   0.00%  95.14%\n",
            "[  5121,  5632)   0   0.00%  95.14%\n",
            "[  5632,  6144)   0   0.00%  95.14%\n",
            "[  6144,  6655)   0   0.00%  95.14%\n",
            "[  6655,  7167)   0   0.00%  95.14%\n",
            "[  7167,  7679)   1   0.35%  95.49%\n",
            "[  7679,  8190)   0   0.00%  95.49%\n",
            "[  8190,  8702)   2   0.69%  96.18%\n",
            "[  8702,  9213)   3   1.04%  97.22%\n",
            "[  9213,  9725)   4   1.39%  98.61%\n",
            "[  9725, 10236]   4   1.39% 100.00%\n",
            "\n",
            "Attribute in nodes:\n",
            "\t49 : f_8 [NUMERICAL]\n",
            "\t32 : f_23 [NUMERICAL]\n",
            "\t21 : f_25 [NUMERICAL]\n",
            "\t20 : f_22 [NUMERICAL]\n",
            "\t17 : f_19 [NUMERICAL]\n",
            "\t15 : f_20 [NUMERICAL]\n",
            "\t13 : f_21 [NUMERICAL]\n",
            "\t13 : f_18 [NUMERICAL]\n",
            "\t13 : f_10 [NUMERICAL]\n",
            "\t10 : f_4 [NUMERICAL]\n",
            "\t10 : f_14 [NUMERICAL]\n",
            "\t8 : f_15 [NUMERICAL]\n",
            "\t7 : f_9 [NUMERICAL]\n",
            "\t7 : f_3 [NUMERICAL]\n",
            "\t6 : f_7 [NUMERICAL]\n",
            "\t6 : f_24 [NUMERICAL]\n",
            "\t5 : f_13 [NUMERICAL]\n",
            "\t4 : f_12 [NUMERICAL]\n",
            "\t4 : f_11 [NUMERICAL]\n",
            "\t3 : f_6 [NUMERICAL]\n",
            "\t2 : f_2 [NUMERICAL]\n",
            "\t2 : f_17 [NUMERICAL]\n",
            "\t2 : f_16 [NUMERICAL]\n",
            "\t1 : f_5 [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 0:\n",
            "\t16 : f_8 [NUMERICAL]\n",
            "\t1 : f_4 [NUMERICAL]\n",
            "\t1 : f_22 [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 1:\n",
            "\t18 : f_8 [NUMERICAL]\n",
            "\t12 : f_25 [NUMERICAL]\n",
            "\t7 : f_23 [NUMERICAL]\n",
            "\t5 : f_22 [NUMERICAL]\n",
            "\t4 : f_21 [NUMERICAL]\n",
            "\t3 : f_4 [NUMERICAL]\n",
            "\t2 : f_20 [NUMERICAL]\n",
            "\t1 : f_3 [NUMERICAL]\n",
            "\t1 : f_24 [NUMERICAL]\n",
            "\t1 : f_10 [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 2:\n",
            "\t30 : f_8 [NUMERICAL]\n",
            "\t17 : f_23 [NUMERICAL]\n",
            "\t12 : f_25 [NUMERICAL]\n",
            "\t9 : f_22 [NUMERICAL]\n",
            "\t7 : f_20 [NUMERICAL]\n",
            "\t5 : f_18 [NUMERICAL]\n",
            "\t4 : f_21 [NUMERICAL]\n",
            "\t4 : f_19 [NUMERICAL]\n",
            "\t4 : f_10 [NUMERICAL]\n",
            "\t3 : f_4 [NUMERICAL]\n",
            "\t2 : f_15 [NUMERICAL]\n",
            "\t2 : f_14 [NUMERICAL]\n",
            "\t1 : f_3 [NUMERICAL]\n",
            "\t1 : f_24 [NUMERICAL]\n",
            "\t1 : f_16 [NUMERICAL]\n",
            "\t1 : f_13 [NUMERICAL]\n",
            "\t1 : f_11 [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 3:\n",
            "\t42 : f_8 [NUMERICAL]\n",
            "\t25 : f_23 [NUMERICAL]\n",
            "\t18 : f_25 [NUMERICAL]\n",
            "\t13 : f_22 [NUMERICAL]\n",
            "\t12 : f_20 [NUMERICAL]\n",
            "\t10 : f_21 [NUMERICAL]\n",
            "\t8 : f_19 [NUMERICAL]\n",
            "\t6 : f_10 [NUMERICAL]\n",
            "\t5 : f_4 [NUMERICAL]\n",
            "\t5 : f_18 [NUMERICAL]\n",
            "\t4 : f_9 [NUMERICAL]\n",
            "\t4 : f_3 [NUMERICAL]\n",
            "\t3 : f_7 [NUMERICAL]\n",
            "\t3 : f_15 [NUMERICAL]\n",
            "\t3 : f_14 [NUMERICAL]\n",
            "\t3 : f_11 [NUMERICAL]\n",
            "\t2 : f_2 [NUMERICAL]\n",
            "\t2 : f_12 [NUMERICAL]\n",
            "\t1 : f_6 [NUMERICAL]\n",
            "\t1 : f_24 [NUMERICAL]\n",
            "\t1 : f_17 [NUMERICAL]\n",
            "\t1 : f_16 [NUMERICAL]\n",
            "\t1 : f_13 [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 5:\n",
            "\t49 : f_8 [NUMERICAL]\n",
            "\t32 : f_23 [NUMERICAL]\n",
            "\t21 : f_25 [NUMERICAL]\n",
            "\t20 : f_22 [NUMERICAL]\n",
            "\t17 : f_19 [NUMERICAL]\n",
            "\t15 : f_20 [NUMERICAL]\n",
            "\t13 : f_21 [NUMERICAL]\n",
            "\t13 : f_18 [NUMERICAL]\n",
            "\t13 : f_10 [NUMERICAL]\n",
            "\t10 : f_4 [NUMERICAL]\n",
            "\t10 : f_14 [NUMERICAL]\n",
            "\t8 : f_15 [NUMERICAL]\n",
            "\t7 : f_9 [NUMERICAL]\n",
            "\t7 : f_3 [NUMERICAL]\n",
            "\t6 : f_7 [NUMERICAL]\n",
            "\t6 : f_24 [NUMERICAL]\n",
            "\t5 : f_13 [NUMERICAL]\n",
            "\t4 : f_12 [NUMERICAL]\n",
            "\t4 : f_11 [NUMERICAL]\n",
            "\t3 : f_6 [NUMERICAL]\n",
            "\t2 : f_2 [NUMERICAL]\n",
            "\t2 : f_17 [NUMERICAL]\n",
            "\t2 : f_16 [NUMERICAL]\n",
            "\t1 : f_5 [NUMERICAL]\n",
            "\n",
            "Condition type in nodes:\n",
            "\t270 : HigherCondition\n",
            "Condition type in nodes with depth <= 0:\n",
            "\t18 : HigherCondition\n",
            "Condition type in nodes with depth <= 1:\n",
            "\t54 : HigherCondition\n",
            "Condition type in nodes with depth <= 2:\n",
            "\t104 : HigherCondition\n",
            "Condition type in nodes with depth <= 3:\n",
            "\t173 : HigherCondition\n",
            "Condition type in nodes with depth <= 5:\n",
            "\t270 : HigherCondition\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TNv63q9juWic"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}